{"meta":{"title":"lessinthemore","subtitle":"大道至简","description":"没有人可以和生活讨价还价。——《风雨哈佛路》","author":"大雷小宇","url":"https://xudongye.github.io/xdlog"},"pages":[{"title":"categories","date":"2020-12-18T02:51:05.441Z","updated":"2020-12-18T02:51:05.441Z","comments":false,"path":"categories/index.html","permalink":"https://xudongye.github.io/xdlog/categories/index.html","excerpt":"","text":""},{"title":"致谢","date":"2020-12-18T02:51:05.513Z","updated":"2020-12-18T02:51:05.513Z","comments":true,"path":"thanks/index.html","permalink":"https://xudongye.github.io/xdlog/thanks/index.html","excerpt":"","text":"致谢感谢构建此博客所用到的工具 hexo - 博客框架hexo theme indigo - 博客主题uiintellij Markdown support plugin - markdown编辑器processon - 在线制图工具七牛云 - 支持图片外链的免费云存储空间"},{"title":"tags","date":"2020-12-18T02:51:05.513Z","updated":"2020-12-18T02:51:05.513Z","comments":false,"path":"tags/index.html","permalink":"https://xudongye.github.io/xdlog/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"docker安装minio分布式存储系统","slug":"minio/docker安装minio分布式存储系统","date":"2021-06-08T06:33:35.000Z","updated":"2021-06-08T06:36:54.262Z","comments":true,"path":"minio/docker安装minio分布式存储系统/","link":"","permalink":"https://xudongye.github.io/xdlog/minio/docker安装minio分布式存储系统/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"minio123456789101112# 获取镜像docker pull minio/minio#构建容器docker run -p 9000:9000 --name minio \\ -d --restart=always \\ -e &quot;MINIO_ACCESS_KEY=minioadmin&quot; \\ -e &quot;MINIO_SECRET_KEY=minioadmin&quot; \\ -v /volume/yexudong/minio/data:/data \\ -v /volume/yexudong/minio/config:/root/.minio \\ minio/minio server /data","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"minio","slug":"minio","permalink":"https://xudongye.github.io/xdlog/tags/minio/"}]},{"title":"springcloud实战笔记","slug":"springcloud实战笔记","date":"2020-12-18T02:56:28.000Z","updated":"2020-12-18T02:56:29.027Z","comments":true,"path":"springcloud实战笔记/","link":"","permalink":"https://xudongye.github.io/xdlog/springcloud实战笔记/","excerpt":"","keywords":[],"text":"","categories":[],"tags":[]},{"title":"Java深拷贝与浅拷贝区别","slug":"mianshi/Java深拷贝与浅拷贝区别","date":"2020-11-27T08:41:53.000Z","updated":"2020-12-18T02:51:05.441Z","comments":true,"path":"mianshi/Java深拷贝与浅拷贝区别/","link":"","permalink":"https://xudongye.github.io/xdlog/mianshi/Java深拷贝与浅拷贝区别/","excerpt":"","keywords":[{"name":"面试","slug":"面试","permalink":"https://xudongye.github.io/xdlog/categories/面试/"}],"text":"为什么要使用数据拷贝场景在开发中经常会遇到，从父级类中拷贝属性到子类。一般使用2种方法： 一个一个的get/set 使用BeanUtils.copyProperties显然BeanUtils更加美观 BeanUtils是深拷贝还是浅拷贝呢？ 知识铺垫 Java中的数据类型分为基本数据类型和引用数据类型。对于二者，在进行赋值时，用作方法参数或返回时，会有值传递和引用传递的差别 浅拷贝 基本数据类型：浅拷贝会直接进行值传递，也就是将属性值复制一份给新的对象。 引用数据类型：如果成员变量时某个对象或数组，那么浅拷贝会进行引用传递，也就是将成员变量引用值（内存地址）复制一份给新的对象 浅拷贝的实现方式：通过构造函数参数为该类，可以完成浅拷贝12345678910111213141516171819202122232425public class Test &#123; public static void main(String[] args) &#123; CopyTest copyTest = new CopyTest(\"a\", \"b\"); CopyTest copyTest1 = new CopyTest(); BeanUtils.copyProperties(copyTest, copyTest); copyTest1.setA(\"A\"); System.out.println(copyTest1.getA() == copyTest.getA()); CopyTest copyTest2 = new CopyTest(copyTest); copyTest2.setB(\"B\"); System.out.println(copyTest2.getB()==copyTest2.getB()); &#125; @Data @AllArgsConstructor @NoArgsConstructor static class CopyTest &#123; private String a; private String b; public CopyTest(CopyTest copyTest) &#123; &#125; &#125;&#125; 运行结果 12falsetrue 深拷贝 结果分析","categories":[{"name":"面试","slug":"面试","permalink":"https://xudongye.github.io/xdlog/categories/面试/"}],"tags":[{"name":"java理论复习","slug":"java理论复习","permalink":"https://xudongye.github.io/xdlog/tags/java理论复习/"}]},{"title":"centos7.4 docker安装","slug":"texin/centos7.4 docker安装","date":"2020-09-10T06:21:07.000Z","updated":"2020-12-18T02:51:05.441Z","comments":true,"path":"texin/centos7.4 docker安装/","link":"","permalink":"https://xudongye.github.io/xdlog/texin/centos7.4 docker安装/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"Docker环境安装Docker三个基本概念: 仓库（Repository） 镜像（Image） 容器(Container）安装docker1.root账户登录，查看内核版本如下123[root@localhost ~]# uname -aLinux localhost.localdomain 3.10.0-957.el7.x86_64 #1 SMP Thu Nov 8 23:39:32 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux 2.把yum包更新到最新12345678910111213[root@localhost ~]# yum update已加载插件：fastestmirrorLoading mirror speeds from cached hostfile * base: centos.ustc.edu.cn * extras: mirrors.aliyun.com * updates: mirrors.cn99.combase | 3.6 kB 00:00:00 extras | 3.4 kB 00:00:00 updates | 3.4 kB 00:00:00 正在解决依赖关系--&gt; 正在检查事务---&gt; 软件包 NetworkManager.x86_64.1.1.12.0-6.el7 将被 升级---&gt; 软件包 NetworkManager.x86_64.1.1.12.0-10.el7_6 将被 更新 3.安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的1234567891011121314[root@localhost ~]# yum install -y yum-utils device-mapper-persistent-data lvm2已加载插件：fastestmirrorLoading mirror speeds from cached hostfile * base: centos.ustc.edu.cn * extras: mirrors.aliyun.com * updates: mirrors.cn99.com软件包 device-mapper-persistent-data-0.7.3-3.el7.x86_64 已安装并且是最新版本软件包 7:lvm2-2.02.180-10.el7_6.8.x86_64 已安装并且是最新版本正在解决依赖关系--&gt; 正在检查事务---&gt; 软件包 yum-utils.noarch.0.1.1.31-50.el7 将被 安装--&gt; 正在处理依赖关系 python-kitchen，它被软件包 yum-utils-1.1.31-50.el7.noarch 需要...... 4.设置yum源（选择其中一个）12yum-config-manager --add-repo http://download.docker.com/linux/centos/docker-ce.repo（中央仓库）yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo（阿里仓库） 1234567[root@localhost ~]# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo已加载插件：fastestmirroradding repo from: https://download.docker.com/linux/centos/docker-ce.repograbbing file https://download.docker.com/linux/centos/docker-ce.repo to /etc/yum.repos.d/docker-ce.reporepo saved to /etc/yum.repos.d/docker-ce.repo 5.可以查看所有仓库中所有docker版本，并选择特定版本安装12345678910111213141516171819202122232425[root@localhost ~]# yum list docker-ce --showduplicates | sort -r已加载插件：fastestmirror可安装的软件包 * updates: mirrors.cn99.comLoading mirror speeds from cached hostfile * extras: mirrors.aliyun.comdocker-ce.x86_64 3:19.03.2-3.el7 docker-ce-stabledocker-ce.x86_64 3:19.03.1-3.el7 docker-ce-stabledocker-ce.x86_64 3:19.03.0-3.el7 docker-ce-stabledocker-ce.x86_64 3:18.09.8-3.el7 docker-ce-stabledocker-ce.x86_64 3:18.09.7-3.el7 docker-ce-stabledocker-ce.x86_64 3:18.09.6-3.el7 docker-ce-stabledocker-ce.x86_64 3:18.09.5-3.el7 docker-ce-stabledocker-ce.x86_64 3:18.09.4-3.el7 docker-ce-stabledocker-ce.x86_64 3:18.09.3-3.el7 docker-ce-stabledocker-ce.x86_64 3:18.09.2-3.el7 docker-ce-stabledocker-ce.x86_64 3:18.09.1-3.el7 docker-ce-stabledocker-ce.x86_64 3:18.09.0-3.el7 docker-ce-stabledocker-ce.x86_64 18.06.3.ce-3.el7 docker-ce-stabledocker-ce.x86_64 18.06.2.ce-3.el7 docker-ce-stabledocker-ce.x86_64 18.06.1.ce-3.el7 docker-ce-stabledocker-ce.x86_64 18.06.0.ce-3.el7 docker-ce-stabledocker-ce.x86_64 18.03.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 18.03.0.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.12.1.ce-1.el7.centos docker-ce-stable 6.安装Docker，命令：yum install docker-ce-版本号，我选的是docker-ce-18.03.1.ce，如下123456789[root@localhost ~]# yum install docker-ce-18.03.1.ce已加载插件：fastestmirrorLoading mirror speeds from cached hostfile * base: centos.ustc.edu.cn * extras: mirrors.aliyun.com * updates: mirrors.cn99.com正在解决依赖关系--&gt; 正在检查事务---&gt; 软件包 docker-ce.x86_64.0.18.03.1.ce-1.el7.centos 将被 安装 7.启动Docker，命令：systemctl start docker，然后加入开机启动，如下1234567891011121314151617181920212223[root@localhost ~]# systemctl start docker[root@localhost ~]# systemctl enable dockerCreated symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.[root@localhost ~]# docker versionClient: Version: 18.03.1-ce API version: 1.37 Go version: go1.9.5 Git commit: 9ee9f40 Built: Thu Apr 26 07:20:16 2018 OS/Arch: linux/amd64 Experimental: false Orchestrator: swarm Server: Engine: Version: 18.03.1-ce API version: 1.37 (minimum version 1.12) Go version: go1.9.5 Git commit: 9ee9f40 Built: Thu Apr 26 07:23:58 2018 OS/Arch: linux/amd64 Experimental: false 8.常用Docker命令，更多命令详解，请访问：http://www.docker.org.cn/dockerppt/106.html123456781. docker ps 查看当前正在运行的容器2. docker ps -a 查看所有容器的状态3. docker start/stop id/name 启动/停止某个容器4. docker attach id 进入某个容器(使用exit退出后容器也跟着停止运行)5. docker exec -ti id 启动一个伪终端以交互式的方式进入某个容器（使用exit退出后容器不停止运行）6. docker images 查看本地镜像7. docker rm id/name 删除某个容器8. docker rmi id/name 删除某个镜像","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"微联电召","slug":"微联电召","permalink":"https://xudongye.github.io/xdlog/tags/微联电召/"}]},{"title":"centos7.4 部署 docker，nginx, mysql,redis,activemq","slug":"texin/docker安装mysql-redis-activemq-nginx并挂载配置宿主机","date":"2020-09-10T06:21:07.000Z","updated":"2021-01-05T12:31:47.933Z","comments":true,"path":"texin/docker安装mysql-redis-activemq-nginx并挂载配置宿主机/","link":"","permalink":"https://xudongye.github.io/xdlog/texin/docker安装mysql-redis-activemq-nginx并挂载配置宿主机/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"mysql1234567891011121314151617181920212223242526272829303132333435363738394041#安装dockerdocker pull mysql#先启动docker run --name mysql -p 4148:3306 -e MYSQL_ROOT_PASSWORD=root -d mysql#注意：my.cnf得从docker mysql容器中复制一份到/texin/volume/mysql/conf中docker cp mysql:/etc/mysql/my.cnf /texin/volume/mysql/conf#成功后关闭mysql#重新启动#启动并挂载配置到宿主机docker run -p 4148:3306 --name mysql \\ -v /texin/volume/mysql/log:/var/log/mysql \\ -v /texin/volume/mysql/data:/var/lib/mysql \\ -v /texin/volume/mysql/conf/my.cnf:/etc/mysql/my.cnf \\ -e MYSQL_ROOT_PASSWORD=root \\ -d mysql#进入mysql容器docker exec -it mysql /bin/bash#本地登录mysqlmysql -uroot -proot#查询mysql用户select user,host from mysql.user;#新建用户@&apos;%&apos; 不限ip连接，只要本地则@&apos;localhost&apos;即可create user &apos;weilian&apos;@&apos;%&apos; identified by &apos;weilian2020&apos;;#查看用户密码方式注意远程连接不支持：caching_sha2_password验证方式#我们将他改成msyql_native_passwordalter user &apos;weilian&apos;@&apos;%&apos; identified with mysql_native_password BY &apos;weilian2020&apos;;#刷新flush privileges;#查看用户密码方式，检查是否修改成功select host,user,plugin,authentication_string from mysql.user;#指定数据库texin授权用户grant all privileges on texin.* to &apos;weilian&apos;@&apos;%&apos;;#授予用户所有权限grant all privileges on *.* to &apos;weilian&apos;@&apos;%&apos;;#如果navicat还是连接失败请在挂载主机目录的my.cnf文件中加一句default_authentication_plugin=mysql_native_password#即可实现远程 redis1234567#安装redis默认lasted版本docker pull redis#启动并挂载docker run -p 4149:6379 --name redis \\-v /texin/volume/redis/conf/redis.conf:/etc/redis/redis.conf \\-v /texin/volume/redis/data:/data \\-d redis redis-server --appendonly yes --requirepass &apos;weilian2020&apos; mongo12345678910#安装mongo默认lasted版本docker pull mongo#启动并挂载docker run \\--name mongo \\-p 4147:27017 \\-e MONGO_INITDB_ROOT_USERNAME=&apos;weilian&apos; -e MONGO_INITDB_ROOT_PASSWORD=&apos;weilian2020&apos; \\-v /texin/volume/mongo/data:/data/db \\-v /texin/volume/mongo/configdb:/data/configdb/ \\-d mongo activemq123456789101112131415161718192021222324#搜索activemq版本列表docker search activemq#安装activemqdocker pull webcenter/activemq#启动指定对外端口61617和8167docker run -d --name activemq -p 61617:61616 -p 8162:8161 webcenter/activemq#挂载宿主机#第一步：用临时方式启动一个activemq 容器docker run --user root --privileged=true --rm -ti \\ -v /texin/volume/activemq/conf:/mnt/conf \\ -v /texin/volume/activemq/data:/mnt/data \\ webcenter/activemq /bin/sh#第二步：将容器中的配置目录和数据目录拷贝出去并退出chown activemq:activemq /mnt/confchown activemq:activemq /mnt/datacp -a /opt/activemq/conf/* /mnt/conf/cp -a /opt/activemq/data/* /mnt/data/#第三步：运行activemqdocker run -d --name activemq -p 61617:61616 -p 8162:8161 \\-v /texin/volume/activemq/conf:/opt/activemq/conf \\-v /texin/volume/activemq/data:/opt/activemq/data \\-v /texin/volume/activemq/log:/var/log/activemq \\webcenter/activemq nginx12345678910111213#安装nginx 并配置httpsdocker pull nginx#启动docker run -p 80:80 -p 443:443 --name nginx \\-v /texin/volume/nginx/conf/nginx.conf:/etc/nginx/nginx.conf \\-v /texin/volume/front:/etc/nginx/html \\-v /texin/volume/nginx/logs:/var/log/nginx \\-v /texin/volume/nginx/conf/cert:/etc/nginx/cert \\-d nginx#在宿主机texin/volume/nginx/conf目录下新建nginx.conf#内容(这是最终配置) 前后端分离资源访问 nginx.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; charset utf-8,gbk; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; listen 443 ssl; server_name dev.ruixuelong.com; ssl_certificate /etc/nginx/cert/4670445_dev.ruixuelong.com.pem; ssl_certificate_key /etc/nginx/cert/4670445_dev.ruixuelong.com.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; try_files $uri $uri/ @router; &#125; location /payment/ &#123; root html; try_files $uri $uri/ /payment/@router; #index index.html index.htm; &#125; location /manage/ &#123; root html; try_files $uri $uri/ /manage/@router; #index index.html index.htm; &#125; location @router &#123; rewrite ^.*$ /index.html last; &#125; location /admin/ &#123; set $cors &apos;&apos;; if ($http_origin ~* &apos;https?://(localhost(:8090)?|dev\\.ruixuelong\\.com|ruixuelong\\.com)&apos;) &#123; set $cors &apos;true&apos;; &#125; if ($cors = &apos;true&apos;) &#123; add_header &apos;Access-Control-Allow-Origin&apos; &quot;$http_origin&quot; always; add_header &apos;Access-Control-Allow-Credentials&apos; &apos;true&apos; always; add_header &apos;Access-Control-Allow-Methods&apos; &apos;GET, POST, PUT, DELETE, OPTIONS&apos; always; add_header &apos;Access-Control-Allow-Headers&apos; &apos;Accept,Authorization,Cache-Control,Content-Type,DNT,If-Modified-Since,Keep-Alive,Origin,User-Agent,X-Mx-ReqToken,X-Requested-With&apos; always; &#125; if ($request_method = &apos;OPTIONS&apos;) &#123; return 204; &#125; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://39.99.150.17:8080/admin/; &#125; location /taxi/ &#123; set $cors &apos;&apos;; if ($http_origin ~* &apos;https?://(localhost(:8090)?|dev\\.ruixuelong\\.com|ruixuelong\\.com)&apos;) &#123; set $cors &apos;true&apos;; &#125; if ($cors = &apos;true&apos;) &#123; add_header &apos;Access-Control-Allow-Origin&apos; &quot;$http_origin&quot; always; add_header &apos;Access-Control-Allow-Credentials&apos; &apos;true&apos; always; add_header &apos;Access-Control-Allow-Methods&apos; &apos;GET, POST, PUT, DELETE, OPTIONS&apos; always; add_header &apos;Access-Control-Allow-Headers&apos; &apos;Accept,Authorization,Cache-Control,Content-Type,DNT,If-Modified-Since,Keep-Alive,Origin,User-Agent,X-Mx-ReqToken,X-Requested-With&apos; always; &#125; if ($request_method = &apos;OPTIONS&apos;) &#123; return 204; &#125; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://39.99.150.17:8081/taxi/; &#125; location /texin/ &#123; set $cors &apos;&apos;; if ($http_origin ~* &apos;https?://(localhost(:8090)?|dev\\.ruixuelong\\.com|ruixuelong\\.com)&apos;) &#123; set $cors &apos;true&apos;; &#125; if ($cors = &apos;true&apos;) &#123; add_header &apos;Access-Control-Allow-Origin&apos; &quot;$http_origin&quot; always; add_header &apos;Access-Control-Allow-Credentials&apos; &apos;true&apos; always; add_header &apos;Access-Control-Allow-Methods&apos; &apos;GET, POST, PUT, DELETE, OPTIONS&apos; always; add_header &apos;Access-Control-Allow-Headers&apos; &apos;Accept,Authorization,Cache-Control,Content-Type,DNT,If-Modified-Since,Keep-Alive,Origin,User-Agent,X-Mx-ReqToken,X-Requested-With&apos; always; &#125; if ($request_method = &apos;OPTIONS&apos;) &#123; return 204; &#125; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://39.99.150.17:8082/texin/; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; ###注：所有端口记得要在aliyun安全规则添加规则并开放防火墙端口","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"微联电召","slug":"微联电召","permalink":"https://xudongye.github.io/xdlog/tags/微联电召/"}]},{"title":"基于docker容器部署superm项目","slug":"superm/基于docker容器部署superm项目","date":"2020-05-13T02:43:42.000Z","updated":"2020-12-18T02:51:05.441Z","comments":true,"path":"superm/基于docker容器部署superm项目/","link":"","permalink":"https://xudongye.github.io/xdlog/superm/基于docker容器部署superm项目/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"Docker环境安装 安装yum-utils: 1yum install -y yum-utils device-mapper-persistent-data lvm2 为yum源添加docker仓库位置： 1yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 安装docker： 1yum install docker-ce 启动docker： 1systemctl start docker Mysql安装 下载mysql5.7的docker镜像： 1docker pull mysql:5.7 使用docker命令启动： 123456docker run -p 3306:3306 --name mysql \\-v /mydata/mysql/log:/var/log/mysql \\-v /mydata/mysql/data:/var/lib/mysql \\-v /mydata/mysql/conf:/etc/mysql \\-e MYSQL_ROOT_PASSWORD=root \\-d mysql:5.7 参数说明 -p 3306:3306：将容器的3306端口映射到主机的3306端口 -v /mydata/mysql/conf:/etc/mysql：将配置文件夹挂在到主机 -v /mydata/mysql/log:/var/log/mysql：将日志文件夹挂载到主机 -v /mydata/mysql/data:/var/lib/mysql/：将数据文件夹挂载到主机 -e MYSQL_ROOT_PASSWORD=root：初始化root用户的密码 进入运行mysql的docker容器： 1docker exec -it mysql /bin/bash 使用mysql命令打开客户端： 1mysql -uroot -proot --default-character-set=utf8 创建mall数据库： 1create database mall character set utf8 安装上传下载插件，并将docment/sql/mall.sql上传到Linux服务器上： 1yum -y install lrzsz 将mall.sql文件拷贝到mysql容器的/目录下： 1docker cp /mydata/mall.sql mysql:/ 将sql文件导入到数据库： 12use mall;source /mall.sql; 创建一个reader帐号并修改权限，使得任何ip都能访问： 1grant all privileges on *.* to &apos;reader&apos; @&apos;%&apos; identified by &apos;123456&apos;; Redis安装 下载redis3.2的docker镜像： 1docker pull redis:3.2 使用docker命令启动： 123docker run -p 6379:6379 --name redis \\-v /mydata/redis/data:/data \\-d redis:3.2 redis-server --appendonly yes 进入redis容器使用redis-cli命令进行连接： 1docker exec -it redis redis-cli Nginx安装 下载nginx1.10的docker镜像： 1docker pull nginx:1.10 从容器中拷贝nginx配置 先运行一次容器（为了拷贝配置文件）： 1234docker run -p 80:80 --name nginx \\-v /mydata/nginx/html:/usr/share/nginx/html \\-v /mydata/nginx/logs:/var/log/nginx \\-d nginx:1.10 将容器内的配置文件拷贝到指定目录： 1docker container cp nginx:/etc/nginx /mydata/nginx/ 修改文件名称： 1mv nginx conf 终止并删除容器：12docker stop nginxdocker rm nginx 使用docker命令启动： 123456789101112docker run -p 80:80 --name nginx \\-v /mydata/nginx/html:/usr/share/nginx/html \\-v /mydata/nginx/logs:/var/log/nginx \\-v /mydata/nginx/conf:/etc/nginx \\-d nginx:1.10``` ## RabbitMQ安装* 下载rabbitmq3.7.15的docker镜像：```textdocker pull rabbitmq:3.7.15 使用docker命令启动： 1234docker run -d --name rabbitmq \\--publish 5671:5671 --publish 5672:5672 --publish 4369:4369 \\--publish 25672:25672 --publish 15671:15671 --publish 15672:15672 \\rabbitmq:3.7.15 进入容器并开启管理功能： 12docker exec -it rabbitmq /bin/bashrabbitmq-plugins enable rabbitmq_management 开启防火墙：12firewall-cmd --zone=public --add-port=15672/tcp --permanentfirewall-cmd --reload 访问地址查看是否安装成功：http://106.14.146.164:15672/ 输入账号密码并登录：guest guest 创建帐号并设置其角色为管理员：mall mall 创建一个新的虚拟host为：/mall 点击mall用户进入用户配置页面 给mall用户配置该虚拟host的权限 Elasticsearch安装 下载elasticsearch6.4.0的docker镜像： 1docker pull elasticsearch:6.4.0 修改虚拟内存区域大小，否则会因为过小而无法启动: 1sysctl -w vm.max_map_count=262144 使用docker命令启动： 1234567docker run -p 9200:9200 -p 9300:9300 --name elasticsearch \\-e &quot;ES_JAVA_OPTS=-Xms256m -Xmx256m&quot; \\-e &quot;discovery.type=single-node&quot; \\-e &quot;cluster.name=elasticsearch&quot; \\-v /mydata/elasticsearch/plugins:/usr/share/elasticsearch/plugins \\-v /mydata/elasticsearch/data:/usr/share/elasticsearch/data \\-d elasticsearch:6.4.0 启动时会发现/usr/share/elasticsearch/data目录没有访问权限，只需要修改/mydata/elasticsearch/data目录的权限，再重新启动。 1chmod 777 /mydata/elasticsearch/data/ 安装中文分词器IKAnalyzer，并重新启动： 1234docker exec -it elasticsearch /bin/bash#此命令需要在容器中运行elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.4.0/elasticsearch-analysis-ik-6.4.0.zipdocker restart elasticsearch 开启防火墙： 12firewall-cmd --zone=public --add-port=9200/tcp --permanentfirewall-cmd --reload 访问http://106.14.146.164:9200/ kibana安装 下载kibana6.4.0的docker镜像： 1docker pull kibana:6.4.0 使用docker命令启动： 1234docker run --name kibana -p 5601:5601 \\--link elasticsearch:es \\-e &quot;elasticsearch.hosts=http://106.14.146.164:9200&quot; \\-d kibana:6.4.0 开启防火墙： 12firewall-cmd --zone=public --add-port=5601/tcp --permanentfirewall-cmd --reload 访问http://106.14.146.164:5601/ Mongodb安装 下载mongo3.2的docker镜像： 1docker pull mongo:3.2 使用docker命令启动： 123docker run -p 27017:27017 --name mongo \\-v /mydata/mongo/db:/data/db \\-d mongo:3.2 至此docker全部环境安装完成 使用docker-maven-plugin插件构建docker镜像 Dockerfile方式构建 配置本机DOCKER_HOST环境变量 pom配置12345678910111213141516171819202122232425262728293031323334&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;docker.maven.plugin.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;build-image&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;imageName&gt;superm/$&#123;project.artifactId&#125;:$&#123;project.version&#125;&lt;/imageName&gt; &lt;dockerHost&gt;$&#123;docker.host&#125;&lt;/dockerHost&gt; &lt;dockerDirectory&gt;$&#123;project.basedir&#125;/src/main/docker&lt;/dockerDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 3.Dockerfile配置 123456789101112# 该镜像需要依赖的基础镜像FROM java:8# 将当前目录下的jar包复制到docker容器的/目录下ADD superm-admin-1.0-SNAPSHOT.jar /superm-admin.jar# 运行过程中创建一个superm-admin.jar文件RUN bash -c 'touch /superm-admin.jar'# 声明服务运行在8080端口EXPOSE 8080# 指定docker容器启动时运行jar包ENTRYPOINT [\"java\", \"-jar\",\"/superm-admin.jar\"]# 指定维护者的名字MAINTAINER xudongye 4.运行mvn打包指令5.查看docker镜像5.运行 1234567docker run -p 8080:8080 \\--name superm-admin \\--link mysql:106.14.146.164 \\--link redis:106.14.146.164 \\-v /etc/localtime:/etc/localtime \\-v /mydata/app/admin/logs:/var/logs \\-d superm/superm-admin:1.0-SNAPSHOT","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"商城后台","slug":"商城后台","permalink":"https://xudongye.github.io/xdlog/tags/商城后台/"}]},{"title":"支付宝多租户模式下支付功能实现","slug":"aihotel/支付宝多租户模式下支付功能实现","date":"2020-01-08T06:07:56.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"aihotel/支付宝多租户模式下支付功能实现/","link":"","permalink":"https://xudongye.github.io/xdlog/aihotel/支付宝多租户模式下支付功能实现/","excerpt":"","keywords":[{"name":"支付系统","slug":"支付系统","permalink":"https://xudongye.github.io/xdlog/categories/支付系统/"}],"text":"多账户支付系统该如何实现？需求分析 由于智能酒店业务不断更新，随之而来的需求迭代不断增加。自从酒店商城项目上线之后，吸引了很多酒店热情入驻，既然是酒店那么支付是必不可少的功能，原来的单机模式显然已经无法满足各个酒店方需求。单机模式下商城扫码支付，收款方都是阳淳账户代收，然后再打款到各个酒店平台，对账-开发票各种流程。财务麻烦，领导嫌弃，那么就做成多租户模式吧。为酒店配置各自收款账户，商品捆绑酒店编码（唯一标识）下单到支付即可指定对应收款参数，生成收款码进行扫码支付，若未设置，则默认阳淳。典型的Software-as-a-Service系统。 er模型 order为订单表，关联商品good_id，酒店org_id。 accountPayOrder为内部订单表，关联orderNo（businessId）,支付回调支付结果存储，已经支付网关，支付方式等信息（支付方式：alipay,wxpay，pointpay） accountAliPay为支付账户参数表， 存放各个酒店设置支付宝收款账户配置信息。 流程 支付结果回调就不赘述了,通过预下单产生的outTradeNo查询对应订单所在PayAccount","categories":[{"name":"支付系统","slug":"支付系统","permalink":"https://xudongye.github.io/xdlog/categories/支付系统/"}],"tags":[{"name":"aiHotel","slug":"aiHotel","permalink":"https://xudongye.github.io/xdlog/tags/aiHotel/"}]},{"title":"利用JXLS2.4实现exel导出","slug":"design/利用JXLS2-4实现exel导出","date":"2019-12-27T06:11:24.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"design/利用JXLS2-4实现exel导出/","link":"","permalink":"https://xudongye.github.io/xdlog/design/利用JXLS2-4实现exel导出/","excerpt":"","keywords":[{"name":"excel","slug":"excel","permalink":"https://xudongye.github.io/xdlog/categories/excel/"}],"text":"java集成jxls实现Excle导出功能 项目需求(场景描述)：酒店租用智能生成设备佣金账单 酒店安装智能设备后，设备每5分钟上报一次状态信息，后台接到上报信息之后并缓存下设备连续在线时间 连续在线(duration)满4小时(timeInterval = currentTime-lastReportTime &gt;= 10min,duration=0)，记录一笔设备使用佣金 每一个酒店organization,不同房间设备在同时上报 账单范围以及单笔账单归属日期，以开始时间(startTime)为参考值,条件：startTime &gt; 12:00,则todayDate - 1 day(即startTime=2019-12-27 11:59:59,则此笔账单recordDate=2019-12-26)。 账单周期(周（每周二凌晨2点统计一次上周账单），月（每月2号凌晨2点统计一次上月账单）)starDate-endDate 回归正题，集成jxls,maven项目为例 依赖 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.jxls&lt;/groupId&gt; &lt;artifactId&gt;jxls&lt;/artifactId&gt; &lt;version&gt;2.4.6&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.jxls&lt;/groupId&gt; &lt;artifactId&gt;jxls-poi&lt;/artifactId&gt; &lt;version&gt;1.0.9&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.jxls&lt;/groupId&gt; &lt;artifactId&gt;jxls-jexcel&lt;/artifactId&gt; &lt;version&gt;1.0.6&lt;/version&gt;&lt;/dependency&gt; 代码： 1234567891011121314151617181920212223242526272829303132333435363738/** * @author yexudong * @date 2019/1/11 16:23 */public class BillExcelExport &#123; private static String templateFileName = \"D:\\\\yc_learn_project\\\\jxls\\\\jxls-examples\\\\src\\\\main\\\\resources\\\\templates\\\\对账单.xlsx\"; private static String destFileName = \"D:\\\\var\\\\yangchun_对账单.xlsx\"; public static void main(String[] args) throws IOException, ParsePropertyException, InvalidFormatException &#123; if (args.length &gt;= 2) &#123; templateFileName = args[0]; destFileName = args[1]; &#125; YoungchAccount account = new YoungchAccount(\"阳淳股份\", \"123245335345346\", \"中国银行\"); BillStat billStat = new BillStat(\"演示箱\", 1000.0D, \"231234\", 1D, \"2018-12-31\", \"2019-01-06\", 1000.0D, \"2018-01-07 02:00:00\", 1); BillDepartment department = new BillDepartment(\"阳淳财务对账单\", account, billStat); department.addRecord(new BillRecordDetail(\"s213aeqwdhb123123\", \"101\", \"2018-12-31 12:00:00\", \"2019-01-01\", 1, 12.0, 12.0, \"device\")); department.addRecord(new BillRecordDetail(\"s213aeqwdhb123123\", \"101\", \"2018-12-31 12:00:00\", \"2019-01-01\", 1, 12.0, 12.0, \"device\")); department.addRecord(new BillRecordDetail(\"s213aeqwdhb123123\", \"101\", \"2018-12-31 12:00:00\", \"2019-01-01\", 1, 12.0, 12.0, \"device\")); department.addRecord(new BillRecordDetail(\"s213aeqwdhb123123\", \"101\", \"2018-12-31 12:00:00\", \"2019-01-01\", 1, 12.0, 12.0, \"device\")); department.addRecord(new BillRecordDetail(\"s213aeqwdhb123123\", \"101\", \"2018-12-31 12:00:00\", \"2019-01-01\", 1, 12.0, 12.0, \"device\")); department.addRecord(new BillRecordDetail(\"s213aeqwdhb123123\", \"101\", \"2018-12-31 12:00:00\", \"2019-01-01\", 1, 12.0, 12.0, \"device\")); Map beans = new HashMap(); beans.put(\"bill\", department); writeExcel(beans, destFileName, templateFileName); &#125; public static void writeExcel(Map beans, String destFileName, String templateFileName) throws IOException, InvalidFormatException &#123; XLSTransformer transformer = new XLSTransformer();// transformer.registerRowProcessor(new StyleRowProcessor(\"bill.records\")); transformer.transformXLS(templateFileName, beans, destFileName); &#125;&#125; 调用： 1234567891011121314151617181920212223242526272829303132333435363738394041@ApiOperation( value = \"管理员生成周期账单明细excel表单\", notes = \"生成周期账单\", response = ApiResponseBody.class)@ApiImplicitParam(name = \"u_id\", value = \"调试模式\", paramType = \"query\", dataType = \"String\", defaultValue = \"1\")@RequestMapping(value = \"/period-excel\", method = RequestMethod.GET)@UserAuthenticationRequired( needPermission = &#123;RoleConstants.Permissions.CREATE_UPDATE_ONLY&#125;, doLog = true, moduleName = \"bill\", operateType = \"get\", description = \"生成对账单#&#123;#billId&#125;excel\")public ResponseEntity getExcel(HttpServletRequest request, HttpServletResponse response, UserAccessToken uat, @RequestParam String billId) throws Exception &#123; ApiResponseBody&lt;String&gt; apiResponseBody = new ApiResponseBody&lt;&gt;(); try &#123; //导出数据bean BillDepartment department = billDepartment(billId); Map beans = new HashMap(); beans.put(\"bill\", department); String destFileName = simpleDateFormat.format(new Date()) + fileName.replace(\"&#123;&#123;orgName&#125;&#125;\", department.getBillStat().getOrgName()); //模板路径 String templateFileName = delegate.getConfiguration().getFile().getExcelPath() + \"bill_template.xlsx\"; BillExcelExport.writeExcel(beans, delegate.getConfiguration().getFile().getExcelPath() + destFileName, templateFileName); //拼装excel网络路径 String excelUrl = delegate.getConfiguration().getFile(). getUrlPrefix().replace(\"&#123;&#123;media&#125;&#125;\", \"excel\") + destFileName; billService.updateExcelUrl(billId, excelUrl); apiResponseBody.setCode(200); apiResponseBody.setMessage(\"success!\"); apiResponseBody.setData(excelUrl); &#125; catch (IllegalArgumentException ie) &#123; apiResponseBody.setCode(400); apiResponseBody.setMessage(ie.getMessage()); &#125; return new ResponseEntity(apiResponseBody, HttpStatus.OK);&#125; excel模板 jxls多sheet导出 智能酒店安装设备流程之勘店 在成为智能酒店设备之前，实地勘察酒店环境是非常有必要的 勘店内容划分为： 酒店基本信息 电视部分 网络部分 强电部分 窗帘部分 空调部分 模板批注才是精髓 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108/** * @author yexudong * @date 2019/9/10 10:02 */public class JxlsUtils &#123; static &#123; //添加自定义指令（可覆盖jxls原指令） XlsCommentAreaBuilder.addCommandMapping(\"image\", ImageCommand.class); XlsCommentAreaBuilder.addCommandMapping(\"each\", EachCommand.class); XlsCommentAreaBuilder.addCommandMapping(\"merge\", MergeCommand.class); XlsCommentAreaBuilder.addCommandMapping(\"link\", LinkCommand.class); &#125; public static void exportExcel(InputStream is, OutputStream os, Map&lt;String, Object&gt; model) throws IOException &#123; Context context = PoiTransformer.createInitialContext(); if (model != null) &#123; for (Map.Entry&lt;String, Object&gt; entry : model.entrySet()) &#123; context.putVar(entry.getKey(), entry.getValue()); &#125; &#125; JxlsHelper jxlsHelper = JxlsHelper.getInstance(); Transformer transformer = jxlsHelper.createTransformer(is, os); //获得配置 JexlExpressionEvaluator evaluator = (JexlExpressionEvaluator) transformer.getTransformationConfig().getExpressionEvaluator(); //设置静默模式，不报警告 evaluator.getJexlEngine().setSilent(true); //函数强制，自定义功能 Map&lt;String, Object&gt; funcs = new HashMap&lt;String, Object&gt;(); funcs.put(\"jx\", new JxlsUtils()); //添加自定义功能 evaluator.getJexlEngine().setFunctions(funcs); //必须要这个，否者表格函数统计会错乱 jxlsHelper.setUseFastFormulaProcessor(false).processTemplate(context, transformer); &#125; public static void exportExcel(File xls, File out, Map&lt;String, Object&gt; model) throws FileNotFoundException, IOException &#123; exportExcel(new FileInputStream(xls), new FileOutputStream(out), model); &#125; public static void exportExcel(String templatePath, OutputStream os, Map&lt;String, Object&gt; model) throws Exception &#123; File template = getTemplate(templatePath); if (template != null) &#123; exportExcel(new FileInputStream(template), os, model); &#125; else &#123; throw new Exception(\"Excel 模板未找到。\"); &#125; &#125; //获取jxls模版文件 public static File getTemplate(String path) &#123; File template = new File(path); if (template.exists()) &#123; return template; &#125; return null; &#125; // 日期格式化 public String dateFmt(Date date, String fmt) &#123; if (date == null) &#123; return \"\"; &#125; try &#123; SimpleDateFormat dateFmt = new SimpleDateFormat(fmt); return dateFmt.format(date); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return \"\"; &#125; // if判断 public Object ifelse(boolean b, Object o1, Object o2) &#123; return b ? o1 : o2; &#125; /** * 图片转为byte数组 * * @param path * @return */ public static byte[] image2byte(String path) &#123; byte[] data = null; URL url = null; InputStream input = null; try &#123; url = new URL(path); HttpURLConnection httpUrl = (HttpURLConnection) url.openConnection(); httpUrl.connect(); httpUrl.getInputStream(); input = httpUrl.getInputStream(); ByteArrayOutputStream output = new ByteArrayOutputStream(); byte[] buf = new byte[1024]; int numBytesRead = 0; while ((numBytesRead = input.read(buf)) != -1) &#123; output.write(buf, 0, numBytesRead); &#125; data = output.toByteArray(); output.close(); input.close(); return data; &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125;&#125; 调用 123456789101112131415161718192021222324private String createExcel(CollectExcelBean excelBean) &#123; String excelUrl = null; try &#123; String destFileName = fileName.replace(\"&#123;&#123;hotelName&#125;&#125;\", excelBean.getHotelName()) .replace(\"&#123;&#123;roomNo&#125;&#125;\", excelBean.getRoom().getRoomNo()) .replace(\"&#123;&#123;timestamp&#125;&#125;\", String.valueOf(System.currentTimeMillis())); String templatePath = delegate.getConfiguration().getFile().getExcelPath() + \"collect_template.xlsx\"; LOGGER.info(\"template excel dest file path: &#123;&#125; \", templatePath); Map&lt;String, Object&gt; data = new HashMap&lt;&gt;(); data.put(\"collect\", excelBean); OutputStream os = new FileOutputStream(delegate.getConfiguration().getFile().getExcelPath() + destFileName); //调用封装的工具类，传入模板路径，输出流，和装有数据的Map,按照模板导出 JxlsUtils.exportExcel(templatePath, os, data); os.close(); excelUrl = delegate.getConfiguration().getFile(). getUrlPrefix().replace(\"&#123;&#123;media&#125;&#125;\", \"excel\") + destFileName; excelBean.setExcelUrl(excelUrl); LOGGER.info(\"excel dest file &#123;&#125; generate new excel &#123;&#125; success!\", destFileName, excelUrl); &#125; catch (Exception e) &#123; e.printStackTrace(); LOGGER.error(\" excel generate failure! reason :&#123;&#125;\", e.getMessage()); &#125; return excelUrl; &#125; 实体部分参数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157public class CollectExcelBean &#123; private String excelUrl; private String exportPerson; private Long exportPersonId; private String hotelName; private String address; //施工房间数 private int roomCount; //酒店总房间数 private int roomTotalCount; private String pmsName; //对接人 private String pmsMan; //服务器，局域网，云端 private String pmsServer; //房间信息 private RoomBean room; private TvBean tv; private NetworkBean network; private CurtainBean curtain; private VrvBean vrv; private ElecBean elec; public ElecBean getElec() &#123; return elec; &#125; public void setElec(ElecBean elec) &#123; this.elec = elec; &#125; public VrvBean getVrv() &#123; return vrv; &#125; public void setVrv(VrvBean vrv) &#123; this.vrv = vrv; &#125; public CurtainBean getCurtain() &#123; return curtain; &#125; public void setCurtain(CurtainBean curtain) &#123; this.curtain = curtain; &#125; public NetworkBean getNetwork() &#123; return network; &#125; public void setNetwork(NetworkBean network) &#123; this.network = network; &#125; public TvBean getTv() &#123; return tv; &#125; public void setTv(TvBean tv) &#123; this.tv = tv; &#125; public String getExcelUrl() &#123; return excelUrl; &#125; public void setExcelUrl(String excelUrl) &#123; this.excelUrl = excelUrl; &#125; public String getExportPerson() &#123; return exportPerson; &#125; public void setExportPerson(String exportPerson) &#123; this.exportPerson = exportPerson; &#125; public Long getExportPersonId() &#123; return exportPersonId; &#125; public void setExportPersonId(Long exportPersonId) &#123; this.exportPersonId = exportPersonId; &#125; public String getHotelName() &#123; return hotelName; &#125; public void setHotelName(String hotelName) &#123; this.hotelName = hotelName; &#125; public String getAddress() &#123; return address; &#125; public void setAddress(String address) &#123; this.address = address; &#125; public int getRoomCount() &#123; return roomCount; &#125; public void setRoomCount(int roomCount) &#123; this.roomCount = roomCount; &#125; public int getRoomTotalCount() &#123; return roomTotalCount; &#125; public void setRoomTotalCount(int roomTotalCount) &#123; this.roomTotalCount = roomTotalCount; &#125; public String getPmsName() &#123; return pmsName; &#125; public void setPmsName(String pmsName) &#123; this.pmsName = pmsName; &#125; public String getPmsMan() &#123; return pmsMan; &#125; public void setPmsMan(String pmsMan) &#123; this.pmsMan = pmsMan; &#125; public String getPmsServer() &#123; return pmsServer; &#125; public void setPmsServer(String pmsServer) &#123; this.pmsServer = pmsServer; &#125; public RoomBean getRoom() &#123; return room; &#125; public void setRoom(RoomBean room) &#123; this.room = room; &#125;&#125; 图片属性 图片链接一定要转成byte[],否则无法显示","categories":[{"name":"excel","slug":"excel","permalink":"https://xudongye.github.io/xdlog/categories/excel/"}],"tags":[{"name":"JXLS","slug":"JXLS","permalink":"https://xudongye.github.io/xdlog/tags/JXLS/"}]},{"title":"利用DFA算法实现敏感词过滤","slug":"algorithm/利用DFA算法实现敏感词过滤","date":"2019-12-26T06:58:19.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"algorithm/利用DFA算法实现敏感词过滤/","link":"","permalink":"https://xudongye.github.io/xdlog/algorithm/利用DFA算法实现敏感词过滤/","excerpt":"","keywords":[{"name":"算法","slug":"算法","permalink":"https://xudongye.github.io/xdlog/categories/算法/"}],"text":"DFA算法简介 敏感词过滤是一个网站必不可少的功能，那么如何设计一个科学并且高效过滤算法是非要有必要的。一般的开发人员首先考虑的肯定是简单的匹配规则，可以实现，但是效率很低。再高级一点的就是正则表达式，但终究都不可取。 DFA全称(Deterministic Finite Automaton)，即确定有穷自动机。 特征：有一个有序集集合和一些从一个状态通向另一个状态的边，每条边上标记一个符号，其中状态有初态和终态。 区别：不同于不确定的有限自动机，DFA中不会从同一状态出发的两边标志有相同的符号。 实现：通过event和当前state得到下一个state，即event+state=nextstate （S、U、V、Q）都是状态，小写字母a、b为动作 关系如下： 12 a b b S -----&gt; U S -----&gt; V U -----&gt; V 在DFA算法里面几乎没有什么计算 Java实现DFA算法实现敏感词过滤 我们可以认为，通过S query U、V，通过U query V、P，通过V query U P。通过这样的转变我们可以将状态的转换转变为使用Java集合的查找。 举个栗子：假设我们的敏感词库里面有日本人，日本鬼子，毛.泽.东 首先：query 日 —&gt; {本}、query 本 —&gt;{人、鬼子}、query 人 —&gt;{null}、query 鬼 —&gt; {子}。形如下结构: 这样我们就将我们的敏感词库构建成了一个类似与一颗一颗的树，这样我们判断一个词是否为敏感词时就大大减少了检索的匹配范围。比如我们要判断日本人，根据第一个字我们就可以确认需要检索的是那棵树，然后再在这棵树中进行检索。 但是如何来判断一个敏感词已经结束了呢？利用标识位来判断。所以对于这个关键是如何来构建一棵棵这样的敏感词树。下面我已Java中的HashMap为例来实现DFA算法。具体过程如下： 日本人，日本鬼子为例 1、在hashMap中查询“日”看其是否在hashMap中存在，如果不存在，则证明已“日”开头的敏感词还不存在，则我们直接构建这样的一棵树。跳至3。 2、如果在hashMap中查找到了，表明存在以“日”开头的敏感词，设置hashMap = hashMap.get(“日”)，跳至1，依次匹配“本”、“人”。 3、判断该字是否为该词中的最后一个字。若是表示敏感词结束，设置标志位isEnd = 1，否则设置标志位isEnd = 0； 程序如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * 读取敏感词库，将敏感词放入HashSet中，构建一个DFA算法模型：&lt;br&gt; * 中 = &#123; * isEnd = 0 * 国 = &#123;&lt;br&gt; * isEnd = 1 * 人 = &#123;isEnd = 0 * 民 = &#123;isEnd = 1&#125; * &#125; * 男 = &#123; * isEnd = 0 * 人 = &#123; * isEnd = 1 * &#125; * &#125; * &#125; * &#125; * 五 = &#123; * isEnd = 0 * 星 = &#123; * isEnd = 0 * 红 = &#123; * isEnd = 0 * 旗 = &#123; * isEnd = 1 * &#125; * &#125; * &#125; * &#125; * @param keyWordSet 敏感词库 * @version 1.0 */ @SuppressWarnings(&#123; \"rawtypes\", \"unchecked\" &#125;) private void addSensitiveWordToHashMap(Set&lt;String&gt; keyWordSet) &#123; sensitiveWordMap = new HashMap(keyWordSet.size()); //初始化敏感词容器，减少扩容操作 String key = null; Map nowMap = null; Map&lt;String, String&gt; newWorMap = null; //迭代keyWordSet Iterator&lt;String&gt; iterator = keyWordSet.iterator(); while(iterator.hasNext())&#123; key = iterator.next(); //关键字 nowMap = sensitiveWordMap; for(int i = 0 ; i &lt; key.length() ; i++)&#123; char keyChar = key.charAt(i); //转换成char型 Object wordMap = nowMap.get(keyChar); //获取 if(wordMap != null)&#123; //如果存在该key，直接赋值 nowMap = (Map) wordMap; &#125; else&#123; //不存在则，则构建一个map，同时将isEnd设置为0，因为他不是最后一个 newWorMap = new HashMap&lt;String,String&gt;(); newWorMap.put(\"isEnd\", \"0\"); //不是最后一个 nowMap.put(keyChar, newWorMap); nowMap = newWorMap; &#125; if(i == key.length() - 1)&#123; nowMap.put(\"isEnd\", \"1\"); //最后一个 &#125; &#125; &#125; &#125; 运行得到的hashMap结构如下： &#123;五=&#123;星=&#123;红=&#123;isEnd=0, 旗=&#123;isEnd=1&#125;&#125;, isEnd=0&#125;, isEnd=0&#125;, 中=&#123;isEnd=0, 国=&#123;isEnd=0, 人=&#123;isEnd=1&#125;, 男=&#123;isEnd=0, 人=&#123;isEnd=1&#125;&#125;&#125;&#125;&#125; 如何实现检索： 假设我们检索“中国人民万岁” 1、第一个字“中”，我们在hashMap中可以找到。得到一个新的map = hashMap.get(“”)。 2、如果map == null，则不是敏感词。否则跳至3 3、获取map中的isEnd，通过isEnd是否等于1来判断该词是否为最后一个。如果isEnd == 1表示该词为敏感词，否则跳至1。 通过这个步骤我们可以判断“中国人民”为敏感词，但是如果我们输入“中国女人”则不是敏感词了。 1234567891011121314151617181920212223242526272829303132333435/** * 检查文字中是否包含敏感字符，检查规则如下：&lt;br&gt; * @param txt * @param beginIndex * @param matchType * @return，如果存在，则返回敏感词字符的长度，不存在返回0 * @version 1.0 */ @SuppressWarnings(&#123; \"rawtypes\"&#125;) public int CheckSensitiveWord(String txt,int beginIndex,int matchType)&#123; boolean flag = false; //敏感词结束标识位：用于敏感词只有1位的情况 int matchFlag = 0; //匹配标识数默认为0 char word = 0; Map nowMap = sensitiveWordMap; for(int i = beginIndex; i &lt; txt.length() ; i++)&#123; word = txt.charAt(i); nowMap = (Map) nowMap.get(word); //获取指定key if(nowMap != null)&#123; //存在，则判断是否为最后一个 matchFlag++; //找到相应key，匹配标识+1 if(\"1\".equals(nowMap.get(\"isEnd\")))&#123; //如果为最后一个匹配规则,结束循环，返回匹配标识数 flag = true; //结束标志位为true if(SensitivewordFilter.minMatchTYpe == matchType)&#123; //最小规则，直接返回,最大规则还需继续查找 break; &#125; &#125; &#125; else&#123; //不存在，直接返回 break; &#125; &#125; if(matchFlag &lt; 2 &amp;&amp; !flag)&#123; matchFlag = 0; &#125; return matchFlag; &#125; 测试： 12345678910111213public static void main(String[] args) &#123; SensitivewordFilter filter = new SensitivewordFilter(); System.out.println(\"敏感词的数量：\" + filter.sensitiveWordMap.size()); String string = \"太多的伤感情怀也许只局限于饲养基地 荧幕中的情节，主人公尝试着去用某种方式渐渐的很潇洒地释自杀指南怀那些自己经历的伤感。\" + \"然后法.轮.功 我们的扮演的角色就是跟随着主人公的喜红客联盟 怒哀乐而过于牵强的把自己的情感也附加于银幕情节中，然后感动就流泪，\" + \"难过就躺在某一个人的怀里尽情的阐述心扉或者手机卡复制器一个人一杯红酒一部电影在夜三.级.片 深人静的晚上，关上电话静静的发呆着。\"; System.out.println(\"待检测语句字数：\" + string.length()); long beginTime = System.currentTimeMillis(); Set&lt;String&gt; set = filter.getSensitiveWord(string, 1); long endTime = System.currentTimeMillis(); System.out.println(\"语句中包含敏感词的个数为：\" + set.size() + \"。包含：\" + set); System.out.println(\"总共消耗时间为：\" + (endTime - beginTime)); &#125; 敏感词库","categories":[{"name":"算法","slug":"算法","permalink":"https://xudongye.github.io/xdlog/categories/算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://xudongye.github.io/xdlog/tags/数据结构/"}]},{"title":"CentOs7.4安装jdk1.8-tomcat8-activemq","slug":"linux/CentOs7.4安装jdk1.8-tomcat8-activemq","date":"2019-12-05T07:31:25.000Z","updated":"2020-12-18T02:51:05.441Z","comments":true,"path":"linux/CentOs7.4安装jdk1.8-tomcat8-activemq/","link":"","permalink":"https://xudongye.github.io/xdlog/linux/CentOs7.4安装jdk1.8-tomcat8-activemq/","excerpt":"","keywords":[{"name":"Linux","slug":"Linux","permalink":"https://xudongye.github.io/xdlog/categories/Linux/"}],"text":"安装JDK8 jdk-8u211-linux-x64.tar.tar.gz 选择与自己系统相匹配版本，我的是centOs7 64位，选择的是以tar.gz结尾 通过FTP工具将下载好的jdk-8u211-linux-x64.tar.gz传输到/khgo/volume/service 解压 1tar -zxvf jdk-8u211-linux-x64.tar.tar.gz 编辑/etc/profile 生效命令： 1source /etc/profile 测试命令 1java -version 出现上面的信息,说明安装成功！ 安装Tomcat8 apache-tomcat-8.5.47.tar.gz 12cd /khgo/volume/service/wget https://archive.apache.org/dist/tomcat/tomcat-8/v8.5.47/bin/apache-tomcat-8.5.47.tar.gz 解压安装包 1tar -zxvf apache-tomcat-8.5.47.tar.gz 设置为系统服务 123456789101112131415# tomcat8080.service# vim /lib/systemd/system/tomcat8080.service[Unit]Description=TomcatAfter=syslog.target network.target remote-fs.target nss-lookup.target[Service]Type=oneshotExecStart=/khgo/volume/service/apache-tomcat-8.5.47/bin/startup.shExecStop=/khgo/volume/service/apache-tomcat-8.5.47/bin/shutdown.shExecReload=/bin/kill -s HUP $MAINPIDRemainAfterExit=yes[Install]WantedBy=multi-user.target 编辑catalina.sh，由于Tomcat默认情况下会用系统的环境变量中找到JAVA_HOME和JRE_HOME。但是有的时候我们需要不同版本的JDK共存。 123456export JAVA_HOME=/khgo/volume/service/jdk1.8.0_231;#或用的全一点如下设置（用上面只设置一个JAVA_HOME足够了）：export JAVA_HOME=/usr/local/java/jdk1.8.0_231export JRE_HOME=/usr/local/java/jdk1.8.0_231/jreexport PATH=$PATH:/usr/local/java/jdk1.8.0_231/binexport CLASSPATH=/usr/local/java/jdk1.8.0_231/lib:/usr/local/java/jdk1.8.0_231/jre/lib 如图： 添加完即可 1systemctl enable|status|start|restart|stop tomcat8080.service 安装成功！ Tomcat8优化 元素属性： 12345678910111213141516171819202122232425&lt;Executor name=&quot;tomcatThreadPool&quot; &lt;!--线程名称--&gt; namePrefix=&quot;catalina-exec-&quot; maxThreads=&quot;150&quot; &lt;!--最大处理连接数线程--&gt; minSpareThreads=&quot;4&quot; /&gt; &lt;!--保留最少线程数--&gt;&lt;!-- 将原有的Connector 替换为带有线程池的Connector如下,其实servlet.xml已经有了,只要打开就可以了,将原来的去掉 --&gt;&lt;Connector port=&quot;8080&quot; &lt;!-- Connector创建server socket并等待连接的TCP端口号。操作系统在特定的IP地址上只允许一个服务器应用程序监听特定的端口 --&gt; maxThreads=&quot;10000&quot; &lt;!-- 该线程池可以容纳的最大线程数、默认值：200 --&gt; executor=&quot;tomcatThreadPool&quot; protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot; &lt;!-- 为了使用HTTP处理器，该属性值必须为HTTP/1.1（缺省值） --&gt; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; &lt;!-- 如果Connector支持非SSL请求，在收到一个要求使用SSL传输的请求以后，Catalina会自动将该请求重定向到这里指定的端口号 --&gt; maxConnections=&quot;900&quot; enableLookups=&quot;false&quot; &lt;!-- 如果希望调用request.getRemoteHost()进行DNS查询，以返回远程客户的实际主机名，将enableLookups设为true。如果希望忽略DNS查询，仅仅返回IP地址，设为false（这样提高了性能）。缺省情况下，DNS查询是使能的 --&gt; acceptCount=&quot;700&quot; &lt;!-- 接受最大并发数量 ,超过这个数量就会返回连接被拒绝 --&gt; maxPostSize=&quot;10485760&quot; disableUploadTimeout=&quot;true&quot; compression=&quot;on&quot; compressionMinSize=&quot;2048&quot; maxProcessors=&quot;1000&quot; &lt;!-- 同时处理请求的最大数 --&gt; minProcessors=&quot;5&quot; &lt;!-- 同时处理请求的最小数 --&gt; maxHttpHeaderSize=&quot;81920&quot; compressableMimeType=&quot;text/html,text/xml,text/plain,text/css,text/javascript,application/javascript&quot; URIEncoding=&quot;UTF-8&quot; /&gt; 安装activemq 下载apache-activemq-5.15.10-bin.tar.gz 解压 1tar -zxvf apache-activemq-5.15.10-bin.tar.gz 防火墙的设置添加8161和61616端口号 配置系统服务 12345678910111213141516#/lib/systemd/system/activemq.service[Unit]Description=ActivemqAfter=network.target[Service]Type=forkingPIDFile=/khgo/volume/service/apache-activemq-5.15.10/data/activemq.pidExecStart=/khgo/volume/service/apache-activemq-5.15.10/bin/activemq startExecReload=/khgo/volume/service/apache-activemq-5.15.10/bin/activemq restartExecStop=/khgo/volume/service/apache-activemq-5.15.10/bin/activemq stopPrivateTmp=true[Install]WantedBy=mutli-user.target 报错：ERROR: Configuration variable JAVA_HOME or JAVACMD is not defined correctly解决： 12345vim bin/activemq#在第2行加入export JAVA_HOME=/khgo/volume/service/jdk1.8.0_231;#成功启动systemctl start activemq.service 成功！","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xudongye.github.io/xdlog/categories/Linux/"}],"tags":[{"name":"系统服务","slug":"系统服务","permalink":"https://xudongye.github.io/xdlog/tags/系统服务/"},{"name":"CentOs7.4","slug":"CentOs7-4","permalink":"https://xudongye.github.io/xdlog/tags/CentOs7-4/"},{"name":"JDK8","slug":"JDK8","permalink":"https://xudongye.github.io/xdlog/tags/JDK8/"},{"name":"Tomcat8","slug":"Tomcat8","permalink":"https://xudongye.github.io/xdlog/tags/Tomcat8/"},{"name":"Activemq","slug":"Activemq","permalink":"https://xudongye.github.io/xdlog/tags/Activemq/"}]},{"title":"Centos7.4安装nginx-mysql-redis","slug":"linux/CentOs7.4安装nginx-mysql-redis","date":"2019-12-03T02:38:11.000Z","updated":"2020-12-18T02:51:05.441Z","comments":true,"path":"linux/CentOs7.4安装nginx-mysql-redis/","link":"","permalink":"https://xudongye.github.io/xdlog/linux/CentOs7.4安装nginx-mysql-redis/","excerpt":"","keywords":[{"name":"Linux","slug":"Linux","permalink":"https://xudongye.github.io/xdlog/categories/Linux/"}],"text":"修改hostname 修改/etc/hostname文件内容：$ sudo vim /etc/hostname 将里面的内容修改为新的主机名称 修改/etc/hosts文件：$ sudo vim /etc/hosts 将127.0.0.1这一行的内容修改为新的主机名称 重启 安装 nginx-1.17.0.tar.gz nginx 的 http 模块使用 pcre 来解析正则表达式，所以需要在 linux 上安装 pcre 库，pcre-devel 是使用 pcre 开发的一个二次开发库 1yum install -y pcre pcre-devel zlib 库提供了很多种压缩和解压缩的方式， nginx 使用 zlib 对 http 包的内容进行 gzip ，所以需要在 Centos 上安装 zlib 库 1yum install -y zlib zlib-devel 如果有需要，根据error提示可能还需要GCC和OpenSSL 12yum install gcc-c++yum install -y openssl openssl-devel 开始安装nginx,1.17.0这个是目前最新版本 1wget -c https://nginx.org/download/nginx-1.17.0.tar.gz 解压并进入nginx目录 12tar -zxvf nginx-1.17.0.tar.gzcd nginx-1.17.0 使用nginx的默认配置 1./configure 查找安装路径 1whereis nginx 安装好后，把nginx添加到系统服务中 1234567891011121314# 添加nginx.service# vim /lib/systemd/system/nginx.service[Unit]Description=nginx serviceAfter=network.target [Service] Type=forking# 路径对应安装路径ExecStart=/usr/local/nginx/sbin/nginxExecReload=/usr/local/nginx/sbin/nginx -s reloadExecStop=/usr/local/nginx/sbin/nginx -s quitPrivateTmp=true [Install] WantedBy=multi-user.target 添加完成之后即可 1systemctl enable|status|start|restart|stop nginx.service Nginx部署前后端分离服务以及配置 在前后端分离端项目里，前端的代码会被打包成为纯静态文件。使用 Nginx的目的就是让静态文件运行起服务，由于后端的接口也是分离的，直接请求可能会产生跨域问题，此时就需要Nginx转发代理后端接口。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980user root; #指定 Nginx Worker 进程运行用户以及用户组worker_processes auto; #启动进程error_log /var/log/nginx/error.log; #全局错误日志#error_log logs/error.log notice;#error_log logs/error.log info;pid /run/nginx.pid; #PID文件events &#123; worker_connections 1024; #单个后台worker process进程的最大并发链接数&#125;http &#123; include mime.types; default_type application/octet-stream; gzip on; #开启gzip压缩 gzip_min_length 1k; #设置对数据启用压缩的最少字节数 gzip_buffers 4 16k; gzip_http_version 1.0; gzip_comp_level 6; #设置数据的压缩等级,等级为1-9，压缩比从小到大 gzip_types text/plain text/css text/javascript application/json application/javascript application/x-javascript application/xml; #设置需要压缩的数据格式 gzip_vary on; server &#123; listen 80; #侦听80端口,并为默认服务,default_server只能有一个 server_name www.kuanghuan.shop; #服务域名,可以有多个,用空格隔开 root /khgo/volume/project/front; ##定义服务器的默认网站根目录位置 error_page 404 /404.html; #将404错误页面重定向到index.html可以解决history模式访问不到页面问题 location / &#123; root html; index index.html index.htm; &#125; location /storemanager/ &#123; try_files $uri $uri/ /storemanager/index.html; &#125; location /learn/ &#123; set $cors &apos;&apos;; if ($http_origin ~* &apos;https?://(localhost(:8090)?|www\\.kuanghuan\\.shop|kuanghuan\\.shop)&apos;) &#123; set $cors &apos;true&apos;; &#125; if ($cors = &apos;true&apos;) &#123; add_header &apos;Access-Control-Allow-Origin&apos; &quot;$http_origin&quot; always; add_header &apos;Access-Control-Allow-Credentials&apos; &apos;true&apos; always; add_header &apos;Access-Control-Allow-Methods&apos; &apos;GET, POST, PUT, DELETE, OPTIONS&apos; always; add_header &apos;Access-Control-Allow-Headers&apos; &apos;Accept,Authorization,Cache-Control,Content-Type,DNT,If-Modified-Since,Keep-Alive,Origin,User-Agent,X-Mx-ReqToken,X-Requested-With&apos; always; &#125; if ($request_method = &apos;OPTIONS&apos;) &#123; return 204; &#125; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080/learn/; &#125; # 图片缓存时间设置 location ~.*.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 10d; &#125; # JS和CSS缓存时间设置 location ~.*.(js|css)?$ &#123; expires 1h; &#125; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; &#125; 将前端代码打包后的dist文件放入指定服务目录/khgo/volume/project/front/storemanager 将服务目录指定到/khgo/volume/project/front目录下即可代理静态服务 配置里开启了gzip压缩，可以很大程度上减小文件体积大小 将404错误页面重定向到index.html，可以解决前端history路由模式由于刷新页面访问不到服务出现404的问题 location为代理接口，可以转发代理后端的请求接口域名或者ip，即可解决接口跨域问题 firewalld 防火墙配置 不改变状态下重载防火墙 1firewall-cmd --reload 基本使用 12345启动： systemctl start firewalld关闭： systemctl stop firewalld查看状态： systemctl status firewalld 开机禁用 ： systemctl disable firewalld开机启用 ： systemctl enable firewalld systemctl是CentOS7的服务管理工具中主要的工具，它融合之前service和chkconfig的功能于一体 123456789启动一个服务：systemctl start firewalld.service关闭一个服务：systemctl stop firewalld.service重启一个服务：systemctl restart firewalld.service显示一个服务的状态：systemctl status firewalld.service在开机时启用一个服务：systemctl enable firewalld.service在开机时禁用一个服务：systemctl disable firewalld.service查看服务是否开机启动：systemctl is-enabled firewalld.service查看已启动的服务列表：systemctl list-unit-files|grep enabled查看启动失败的服务列表：systemctl --failed 配置firewalld-cmd 12345678910查看版本： firewall-cmd --version查看帮助： firewall-cmd --help显示状态： firewall-cmd --state查看所有打开的端口： firewall-cmd --zone=public --list-ports更新防火墙规则： firewall-cmd --reload查看区域信息: firewall-cmd --get-active-zones查看指定接口所属区域： firewall-cmd --get-zone-of-interface=eth0拒绝所有包：firewall-cmd --panic-on取消拒绝状态： firewall-cmd --panic-off查看是否拒绝： firewall-cmd --query-panic 开启一个端口 12345678添加firewall-cmd --zone=public --add-port=80/tcp --permanent （--permanent永久生效，没有此参数重启后失效）重新载入firewall-cmd --reload查看firewall-cmd --zone=public --query-port=80/tcp删除firewall-cmd --zone=public --remove-port=80/tcp --permanent CentOs7.4安装Mysql8.0.17,参考文献 mysql-8.0.18-1.el7.x86_64.rpm-bundle.tar 卸载Linux自带mariadb什么是mariadb? 123456查看是否存在rpm -qa | grep mariadb卸载rpm -e mariadb-libs-5.5.56-2.el7.x86_64 --nodeps在查看是否存在rpm -qa | grep mariadb 通过FTP将下载好的mysql-8.0.18-1.el7.x86_64.rpm-bundle.tar传输到/khgo/volume/service 解压MySQL 1tar -xvf mysql-8.0.17-1.el7.x86_64.rpm-bundle.tar 依此安装所需RPM 123456rpm -ivh mysql-community-common-8.0.17-1.el7.x86_64.rpm --nodeps --forcerpm -ivh mysql-community-libs-8.0.17-1.el7.x86_64.rpm --nodeps --forcerpm -ivh mysql-community-client-8.0.17-1.el7.x86_64.rpm --nodeps --forcerpm -ivh mysql-community-server-8.0.17-1.el7.x86_64.rpm --nodeps --force查看依赖rpm -qa | grep mysql 依此执行执行初始化命令1234567891011121314$ mysqld --initialize报错：mysqld: error while loading shared libraries: libaio.so.1: cannot open shared object file: No such file or directory解决：yum install -y libaio$ chown mysql:mysql /var/lib/mysql -R$ systemctl start mysqld.service报错：Job for mysqld.service failed because the control process exited with error code. See &quot;systemctl status mysqld.service&quot; and &quot;journalctl -xe&quot; for details.解决：rm -rf /var/lib/mysql$ systemctl enable mysqld查看初始Mysql密码$ cat /var/log/mysqld.log | grep password结果：2019-12-03T05:54:50.131567Z 5 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: 0wVr&lt;#prLEow使用命令登录MySQLmysql -uroot -ppassword: 0wVr&lt;#prLEow 修改MySQL密码，并远程授权 123456789101112ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED WITH mysql_native_password BY &apos;khgo2019&apos;;失败：ERROR 1819 (HY000): Your password does not satisfy the current policy requirements原因：密码强度太低为了安全我们就不修改mysql默认安全策略了(大小写，特殊字符都加上)ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED WITH mysql_native_password BY &apos;khGo_2019&apos;;成功！远程访问Mysql,通过下面命令授权create user &apos;root&apos;@&apos;%&apos; identified with mysql_native_password by &apos;mypassword&apos;;grant all privileges on *.* to &apos;root&apos;@&apos;%&apos; with grant option;flush privileges;exit;最后使用navicat看是否能连接数据库！ CentOs7.4安装 redis-5.0.5 下载最稳定个版本redis-5.0.5.tar.gz 1234$ wget http://download.redis.io/releases/redis-5.0.5.tar.gz$ tar tar xzf redis-5.0.5.tar.gz$ cd redis-5.0.5$ make make命令结束后，redis-5.0.5目录里面会出现编译后的redis服务程序redis-server,以及测试的客户端程序redis-cli,两个程序都位于src目录下 12345# 默认启动$ cd src$ ./redis-server &amp;# 携带配置启动$ ./redis-server ../redis.conf 启动服务进程后，可以使用测试客户端redis-cli和redis服务交互 123456$ ./redis-cliredis&gt; set foo barOKredis&gt; get foo&quot;bar&quot;redis&gt; exit 设置redis为系统服务 123456789101112131415#/lib/systemd/system/redis.service[Unit]Description=Redis ServerAfter=network.target[Service]Type=forkingPIDFile=/var/run/redis_6379.pidExecStart=/khgo/volume/service/redis-5.0.5/src/redis-server /khgo/volume/service/redis-5.0.5/redis.confExecReload=/bin/kill -s HUP $MAINPIDExecStop=/bin/kill -s QUIT $MAINPIDPrivateTmp=true[Install]WantedBy=mutli-user.target 重新载入服务 1234567891011#重新载入 systemctl 并启动服务systemctl daemon-reloadsystemctl start redis.service#查看状态systemctl status redis.service#关闭systemctl stop redis.service#开机自启systemctl enable redis.service#是否开机自启systemctl is-enabled redis.service 成功！ redis配置 123456789101112131415161718192021222324252627282930# 绑定的主机地址#bind 127.0.0.1# 指定Redis监听端口，默认端口为6379,为什么选用6379作为默认端口,因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字port 6379# redis3.2版本后新增protected-mode配置，默认是yes，即开启。设置外部网络连接redis服务protected-mode no# 当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能timeout 300# Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程daemonize yes# 当运行多个 redis 服务时，需要指定不同的 pid 文件和端口pidfile /var/run/redis_6379.pid# 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verboseloglevel notice# 设置数据库的数量，默认数据库为0，可以使用SELECT &lt;dbid&gt;命令在连接上指定数据库iddatabases 16# 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH &lt;password&gt;命令提供密码，默认关闭requirepass AW6exN@pVw0mxcB4# 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，# 如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端# 返回max number of clients reached错误信息maxclients 128# 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，# 当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，# Value会存放在swap区# 一般推荐Redis设置内存为最大物理内存的四分之三maxmemory 751619276# 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。# 因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为noappendonly no","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xudongye.github.io/xdlog/categories/Linux/"}],"tags":[{"name":"系统服务","slug":"系统服务","permalink":"https://xudongye.github.io/xdlog/tags/系统服务/"},{"name":"CentOs7.4","slug":"CentOs7-4","permalink":"https://xudongye.github.io/xdlog/tags/CentOs7-4/"}]},{"title":"电商商品表数据库设计","slug":"design/电商商品表数据库设计","date":"2019-11-19T06:09:14.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"design/电商商品表数据库设计/","link":"","permalink":"https://xudongye.github.io/xdlog/design/电商商品表数据库设计/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"一个传统的电商项目，最难的地方也就在于数据库中表的关联，以及多表之间的查询关联，缕清楚表与表之间的关系，才能进行随心所欲的CRUD 第一张表：tb_category 商品类目表 123456789101112131415161718@Id@GeneratedValue(strategy = GenerationType.IDENTITY)private Long id;private String name;//硬件设施，母婴哺乳//排序序号private Integer sortOrder;private Boolean deleted;@Temporal(TemporalType.TIMESTAMP)private Date createTime;@Temporal(TemporalType.TIMESTAMP)private Date modifyTime;@ManyToOne(fetch = FetchType.LAZY)@JoinColumn(name = &quot;parent_id&quot;)private Category parent;@JoinColumn(name = &quot;parent_id&quot;)@OneToMany(fetch = FetchType.LAZY)private List&lt;Category&gt; children;private String picUrl; 第二张表：tc_product 商品表(spu) 12345678910111213141516171819@Id@GeneratedValue(strategy = GenerationType.IDENTITY)private Long id;//产品名称：手机，电脑，零食private String name;private String icon;private Boolean deleted;@Temporal(TemporalType.TIMESTAMP)private Date createTime;@Temporal(TemporalType.TIMESTAMP)private Date modifyTime;@ManyToOne(fetch = FetchType.LAZY)@JoinColumn(name = &quot;category_id&quot;, nullable = false)private Category category;private String brandName;private Double originalPrice;private Double promotionPrice;private Long hitCount;private Long saleCount; 第三张表：tb_propertyItem 商品规格属性表(sku) 1234@Id@GeneratedValue(strategy = GenerationType.IDENTITY)private Long id;private String name; 第四张表：tb_product_property 商品与商品属性中间表 123456789101112@Id@GeneratedValue(strategy = GenerationType.IDENTITY)private Long id;@ManyToOneprivate PropertyItem propertyItem;@ManyToOneprivate Product product;@Column(columnDefinition = &quot;tinyint(1) default 0&quot;)private Boolean enable; 贴出商品完整json数据 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586&#123; &quot;code&quot;: 200, &quot;data&quot;: &#123; &quot;id&quot;: 1, &quot;name&quot;: &quot;纯牛奶脱脂&quot;, &quot;title&quot;: null, &quot;description&quot;: null, &quot;deleted&quot;: false, &quot;createTime&quot;: 1562225261000, &quot;modifyTime&quot;: 1572516206000, &quot;productCategory&quot;: &#123; &quot;id&quot;: 14, &quot;name&quot;: &quot;伊利&quot;, &quot;sortOrder&quot;: 0, &quot;deleted&quot;: false, &quot;createTime&quot;: 1572311829000, &quot;modifyTime&quot;: null, &quot;parent&quot;: &#123; &quot;id&quot;: 1, &quot;name&quot;: &quot;牛奶饮品&quot;, &quot;sortOrder&quot;: 0, &quot;deleted&quot;: false, &quot;createTime&quot;: 1560327336000, &quot;modifyTime&quot;: null, &quot;parent&quot;: null &#125; &#125;, &quot;propertyItems&quot;: [ &#123; &quot;propertyId&quot;: 2, &quot;property&quot;: &quot;单位&quot;, &quot;value&quot;: &quot;袋&quot; &#125;, &#123; &quot;propertyId&quot;: 3, &quot;property&quot;: &quot;净含量&quot;, &quot;value&quot;: &quot;250ml&quot; &#125;, &#123; &quot;propertyId&quot;: 4, &quot;property&quot;: &quot;产地&quot;, &quot;value&quot;: &quot;中国安徽大草原&quot; &#125;, &#123; &quot;propertyId&quot;: 5, &quot;property&quot;: &quot;生产日期&quot;, &quot;value&quot;: &quot;2019-11-01&quot; &#125;, &#123; &quot;propertyId&quot;: 6, &quot;property&quot;: &quot;保质期&quot;, &quot;value&quot;: &quot;低于10°3个月&quot; &#125;, &#123; &quot;propertyId&quot;: 7, &quot;property&quot;: &quot;说明&quot;, &quot;value&quot;: &quot;开袋即食，不可直接使用微波炉加热&quot; &#125;, &#123; &quot;propertyId&quot;: 8, &quot;property&quot;: &quot;品牌&quot;, &quot;value&quot;: &quot;蒙牛&quot; &#125;, &#123; &quot;propertyId&quot;: 10, &quot;property&quot;: &quot;贮藏条件&quot;, &quot;value&quot;: &quot;低温冷藏&quot; &#125;, &#123; &quot;propertyId&quot;: 11, &quot;property&quot;: &quot;配料&quot;, &quot;value&quot;: &quot;鲜牛奶&quot; &#125;, &#123; &quot;propertyId&quot;: 12, &quot;property&quot;: &quot;电话&quot;, &quot;value&quot;: &quot;021-2313456&quot; &#125;, &#123; &quot;propertyId&quot;: 13, &quot;property&quot;: &quot;传真&quot;, &quot;value&quot;: &quot;021-8673453&quot; &#125; ] &#125;&#125;","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"数据结构设计","slug":"数据结构设计","permalink":"https://xudongye.github.io/xdlog/tags/数据结构设计/"}]},{"title":"Elasticsearch简介与实战","slug":"aihotel/Elasticsearch简介与实战","date":"2019-11-07T01:25:20.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"aihotel/Elasticsearch简介与实战/","link":"","permalink":"https://xudongye.github.io/xdlog/aihotel/Elasticsearch简介与实战/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"应用场景 因为做到了商城系统，商城数据商品表的复杂性，mysql中进行模糊查询，会放弃索引，导致商品表全表查询，，在PB级数据库中，效率非常低下。而引入es做一个全文索引，我们将经常查询的商品的某些字段，商品名称，描述，价格，id等fields放入索引库，提高查询速度。 为什么ElasticSearch/Lucene检索比Mysql快？ 什么是索引 我个人理解，索引就好比图书目录，查内容可以通过目录提供的页码快速找到。在关系型数据库中，索引是一个单独的、物理的对数据库表中的一列或多列的值进行排序的一种存储结构，是某一列或多列值的集合和相应的指向表中物理标识这些值的数据页的逻辑指针清单 索引的作用 保证数据的准确性，加快检索速度，唯一索引对应唯一值，提高系统性能 mysql索引如何实现？ 在mysql中，索引属于引擎级别的概念，不同的存储引擎对索引的实现方式都是不同的。 MyISAM索引实现 MyISAM表的索引和数据是分离的，索引保存在”表名.MYI”文件内，而数据保存在“表名.MYD”文件内 为了和InnoDB的聚集索引区分，MyISAM的索引方式叫做非聚集索引 InnoDB索引实现 InnoDB使用B+Tree作为索引结构，实现方式与MyISAM截然不同 主键聚集方式，InnoDB要求表必须有主键，如果没有显示指定，则mysql系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在，则mysql自动为InnoDB表生成一个隐性的类型为长整型长度为6字节的字段作为主键。 聚集索引的实现方式使得按主键的搜索十分高效，但是辅助索引是需要检索两边索引的：首先检索辅助索引获得主键，然后通过主键的主索引检索获得记录 了解了不同引擎的索引实现方式对于正确使用和优化索引都是有帮助的，比如InnoDB索引不建议使用过长的字段作为索引，因为辅助索引都是引用主索引，过长的主索引会令辅助索引变得过大。还有就是用非单调的字段作为主键在InnoDB中不是一个好主意，因为InnoDB数据文件本身是一棵B+Tree,非单调的主键会造成插入新纪录时数据文件为了维护B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键是一个很好的选择。 传统的关系型数据库大部分采用的B-Tree和B+Tree这样的数据结构。二叉树的查找效率是logN，同时写入更新新节点不必移动全部节点，所以树型结构存储索引，能同时兼顾写入和查询性能。当我们不需要支持快速的更新的时候，则可以用预先排序等方式换取更小的存储空间，更快的检索速度等好处，其代价就是更新慢。下面我们进一步深入了解Lucene索引是如何实现的。 Lucene 索引实现 lucene索引是如何实现(包含压缩技术)？ 总结 Lucene/Elasticsearch就是尽量将磁盘里的东西搬进内存，减少磁盘随机读取次数，同时利用磁盘顺序读取特性，结合压缩算法，高效使用内存，从而达到高速搜索的特性。","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"learn","slug":"learn","permalink":"https://xudongye.github.io/xdlog/tags/learn/"}]},{"title":"spring配置占位符替换源码解析","slug":"java/spring/spring配置占位符源码解析","date":"2019-07-23T06:06:39.000Z","updated":"2020-12-18T02:51:05.425Z","comments":true,"path":"java/spring/spring配置占位符源码解析/","link":"","permalink":"https://xudongye.github.io/xdlog/java/spring/spring配置占位符源码解析/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"今天搭建spring-boot项目启动时遇到一个问题：TDDL（淘宝内部使用的一款分库分表框架）DataSource无法找到MySQL配置，仔细观察日志发现是XML文件中spring bean的占位符，如${za.castle.bastion.tddl.appname}未被正确替换，运行时还是原来的带$符号的原字符串。 不得不承认，很多时候，我们的代码都是从其他同类项目复制过来的，遇到问题时，最常见的疑问大概就是：“在X项目中是好的啊？”。其实这种时候，问题不是不知道为什么我的代码不行，而是不知道，为什么X项目的代码可行。我的老师曾经说过：“当你不知道什么是正确，你如何能够纠正错误？”。 下面，我就从源码出发，揭示spring替换配置占位符的详细过程。 替换占位符spring-boot启动入口SpringApplication.run()： 123456789101112public class SpringApplication &#123; public ConfigurableApplicationContext run(String... args) &#123; ... context = createApplicationContext(); analyzers = new FailureAnalyzers(context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); ... &#125;&#125; refreshContext是spring bean体系最重要的方法之一，包含了大部分对bean的处理，其中就包含了： 123456private static void invokeBeanFactoryPostProcessors( Collection&lt;? extends BeanFactoryPostProcessor&gt; postProcessors, ConfigurableListableBeanFactory beanFactory) &#123; for (BeanFactoryPostProcessor postProcessor : postProcessors) &#123; postProcessor.postProcessBeanFactory(beanFactory); &#125;&#125; BeanFactoryPostProcessor是spring中与bean定义交互的接口，可以修改其定义。其中，就包含了PropertySourcesPlaceholderConfigurer这个实现(这个实现由PropertyPlaceholderAutoConfiguration配置到Spring ApplicationContext)，转换发现的所有placeholders。 1234567891011121314151617181920212223public class BeanDefinitionVisitor &#123; public void visitBeanDefinition(BeanDefinition beanDefinition) &#123; visitParentName(beanDefinition); visitBeanClassName(beanDefinition); visitFactoryBeanName(beanDefinition); visitFactoryMethodName(beanDefinition); visitScope(beanDefinition); visitPropertyValues(beanDefinition.getPropertyValues()); ConstructorArgumentValues cas = beanDefinition.getConstructorArgumentValues(); visitIndexedArgumentValues(cas.getIndexedArgumentValues()); visitGenericArgumentValues(cas.getGenericArgumentValues()); &#125; ... protected String resolveStringValue(String strVal) &#123; if (this.valueResolver == null) &#123; throw new IllegalStateException(\"No StringValueResolver specified - pass a resolver \" + \"object into the constructor or override the 'resolveStringValue' method\"); &#125; String resolvedValue = this.valueResolver.resolveStringValue(strVal); // Return original String if not modified. return (strVal.equals(resolvedValue) ? strVal : resolvedValue); &#125;&#125; resolveStringValue方法会将placeholder替换为对应的值。 Environment上面解释了什么时候替换占位符，那么占位符的值从哪里来的呢？ spring中所有的property都来源于一个统一的抽象Environment，在PropertySourcesPlaceholderConfigurer初始化之时，会将applicationContext中的Environment注入。 12345678910class ApplicationContextAwareProcessor implements BeanPostProcessor &#123; private void invokeAwareInterfaces(Object bean) &#123; if (bean instanceof Aware) &#123; if (bean instanceof EnvironmentAware) &#123; ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); &#125; ... &#125; &#125;&#125; spring-cloud-config所以，属性来自Environment，那么spring-cloud-config-client又是如何将spring-cloud-config-server上的属性设置到Environment中的呢？ spring-cloud-config的启动配置类PropertySourceBootstrapConfiguration在初始化时，会试图获取property，并将其设置进applicationContext.getEnvironment()中： 123456789101112131415161718public class PropertySourceBootstrapConfiguration implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt;, Ordered &#123; public void initialize(ConfigurableApplicationContext applicationContext) &#123; ... ConfigurableEnvironment environment = applicationContext.getEnvironment(); for (PropertySourceLocator locator : this.propertySourceLocators) &#123; PropertySource&lt;?&gt; source = null; source = locator.locate(environment); if (source == null) &#123; continue; &#125; logger.info(\"Located property source: \" + source); composite.addPropertySource(source); empty = false; &#125; ... &#125;&#125; spring-cloud-config-client的locate()方法实现就是从server获取配置并注入。 所以spring-cloud-config-client就这样获取到配置，并保存在Environment中，并在bean定义处理时替代了对应的占位符。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/tags/Java/"},{"name":"读源码","slug":"读源码","permalink":"https://xudongye.github.io/xdlog/tags/读源码/"}]},{"title":"连接池误用引发的服务失去响应","slug":"java/连接池误用引发的服务失去响应","date":"2019-07-18T11:57:18.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"java/连接池误用引发的服务失去响应/","link":"","permalink":"https://xudongye.github.io/xdlog/java/连接池误用引发的服务失去响应/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"连接池误用引发的服务失去响应记录一次线上问题排查过程。 症状服务完全无法处理用户请求，返回HTTP504状态码，无日志输出。但进程正常运行，端口监听正常。 内存dump排查有人曾经说过：“世界上的Java程序员，有一半在写代码的时候制造内存问题，另一半在解决内存问题”。 所以不管3721先dump一下内存快照看下再说（命令jmap -dump:format=b,file=filename [pid]）。 很遗憾，内存各个区都很富余，问题不在内存。 查看jvm监控公司的JVM监控：基于Prometheus从spring cloud actuator接口中采集jvm监控数据，然后生成Dashboard图。 发现一处可疑的线程数增长情况。 注：此处可以看到积极接入监控系统对jvm问题排查的关键作用，平时不监控，排查两行泪 线程dump排查发现线程的可疑情况后，将服务线程dump出来（命令jstack -l [pid]）。建议将dump文件下载下来，放进分析工具进行分析（这里推荐一个在线的分析工具），肉眼看原始文件真的很累。 dump分析工具将线程调用栈进行了分组，可以看到有200个类似以下调用栈的线程waiting中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110http-nio-8080-exec-796priority:5 - threadId:0x00007fa1f8098800 - nativeId:0x1dfe - nativeId (decimal):7678 - state:WAITINGstackTrace:java.lang.Thread.State: WAITING (parking)at sun.misc.Unsafe.park(Native Method)- parking to wait for &lt;0x00000000a3e59118&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)at org.apache.commons.pool2.impl.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:583)at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:442)at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:363)at redis.clients.util.Pool.getResource(Pool.java:49)at redis.clients.jedis.JedisPool.getResource(JedisPool.java:226)at com.zhongan.redis.JedisPoolManager.getJedis(JedisPoolManager.java:83)at com.zhongan.castle.msspy.common.CastleRedisClient.callback(CastleRedisClient.java:27)at com.zhongan.castle.msspy.common.CastleRedisClient.get(CastleRedisClient.java:60)at com.zhongan.castle.msspy.controller.BigScreenMonitorController.searchQuoteSummaryInfo(BigScreenMonitorController.java:640)at com.zhongan.castle.msspy.controller.BigScreenMonitorController$$FastClassBySpringCGLIB$$1aae1c42.invoke(&lt;generated&gt;)at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:85)at com.zhongan.sleuth.trace.aspect.ZaTraceAspect.wrapWithCorrelationId(ZaTraceAspect.java:74)at sun.reflect.GeneratedMethodAccessor445.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:498)at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:629)at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:618)at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168)at org.springframework.aop.aspectj.AspectJAfterThrowingAdvice.invoke(AspectJAfterThrowingAdvice.java:62)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168)at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)at com.zhongan.castle.msspy.controller.BigScreenMonitorController$$EnhancerBySpringCGLIB$$d22bffc0.searchQuoteSummaryInfo(&lt;generated&gt;)at sun.reflect.GeneratedMethodAccessor1110.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:498)at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)at com.zhongan.sso.client.AuthenticationFilter.doFilter(AuthenticationFilter.java:138)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)at org.springframework.cloud.sleuth.instrument.web.TraceFilter.doFilter(TraceFilter.java:186)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:478)at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:80)at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:799)at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1457)at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)- locked &lt;0x00000000ff519ab0&gt; (a org.apache.tomcat.util.net.NioEndpoint$NioSocketWrapper)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)at java.lang.Thread.run(Thread.java:748)Locked ownable synchronizers:- &lt;0x00000000ff4e63e8&gt; (a java.util.concurrent.ThreadPoolExecutor$Worker) http-nio-8080-exec线程熟悉tomcat的可以跳过本段 往调用链的源头看，可以猜到这个线程是tomcat用的，大概率是线程池。 我们来看一下源码 spring-boot内嵌的tomcat8默认使用nio连接处理请求，NioEndpoint在初始化时创建了线程池，所以个人认为这个线程池应该称之为worker池更为贴切。 1234567891011121314151617/** * Start the NIO endpoint, creating acceptor, poller threads. */@Overridepublic class NioEndpoint extends AbstractJsseEndpoint&lt;NioChannel&gt; &#123; ... public void startInternal() throws Exception &#123; if (!running) &#123; ... // Create worker collection if ( getExecutor() == null ) &#123; createExecutor(); &#125; &#125; &#125;&#125; AbstractEndpoint中实现了连接池的创建，可以看到线程名称前缀为getName()+’-exec-‘，这个getName()的代码就不贴了，结果就是http-nio-8080-这个前缀。 12345678910public abstract class AbstractEndpoint&lt;S&gt; &#123; ... public void createExecutor() &#123; internalExecutor = true; TaskQueue taskqueue = new TaskQueue(); TaskThreadFactory tf = new TaskThreadFactory(getName() + \"-exec-\", daemon, getThreadPriority()); executor = new ThreadPoolExecutor(getMinSpareThreads(), getMaxThreads(), 60, TimeUnit.SECONDS,taskqueue, tf); taskqueue.setParent( (ThreadPoolExecutor) executor); &#125;&#125; 这个线程主要的作用是处理socket连接： 1234567891011121314151617181920public boolean processSocket(SocketWrapperBase&lt;S&gt; socketWrapper, SocketEvent event, boolean dispatch) &#123; try &#123; ... SocketProcessorBase&lt;S&gt; sc = processorCache.pop(); if (sc == null) &#123; sc = createSocketProcessor(socketWrapper, event); &#125; else &#123; sc.reset(socketWrapper, event); &#125; Executor executor = getExecutor(); if (dispatch &amp;&amp; executor != null) &#123; executor.execute(sc); &#125; else &#123; sc.run(); &#125; &#125; ... return true;&#125; 这个线程池的maxThreads默认是200，与线程栈中200个waiting线程也对应上了。 所以此处可以断定，是tomcat的线程池用完了，无法处理新的请求。 线程stack详细分析观察http-nio-8080-exec线程调用栈的顶部发现，线程是堵塞在获取redis获取连接池的方法了。关于连接池的实现原理可以参考ApacheHttpClient连接池源码分析。 查看服务的配置可以看到，redis连接池为100，为什么会出现一个连接都取不到，而所有的线程都在等待Redis连接的情况呢？ 大胆猜测可能是有代码在borrow连接之后，没有release，造成连接越来越少，最终连接池枯竭。 查看代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class CastleRedisClient &#123; private JedisPoolManager jedisPoolManager; public static interface RedisCallback&lt;T&gt; &#123; T callback(Jedis jedis); &#125; public &lt;T&gt; T callback(CastleRedisClient.RedisCallback&lt;T&gt; callback) &#123; Jedis jedis = null; T result = null; try &#123; jedis = jedisPoolManager.getJedis(); result = callback.callback(jedis); &#125; catch (Exception e) &#123; log.error(\"RedisException:\", e); &#125; finally &#123; jedisPoolManager.close(jedis); &#125; return result; &#125; public Object get(final Serializable key) &#123; Object ob = callback(new CastleRedisClient.RedisCallback&lt;Object&gt;() &#123; @Override public Object callback(Jedis jedis) &#123; byte[] result = jedis.get(SerializeUtil.serialize(key)); return null == result ? result : SerializeUtil.deserialize(result); &#125; &#125;); return ob; &#125; ... public JedisPoolManager getJedisPoolManager() &#123; return jedisPoolManager; &#125; public void setJedisPoolManager(JedisPoolManager jedisPoolManager) &#123; this.jedisPoolManager = jedisPoolManager; &#125;&#125; 这个client使用了模板方法设计模式，将callback作为抽象方法留给子类实现，这样就保证了主流程：取连接–&gt;查数据–&gt;释放连接 的公用流程的复用。 但是，这里不恰当地将本应该封装在内部的JedisPoolManager对象通过getter方法逸出了，造成了有代码（确实有，这里就不贴了）没有按照上面的流程取到了连接而没有释放，最终造成了连接池枯竭，影响了整个服务的可用性。 超时时间这里插播一条插曲，在排查过程中，发现明明设置了redis超时时间，为什么线程没有进入timed_waiting状态，而进入了无时间限制的waiting。 通过阅读源码发现，这个超时时间，其实是设置的redis连接的超时时间，而不是从连接池取连接的最大等待时间（这个时间默认值是-1，即无限等待）。开发过程中有很多超时时间，切忌想当然地理解其作用。 123456789101112131415161718192021public void connect() &#123; if (!isConnected()) &#123; try &#123; socket = new Socket(); // -&gt;@wjw_add socket.setReuseAddress(true); socket.setKeepAlive(true); // Will monitor the TCP connection is // valid socket.setTcpNoDelay(true); // Socket buffer Whetherclosed, to // ensure timely delivery of data socket.setSoLinger(true, 0); // Control calls close () method, // the underlying socket is closed // immediately // &lt;-@wjw_add socket.connect(new InetSocketAddress(host, port), connectionTimeout); socket.setSoTimeout(soTimeout); ... &#125; &#125;&#125; 总结这次排查是个很典型的线上问题，所以在这里啰嗦地总结了几点： 服务监控的重要性 合理使用Java调试工具 一个不严谨封装的代码，很可能会带来严重的后果","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/tags/Java/"},{"name":"排查记录","slug":"排查记录","permalink":"https://xudongye.github.io/xdlog/tags/排查记录/"}]},{"title":"ApacheHttpClient连接池源码分析","slug":"java/ApacheHttpClient连接池源码分析","date":"2019-05-23T03:14:00.000Z","updated":"2020-12-18T02:51:05.417Z","comments":true,"path":"java/ApacheHttpClient连接池源码分析/","link":"","permalink":"https://xudongye.github.io/xdlog/java/ApacheHttpClient连接池源码分析/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"ApacheHttpClient连接池源码分析问题背景公司基于apache http client为核心，实现了一个类似于Zuul/nginx的网关系统。为了保护后端被转发的集群，必须具有限流特性，即并发量控制。我们知道apache http client自带了最大连接数的参数设置，在此细致解读一下其表现以及源码级别的实现方式。 连接池微观解读执行堆栈查看得出，核心的处理代码在：org.apache.http.pool.AbstractConnPool，作为一个抽象同步阻塞连接池，实现了接口 123456public interface ConnPool&lt;T, E&gt; &#123; // 租借连接 Future&lt;E&gt; lease(final T route, final Object state, final FutureCallback&lt;E&gt; callback); // 释放连接 void release(E entry, boolean reusable);&#125; 先看一下，org.apache.http.pool.AbstractConnPool类有哪些主要的属性： 1234567891011121314// 不同线程获取连接之间的竞态条件private final Condition condition;// 连接工厂private final ConnFactory&lt;T, C&gt; connFactory;// 保存route到连接池的map，apache http client可以设置参数setMaxConnPerRoute，按照route管理连接private final Map&lt;T, RouteSpecificPool&lt;T, C, E&gt;&gt; routeToPool;// 已租借出的连接private final Set&lt;E&gt; leased;// 可用的连接private final LinkedList&lt;E&gt; available;// 等待中的连接future对象private final LinkedList&lt;Future&lt;E&gt;&gt; pending;// route到连接数的映射private final Map&lt;T, Integer&gt; maxPerRoute; 再来看一下我们最关心的lease方法: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Overridepublic Future&lt;E&gt; lease(final T route, final Object state, final FutureCallback&lt;E&gt; callback) &#123; ... return new Future&lt;E&gt;() &#123; private final AtomicBoolean cancelled = new AtomicBoolean(false); private final AtomicBoolean done = new AtomicBoolean(false); private final AtomicReference&lt;E&gt; entryRef = new AtomicReference&lt;E&gt;(null); @Override public boolean cancel(final boolean mayInterruptIfRunning) &#123; ... &#125; ... @Override public E get() throws InterruptedException, ExecutionException &#123; try &#123; return get(0L, TimeUnit.MILLISECONDS); &#125; catch (final TimeoutException ex) &#123; throw new ExecutionException(ex); &#125; &#125; @Override public E get(final long timeout, final TimeUnit timeUnit) throws InterruptedException, ExecutionException, TimeoutException &#123; final E entry = entryRef.get(); if (entry != null) &#123; return entry; &#125; synchronized (this) &#123; try &#123; for (;;) &#123; // 死循环一直借到连接为止，除非出现被打断的异常 final E leasedEntry = getPoolEntryBlocking(route, state, timeout, timeUnit, this); ... entryRef.set(leasedEntry); done.set(true); onLease(leasedEntry); if (callback != null) &#123; callback.completed(leasedEntry); &#125; return leasedEntry; &#125; &#125; catch (final IOException ex) &#123; done.set(true); if (callback != null) &#123; callback.failed(ex); &#125; throw new ExecutionException(ex); &#125; &#125; &#125; &#125;;&#125; 可以看到，这个方法直接返回了一个与连接池关联的Future对象，所有的秘密都在这个匿名类中。着重看一下Future.get:除了处理一些前后回调钩子（onRelease/callback）外，主要将功能委托给了getPoolEntryBlocking方法 123456789101112131415161718192021private E getPoolEntryBlocking( final T route, final Object state, final long timeout, final TimeUnit timeUnit, final Future&lt;E&gt; future) throws IOException, InterruptedException, TimeoutException &#123; Date deadline = null; if (timeout &gt; 0) &#123; deadline = new Date (System.currentTimeMillis() + timeUnit.toMillis(timeout)); &#125; this.lock.lock(); try &#123; final RouteSpecificPool&lt;T, C, E&gt; pool = getPool(route); E entry; for (;;) &#123; ... &#125; throw new TimeoutException(\"Timeout waiting for connection\"); &#125; finally &#123; this.lock.unlock(); &#125;&#125; 对对象加锁之后，根据route来获取RouteSpecificPool对象，可以参考一下上文提到的属性 routeToPool。 在这个for循环中，主要分为以下几段来获取连接： 尝试获取空闲的连接，如果获取成功直接return。顺便关闭、清除了过期的连接。 123456789101112131415161718192021for (;;) &#123; entry = pool.getFree(state); if (entry == null) &#123; break; &#125; if (entry.isExpired(System.currentTimeMillis())) &#123; entry.close(); &#125; if (entry.isClosed()) &#123; this.available.remove(entry); pool.free(entry, false); &#125; else &#123; break; &#125;&#125;if (entry != null) &#123; this.available.remove(entry); this.leased.add(entry); onReuse(entry); return entry;&#125; 关于pool.getFree(state)中的state： 这是ConnPool接口中lease方法定义了的入参，可以传入任意一个Object对象，含义是用来表示一种特殊的状态（通常是安全秘钥、token等），来定位同样的连接。如果不需要这个支持，可以传null。 缩容超出maxPerRoute的连接池 123456789101112131415// New connection is neededfinal int maxPerRoute = getMax(route);// Shrink the pool prior to allocating a new connectionfinal int excess = Math.max(0, pool.getAllocatedCount() + 1 - maxPerRoute);if (excess &gt; 0) &#123; for (int i = 0; i &lt; excess; i++) &#123; final E lastUsed = pool.getLastUsed(); if (lastUsed == null) &#123; break; &#125; lastUsed.close(); this.available.remove(lastUsed); pool.remove(lastUsed); &#125;&#125; 如果还有空余容量，从工厂对象connFactory生产新的连接加入池。 12345678910111213141516171819if (pool.getAllocatedCount() &lt; maxPerRoute) &#123; final int totalUsed = this.leased.size(); final int freeCapacity = Math.max(this.maxTotal - totalUsed, 0); if (freeCapacity &gt; 0) &#123; final int totalAvailable = this.available.size(); if (totalAvailable &gt; freeCapacity - 1) &#123; if (!this.available.isEmpty()) &#123; final E lastUsed = this.available.removeLast(); lastUsed.close(); final RouteSpecificPool&lt;T, C, E&gt; otherpool = getPool(lastUsed.getRoute()); otherpool.remove(lastUsed); &#125; &#125; final C conn = this.connFactory.create(route); entry = pool.add(conn); this.leased.add(entry); return entry; &#125;&#125; 阻塞线程，等待空闲连接 1234567891011121314151617181920212223242526boolean success = false;try &#123; // 如果Future已经取消，那么直接跳出等待，结束外层死循环 if (future.isCancelled()) &#123; throw new InterruptedException(\"Operation interrupted\"); &#125; pool.queue(future); this.pending.add(future); // 使用condition阻塞线程，等待condition.signalAll() if (deadline != null) &#123; success = this.condition.awaitUntil(deadline); &#125; else &#123; this.condition.await(); success = true; &#125; if (future.isCancelled()) &#123; throw new InterruptedException(\"Operation interrupted\"); &#125;&#125; finally &#123; // In case of 'success', we were woken up by the // connection pool and should now have a connection // waiting for us, or else we're shutting down. // Just continue in the loop, both cases are checked. pool.unqueue(future); this.pending.remove(future);&#125; 被唤醒的时机： 其他Future被cancel，不跟你抢了 其他线程release连接，归还了，但这也不表示能获取到连接，需要在queue排队 检验超时 1234567// 如果未成功获取到对象，且等待超时，那么跳出循环，throw超时异常// check for spurious wakeup vs. timeout if (!success &amp;&amp; (deadline != null &amp;&amp; deadline.getTime() &lt;= System.currentTimeMillis())) &#123; break; &#125;&#125;throw new TimeoutException(\"Timeout waiting for connection\"); 看到这里，这个连接池的微观层面的代码实现已经基本剖析完毕，如果还有细节问题，可以再对照源码查看。 这里比较巧妙地组合了Future/Lock/Condition/Queue（这里并没有使用并发集合类如LinkedBlockingQueue，而用LinkedList实现，猜测可能是历史遗留原因），实现了一个清晰安全的连接池，并且留下了许多可扩展可定制的参数与回调，值得学习参考。 连接池宏观设计上一部分从代码层面解读了连接池的微观实现，这里我们再宏观看一下，ApacheHttpClient如何使用这个连接池。 org.apache.http.impl.conn.PoolingHttpClientConnectionManager类维护了org.apache.http.impl.conn.CPool属性，该类是AbstractConnPool的实现类，基本功能都来自继承。 ApacheHttpClient使用了责任链模式，链条上的executor： RedirectExec: 负责处理重定向 RetryExec： 负责决定在io错误时是不是重试 ServiceUnavailableRetryExec： 负责决定非2xx响应是否重试 ProtocolExec： 负责处理http参数，构建请求体 org.apache.http.impl.execchain.MainClientExec：最后一个executor，负责实际的请求、响应转换，就是他从PoolingHttpClientConnectionManager中获取连接对象 什么时候释放连接？ 流被关闭 12345678public boolean streamClosed(final InputStream wrapped) throws IOException &#123; try &#123; ... &#125; finally &#123; releaseManagedConnection(); &#125; return false;&#125; 流检测读到eof 12345678public boolean eofDetected(final InputStream wrapped) throws IOException &#123; try &#123; ... &#125; finally &#123; releaseManagedConnection(); &#125; return false; &#125; ‘池’池是编程设计中非常常用的一种模式，能够高效地复用对象，网络连接这种初始化成本较高的对象的池化，是最典型的场景。由于许多类库的支持，开发者可能很少需要去重复造轮子自己实现对象池，但深入理解池的实现，会让我们对一些常见的表现能够有更精确的把握，甚至针对一些定制化场景进行优化与修改，设计更强大更高级的池。 ps： 文中httpcore版本 4.4.6，版本间细节差别应该不影响对设计的理解。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/tags/Java/"},{"name":"读源码","slug":"读源码","permalink":"https://xudongye.github.io/xdlog/tags/读源码/"}]},{"title":"Java读取jar包中文件夹内容","slug":"java/Java读取jar包中文件夹内容","date":"2019-05-10T01:56:08.000Z","updated":"2020-12-18T02:51:05.417Z","comments":true,"path":"java/Java读取jar包中文件夹内容/","link":"","permalink":"https://xudongye.github.io/xdlog/java/Java读取jar包中文件夹内容/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"Java读取jar包中文件夹内容目标运行时列举/src/main/resources/configs目录下的所有文件 错误示例12345File f = new File(this.getClass().getResource(\"/configs/\").getPath());for(String s : f.list)&#123; System.out.println(s);&#125; 在IDE或者mvn spring-boot:run时，可以工作。但是打jar包后，使用java -jar命令运行时，找不到这个目录。 文件被打包进jar之后，当然不存在/configs/这个目录，再用java.io.File去取就是缘木求鱼了。 解决方案在spring框架中，对这个问题提供了比较优雅的API： 123PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver();Resource[] resources = resolver.getResources(\"classpath:/configs/*.*\"); org.springframework.core.io.support.PathMatchingResourcePatternResolver这个类取自spring-core包，通过传入getResources()方法的父级目录，来判断路径协议是file://还是jar://: 123456else if (ResourceUtils.isJarURL(rootDirUrl) || isJarResource(rootDirResource)) &#123; result.addAll(doFindPathMatchingJarResources(rootDirResource, rootDirUrl, subPattern));&#125;else &#123; result.addAll(doFindPathMatchingFileResources(rootDirResource, subPattern));&#125; 其中，doFindPathMatchingJarResources,doFindPathMatchingFileResources方法分别实现了在jar中定位resources（利用java.util.jar.JarFile类）、在file系统中定位resources的功能。 总结spring这个工具类同时支持了ide中运行和jar运行，节省了开发很多兼容问题的代码，是一个很好的实现。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/tags/Java/"}]},{"title":"阳淳投屏计价模式设计","slug":"aihotel/阳淳投屏计价模式设计","date":"2018-07-27T15:39:10.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"aihotel/阳淳投屏计价模式设计/","link":"","permalink":"https://xudongye.github.io/xdlog/aihotel/阳淳投屏计价模式设计/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"需求说明 投放模板 投屏系数(T)：A类全屏为系数1，B类半屏为系数0.5，C类四分之一屏系数为0.25 人流量(P)：人流量大于5000人/日，系数为2，小于5000人/日系数为1 点位系数(C)：自定义点位携带系数，类似折扣点最大为1 设备数量(D)：广告投放点位设备安装数量 基础费用(B)：普通投放随机投放模式10元，VIP通道预约时段投放模式100元，高人流量点位霸屏播放模式800元，定制全屏独播模式1000元 计费公式：TxPxCxBxD元/日。以普通播放，人流量大于5000人次，投屏系数为A类，点位系数为1，点位机器数量为20台为例 计价标准为：10x2x1x1x20=400元/天 投放协议及标准：投放合同为保证用户在投点位90%设备正常工作，每个点位每个广告投放必须满足每天播放量为200次以上，否则无法进行立即投放，可预约未来时间段 影响投放因素：广告审核时间过长，设备断电无法正常工作 设备工作时间：每个点位可远程设置自定义设置，远程开关机控制 实现效果(部分)： 点位选择 投屏系数： 投放内容 下单支付 订单列表 广告监播 主页内容","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"信发","slug":"信发","permalink":"https://xudongye.github.io/xdlog/tags/信发/"},{"name":"广告投屏","slug":"广告投屏","permalink":"https://xudongye.github.io/xdlog/tags/广告投屏/"}]},{"title":"关于cms权限管理模块设计","slug":"aihotel/关于cms权限管理模块设计","date":"2018-05-27T02:44:14.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"aihotel/关于cms权限管理模块设计/","link":"","permalink":"https://xudongye.github.io/xdlog/aihotel/关于cms权限管理模块设计/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"关于cms权限管理模块设计需求分析： 说到cms系统，权限管理是必不可少的功能，不断完善总有些不尽人意，所以抽个时间思考一下 如若每个应用系统为了满足不同系统用户需求而重新设计权限，大大降低了代码的重用性，所以就有必要设计一套通用，灵活，方便的权限系统 ER关系模型 行为描述：随着系统的日益庞大，为了做到方便管理，针对每个用户授予不同权限，基本的crud操作是不可少的，每一个用户分配一个角色，角色与权限形成多对多关系，每个角色设置最大分配权限等级，与之对应的就是每个权限所对应的权重等级，这样就可以再分配权限同时做到不会越权分配。为了避免显示业务对权限设计入侵太重，所以就引入了菜单表的设计，关联权限一一对应与之对应的有前端路由即资源分配。权限分为显性权限（即与菜单对应），而隐性权限可以理解为接口的读写权限不用分配菜单 授权示例","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"aiHotel","slug":"aiHotel","permalink":"https://xudongye.github.io/xdlog/tags/aiHotel/"}]},{"title":"阳淳信息发布系统后端架构设计","slug":"aihotel/阳淳信息发布系统后端架构设计","date":"2018-04-27T07:43:53.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"aihotel/阳淳信息发布系统后端架构设计/","link":"","permalink":"https://xudongye.github.io/xdlog/aihotel/阳淳信息发布系统后端架构设计/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"信发系统RestApi架构设计 咱们先画一个脑图捋一捋 架构目录展示 说明： commons模块：组合后台开发所有的公共模块，被业务模块依赖，避免耦合与项目相关的定制化业务逻辑。 cloud模块：父级模块，依赖管理 cloud-modules：所有业务模块组合， cloud-api：组织最终导出war包模块，主要业务功能由其依赖jar包提高，并且维护一些与应用直接相关的配置项。 cloud-configuration：动态配置项读取模块，如支付密钥，支付回调地址等配置 cloud-event：使用activemq异步消息队列服务器，封装事件发布服务，并预定事件消息的数据模型。目的：1.异步处理事务，加快相应速度，提高吞吐量2.消息队列提高访问峰值承载能力3.代码解耦，在不是紧耦合的模块之间传递消息来处理支线流程 cloud-test：使用spring-test测试组件，MockHttpServletRequest对象对rest-api进行测试，依赖注入来测试供其他业务模块调用的service接口 应用服务器 承载主要业务模块，使用mysql,redis作为持久层 鉴权模块 提高身份验证相关的所有服务： 创建token 删除token 通过token查询用户权限，用户包括网站用户与管理员以及app用户 根据token验证身份rest api暴露给其他服务器使用 从mysql中查询用户及权限信息 利用redis保存token,设置有效时间，将token值作为key以最快查询","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"信发","slug":"信发","permalink":"https://xudongye.github.io/xdlog/tags/信发/"}]},{"title":"显式锁","slug":"java/concurrency/Java并发编程实战学习笔记/13显式锁","date":"2017-08-28T16:00:00.000Z","updated":"2020-12-18T02:51:05.417Z","comments":true,"path":"java/concurrency/Java并发编程实战学习笔记/13显式锁/","link":"","permalink":"https://xudongye.github.io/xdlog/java/concurrency/Java并发编程实战学习笔记/13显式锁/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"显式锁Lock与ReentrantLock12345678public interface Lock &#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException; void unlock; Condition newCondition();&#125; 与内置加锁机制不同，Lock提供了一种无条件的、可轮询的、定时的以及可中断的锁获取操作，所有加锁和解锁的方法都是显式的。 Lock的标准使用形式： 123456789Lock lock = new ReentrantLock();...lock.lock();try &#123; // 更新对象状态 // 捕获异常，并在必要时恢复不变性条件&#125; finally &#123; lock.unlock();&#125; 必须在finally块中释放锁，否则相当于启动了一个定时炸弹。 轮询锁与定时锁与无条件的锁获取模式相比，可定时的、可轮询的锁获取模式具有更完善的错误恢复机制，来避免死锁。 如果不能获得所有需要的锁，那么可以使用定时的或可轮询的锁获取方式，从而使你重新获得控制权，它会释放已经获得的锁，然后重新尝试获取所有锁。 12345678910111213141516171819202122public boolean transferMoney(Account from, Account to DollarAmount amount, long timeout, Timeunit unit) &#123; while(true) &#123; if (from.lock.tryLock()) &#123; try &#123; if (to.lock.tryLock()) &#123; try &#123; return transfer(from, to, amount); &#125; finally &#123; to.lock.unlock(); &#125; &#125; &#125; finally &#123; from.lock.unlock(); &#125; &#125; if (retry too many times) &#123; return false; &#125; Thread.sleep(random time); &#125;&#125; 在实现具有时间限制的操作时，定时锁非常有用。当时用内置锁时，在开始请求锁后，这个操作将无法取消。可使用tryLock(timeout, timeunit)方法来实现。 可中断的锁获取操作请求内置锁时，无法响应中断。这些不可中断的阻塞机制，将使得实现可取消任务变得复杂。lockInterruptibly()方法能够在获得锁的同时保持对中断的响应。 非块结构的加锁连锁式加锁Hand-Over-Hand Locking锁耦合Lock Coupling 性能考虑因素 性能是个不断变化的指标，如果昨天的测试基准中发现X比Y快，那么在今天就可能已经过时了。 公平性非公平的锁允许插队：当一个线程请求非公平锁时，如何在发出请求的同时该锁的状态可用，那么这个线程将跳过队列中所有的等待线程，并获得这个锁。 非公平锁的性能高于公平锁。公平性将由于挂起线程和恢复线程时存在的开销而极大降低性能，实际情况下，统计上的公平性保证————确保被阻塞的线程能最终获得锁，已经够用了，并且开销小得多。 在持有锁的时间相对较长，或者请求锁的平均时间间隔较长，那么应该使用公平锁。这种情况下，插队带来的吞吐量提升则可能不会出现。 与默认ReentrantLock一样，内置锁不会提供确定的公平性保证，大多数情况下，实现统计上的公平性保证就已经足够了。 在synchronized和ReentrantLock之间进行选择 在内置锁无法满足需求的情况下，ReentrantLock可作为一种高级工具，如可定时的、可轮询的、可中断的锁获取操作，公平队列，以及非块结构的锁，才是用ReentrantLock。否则还是优先使用synchronized。 读写锁如果能够放宽互斥的加锁策略，允许多个执行读操作的线程同时访问数据，那么将提升程序的性能。 ReentrantReadWriteLock在构造时，可选择非公平（默认）还是公平锁。写线程降级为读线程是可以的，但从读线程升级为写线程则不可以（会导致死锁）。 当锁的持有时间较长，且大部分操作都不会修改被守护的资源时，那么读写锁能提供并发性。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://xudongye.github.io/xdlog/tags/多线程/"},{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"性能与可伸缩性","slug":"java/concurrency/Java并发编程实战学习笔记/11性能与可伸缩性","date":"2017-08-17T16:00:00.000Z","updated":"2020-12-18T02:51:05.417Z","comments":true,"path":"java/concurrency/Java并发编程实战学习笔记/11性能与可伸缩性/","link":"","permalink":"https://xudongye.github.io/xdlog/java/concurrency/Java并发编程实战学习笔记/11性能与可伸缩性/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"性能与可伸缩性我们虽然希望提升性能，但始终要把安全性放在第一位。首先要保证程序能正确运行，然后仅当程序的性能需求和测试结果要求程序执行得更快时，才应该设法提高他的运行速度。 对性能的思考多线程会引入一些额外的开销： 线程之间的协调（锁、触发信号、内存同步等） 增加的上下文切换 线程的创建与销毁 线程的调度 想要通过并发来提升性能，需要做好2件事：更高效地利用现有处理资源，以及出现新的处理资源时使程序尽可能利用这些资源。CPU需要尽可能保持忙碌。 性能与可伸缩性程序的性能指标，一些（服务时间、等待时间）用于衡量程序的运行速度，即某个指定任务单元需要“多块”才能完成；另外一些指标（生产量、吞吐量）用于衡量“处理能力”，即在计算资源一定的情况下，能完成“多少”工作。 可伸缩性：当增加计算资源（如CPU、内存、存储容量、I/O带宽）时，程序的吞吐量或者处理能力能相应地增加。 可伸缩性设计与传统的性能调优方法截然不同：传统的性能调优通常是用更小的代价完成相同的工作，例如缓存重用计算结果，采用时间复杂度更优化的算法；在可伸缩性调优时，其目的是设法将计算并行化，从而利用更多的计算资源来完成更多的工作。 性能的两个方面————“多快”和“多少”，是完全独立的，有时候甚至是相互矛盾的。我们熟悉的三层模型（表现层、逻辑层、持久层）就很好地说明了提高可伸缩性会造成性能损失的原因。 对于服务器程序来说，“多少”这个问题————可伸缩性、吞吐量、生产量，往往比“多快”更受重视。 评估各种性能权衡因素很多性能优化措施通常是以牺牲可读性或可维护性为代价————代码越“聪明”越“晦涩”，就越难以理解和维护。 对性能的提升可能是并发错误的最大来源。 Amdahl定律在增加计算资源的情况下，程序在理论上能够实现最高加速比，取决于程序中并行组件与串行组件所占的比重。假定F为必须串行的部分，在N个处理器的机器中，最高加速比为： Speedup &lt;= 1 / (F + (1 - F) / N) 当N趋近无穷大时，最大的加速比趋近于1/F。 在所有并发程序中都包含一些串行部分。如果你认为不存在串行部分，那么可以再仔细检查一遍。 示例：在各种框架中隐藏的串行部分举了一个从队列中取出任务并发处理的例子，来说明串行部分Queue取元素对可伸缩性的影响。 Amdahl定律的应用一些在4处理器系统中看似具有可伸缩性的算法，却可能含有一些隐藏的可伸缩性瓶颈，只是还没有遇到。 在评估一个算法时，要考虑算数百上千个处理器时的性能表现，从而对可能出现的可伸缩性局限性有一定程度的认识。 线程引入的开销上下文切换内存同步 不要过度担心非竞争同步带来的开销。这个基本的机制已经非常快了，并且JVM还能进行额外的优化以进一步降低或消除开销。因此，我们应该将优化的重点放在那些发生锁竞争的地方。 阻塞当线程无法获取某个锁或者由于在某个条件等待或者I/O操作上阻塞时，需要被挂起，在这个过程中将包含2次额外的上下文切换，以及所有必要的操作系统操作和缓存操作。 减少锁的竞争 在并发程序中，对可伸缩性的最主要威胁就是独占方式的资源锁。 有三种方式可以降低锁的竞争程度： 减少锁的持有时间。 降低锁的请求频率。 使用带有协调机制的独占锁，这些机制允许更高的并发性。 缩小锁的范围（“快进快出”）将一些与锁无关的代码移出同步代码块，尤其是那些开销较大的操作，以及可能被阻塞的操作，如I/O操作。 尽管缩小同步代码块能提高可伸缩性，但同步代码块不能过小————一些需要采用原子方式执行的操作，必须包含在一个同步块中。 此外，同步需要一定的开销，当把一个同步代码分解为多个时，反而可能会对性能提升带来负面影响。 在实际情况下，仅当可以将“大量”的计算，或阻塞操作从同步代码中移出，才应该考虑同步代码块的大小。 减小锁的粒度如果一个锁需要保护多个相互独立的状态变量，那么可以将这个锁分解为多个锁，并且每个锁只保护一个变量，从而降低每个锁被请求的频率，提高可伸缩性。 使用的锁越多，发生死锁的风险就越大。 锁分段在某些情况下，可以将锁分解技术进一步扩展为对一组独立对象上的锁进行分解，成为锁分段。 参考jdk中ConcurrentHashMap的实现原理。 避免热点域一些常见的优化措施，如将反复计算的结果缓存起来，都会引入“热点域”，热点域往往会限制可伸缩性。 如HashMap中size计数器，在多线程情况下，这个热点域就导致了难以提升的可伸缩性。ConcurrentHashMap为了避免size热点域，为每个分段维护了一个独立的技术，并通过每个分段的锁来维护这个值。 一些替代独占锁的方法第三种降低竞争锁的影响的技术就是放弃使用独占锁，从而有助于使用一种友好并发的方式，如： 并发容器 读写锁：实现了在多个线程读取、单个写入情况下的加锁规则。 不可变对象 原子变量 检测CPU的利用率Unix系统命令：vmstat/mpstat。 如果CPU没有充分利用，通常原因有以下几种： 负载不充分 I/O密集。可以通过iostat来判断应用是否是I/O密集型，或者检测网络的通信流量级别来判断它是否需要高带宽。 外部限制。如数据库、Web服务等。 锁竞争。 如果CPU保持忙碌状态，那么可以使用监测工具来判断能否通过增加CPU来提升性能。在vmstat的输出中，有一栏信息是当前处于可运行状态但并没有运行（由于没有足够CPU）的线程数量，如果CPU利用率很高，并且总会有可运行线程在等待CPU，那么增加更多的处理器时，性能可能会得到提升。 向对象池说不在单线程程序中，尽管对象池能降低GC开销，但对于高开销对象之外的其他对象来说，仍然存在性能缺失。 在并发程序中，对象池的表现更糟。如果多线程在对象池中请求对象，那么通常需要同步对象池的访问，从而使某个线程阻塞。阻塞的开销是内存分配操作的数百倍，因此对象池很可能带来可伸缩性瓶颈。 示例：比较Map的性能减少上下文切换的开销举例说明：日志输出时，将写日志的I/O操作转移到了另一个用户感知不到开销的线程，消除了用户线程被I/O阻塞的机会，进而使用户线程快进快出，减少其他被持有的锁上发生竞争的机会。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://xudongye.github.io/xdlog/tags/多线程/"},{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"避免活跃性危险","slug":"java/concurrency/Java并发编程实战学习笔记/10避免活跃性危险","date":"2017-08-14T16:00:00.000Z","updated":"2020-12-18T02:51:05.417Z","comments":true,"path":"java/concurrency/Java并发编程实战学习笔记/10避免活跃性危险/","link":"","permalink":"https://xudongye.github.io/xdlog/java/concurrency/Java并发编程实战学习笔记/10避免活跃性危险/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"避免活跃性危险死锁“哲学家进餐”问题描述了死锁：每个人都拥有其他人需要的资源，同时又等待其他人已经拥有的资源，并且每个人在获得所有需要的资源之前都不会放弃已经拥有的资源。 线程A持有锁L并想获得锁M的同时，线程B持有锁M并尝试获得锁L，那么这两个线程将永远地等待下去，这种情况就是最简单的死锁形式（或称为“抱死”Deadly Embrace）。 数据库设计中考虑了监测死锁以及从死锁中恢复。发生死锁时，根据事务权重判断，回滚权重低的事务，从而使其他事务继续进行。 JVM在解决死锁问题时没有如此强大，当一组Java线程死锁时，这些线程永远不能用了。 锁顺序死锁LeftRightDeadLock发生死锁的原因在于，2个线程试图以不同的顺序来获得相同的锁。 如果所有线程以固定的顺序来获得锁，那么在程序中就不会出现顺序死锁问题。 动态的锁顺序死锁12345678public void transferMoney(Account from, Account to, Amount amount) &#123; synchronized(from) &#123; synchronized(to) &#123; from.debit(amount); to.credit(amount); &#125; &#125;&#125; 如果并发： 12Thread A : transferMoney(a, b, 10);Thread B : transferMoney(b, a, 20); 那么就可能发生死锁。 解决思路： 对多个需要加锁对象进行对比排序，采用固定的顺序进行加锁。如书中建议使用System.identityHashCode()来获取一致性hash，当hash碰撞时，采用“加时赛”的方式，额外增加一个锁以保证每次只有一个线程以未知顺序获得锁，从而消除死锁可能性。如果加锁对象包含一个唯一的、不可变的且具备可比性的键值属性，如id，那么制定锁规则会更加容易。 在协作对象之间发生的死锁如果在持有锁时调用某个外部方法，那么将出现活跃性问题。在这个外部方法中，可能会获取其他锁，这可能会产生死锁，或者阻塞时间过长，导致其他线程无法及时获得当前被持有的锁。 开放调用在调用某个方法时不需要持有锁，那么这种调用被称为开放调用（Open Call）。 通过尽可能地使用开放调用，将易于找出那些需要获取多个锁的代码路径，因此也就容易确保采用一致的顺序来获得锁。 资源死锁当多个线程相互持有彼此正在等待的资源，又不释放自己已持有的资源时，会发生资源死锁。 如线程A持有数据库D1的连接，并等待与数据库D2的连接，而线程B持有数据库D2并等待D1的连接，就会发生资源死锁。 另一个基于资源的死锁形式就是线程饥饿死锁。如：一个任务提交另一个任务，并等待被提交的任务在单线程Executor中执行完成，这种情况下，第一个任务将永远等待，其他任务将无法执行。如果某些任务需要等待其他任务的结果，那么这些任务往往是产生线程饥饿死锁的主要来源，有限线程、资源池与相互依赖的任务不能一起使用。 死锁的避免与诊断如果必须获得多个锁，那么在设计时必须考虑锁的顺序：尽量减少潜在的加锁交互数量，将获取锁时需要遵守的协议写入正式文档并始终遵循。 支持定时的锁显式使用Lock类中的定时tryLock功能来代替内置锁机制：指定超时时限，在等待超时后返回一个失败信息。 通过线程转储信息来分析死锁线程转储包含各个运行中的线程的栈追踪信息，类似于发生异常时的栈追踪信息。线程转储还包含加锁信息，例如每个线程持有了哪些锁，在哪些栈桢中获得这些锁，以及被阻塞的线程正在等待哪个锁。 其他活跃性危险饥饿当线程由于无法访问它所需要的资源而不能继续执行时，就发生了“饥饿”，引发饥饿最常见的资源就是CPU时钟周期。如果Java程序中对线程的优先级使用不当，或者在持有锁时执行一些无法结束的结构（如无限循环、无限等待某个资源），那么也可能导致饥饿。 Thread API中定义的线程优先级只是作为线程调度的参考，其中10个优先级会被JVM根据需要映射到操作系统的调度优先级，这种映射是与特定平台相关联的。 要避免使用线程优先级，因为这会增加平台依赖性，并可能导致活跃性问题。在大多数程序中，都可以使用默认线程优先级。 糟糕的响应性CPU密集型的后台任务可能对响应性造成影响，因为它们会与响应线程共同竞争CPU时钟周期，这时应该降低它们的线程优先级，提高前台的响应性。 不良的锁管理也可能导致糟糕的响应性，如对一个大容器进行迭代并对每个元素进行计算密集的处理。 活锁当多个相互协作的线程都对彼此进行响应，从而修改各自的状态，并使得任何一个线程都无法继续执行时，就发生了活锁。 要解决这种活锁问题，需要在重试机制中引入随机性。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://xudongye.github.io/xdlog/tags/多线程/"},{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"线程池的使用","slug":"java/concurrency/Java并发编程实战学习笔记/8线程池的使用","date":"2017-08-09T16:00:00.000Z","updated":"2020-12-18T02:51:05.425Z","comments":true,"path":"java/concurrency/Java并发编程实战学习笔记/8线程池的使用/","link":"","permalink":"https://xudongye.github.io/xdlog/java/concurrency/Java并发编程实战学习笔记/8线程池的使用/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"线程池的使用在任务与执行策略之间的隐形耦合虽然Executor框架为制定和修改执行策略都提供了很大的灵活性，但并非所有的任务都适用所有的执行策略。有些类型的任务需要明确制定执行策略： 依赖性任务 使用线程封闭机制的任务：必须单线程 对响应时间敏感的任务 适用ThreadLocal的任务 线程饥饿死锁只要线程池中的任务需要无限期地等待一些必须由池中其他任务才能提供的资源或条件，例如某个任务等待另一个任务的返回值或执行效果，那么除非线程池足够大，否则将发生线程饥饿死锁。 运行时间较长的任务执行时间较长的任务不仅会造成线程阻塞，甚至会增加执行时间较短任务的服务时间。如果线程池中线程的数量远小于在稳定状态下执行时间较长任务的数量，那么到最后可能所有的线程都会运行这些执行时间较长的任务，从而影响整体的响应性。 设置线程池的大小对于计算密集型的任务，在拥有N个处理器的系统上，当线程池大小为N+1时，能实现最优利用率。 对于包含I/O操作或其他阻塞操作时，由于线程不会一直执行，因此线程池的规模应该更大： 线程池大小=CPU数量目标CPU利用率(1+等待时间与运算时间的比率) 当然，CPU周期并不是唯一影响线程池大小的资源，还包括内存、文件句柄、套接字句柄和数据库连接等。计算每个任务对该资源的需求总量，然后用该资源的可用总量，除以每个任务的需求量，所得结果就是线程池大小的上限。 配置ThreadPoolExecutorThreadPoolExecutor的通用构造函数 1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123;&#125; 线程池的创建与销毁 基本大小coolPoolSize：在没有任务执行时线程池的大小，并且只有在工作队列满了的情况下才会创建超出这个数量的线程。 最大大小maximumPoolSize：可同时活动的线程数量的上限。 存活时间keepAliveTime：如果某个线程的空闲时间超过了存活时间，那么将被标记为可回收的，并且当线程池的当前大小超过了基本大小时，这个线程将被终止。 管理队列任务ThreadPoolExecutor允许提供一个BlockingQueue来保存等待执行的任务。基本的任务排队方法有3种：无解队列、有界队列和同步移交（Synchronous HandOff）。 newFixedThreadPool、newSingleThreadExecutor在默认情况下使用一个无界的LinkedBlockingQueue。如果所有工作者线程都在忙碌，那么任务将在队列中等待，如果任务持续快速到达，队列将无限增加。 一种更稳妥的资源管理策略是使用有界队列，例如ArrayBlockingQueue、有界LinkedBlockingQueue、PriorityBlockingQueue。有界队列必须与饱和策略配合使用。 对于非常大的或者无界线程池，可以使用SynchronousQueue来避免排队，以及直接将任务从生产者移交到工作者线程。要将一个元素放入SynchronousQueue，必须有一个线程在等待接受这个任务，如果没有线程在等待，且线程数量没有达到上限，那么将创建新的线程，否则根据饱和策略拒绝任务。newCachedThreadPool使用了SynchronousQueue。 PriorityBlockingQueue将按照优先级来安排任务，任务的优先级是按照自然顺序或Comparator来定义的。 只有当任务相互独立，为线程或工作队列设置界限才是合理的。如果任务之间存在依赖性，那么有界可能导致线程饥饿死锁，此时应该使用无界线程池，如newCachedThreadPool。 饱和策略 中止策略（AbortPolicy）：默认的饱和策略，该策略抛出RejectedExecutionException，调用者可以catch这个异常，根据需求编写处理代码。 抛弃策略（DiscardPolicy）：悄悄地抛弃任务。 抛弃最旧的策略（DiscardOldestPolicy）：抛弃下一个将要执行的任务，尝试提交新任务。 调用者运行策略（CallerRunsPolicy）：不会在线程池中执行新任务，而是在调用了execute的线程中执行。 线程工厂通过指定一个线程工厂方法，可以定制线程池的配置信息，如： 指定线程名字 设置自定义UncaughtExceptionHandler 维护一些统计信息（如有多少个线程被创建、销毁） 线程创建或者终止时打日志 在调用构造函数后再定制ThreadPoolExecutor可以调用ThreadPoolExecutor的setter方法来修改参数。 Executors包含一个unconfigurableExecutorService方法将其装饰为ExecutorService接口，以防止执行策略被不信任的代码所修改。 扩展ThreadPoolExecutor可重写方法：beforeExecute, afterExecute, terminated","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://xudongye.github.io/xdlog/tags/多线程/"},{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"取消与关闭","slug":"java/concurrency/Java并发编程实战学习笔记/7取消与关闭","date":"2017-08-08T16:00:00.000Z","updated":"2020-12-18T02:51:05.425Z","comments":true,"path":"java/concurrency/Java并发编程实战学习笔记/7取消与关闭/","link":"","permalink":"https://xudongye.github.io/xdlog/java/concurrency/Java并发编程实战学习笔记/7取消与关闭/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"取消与关闭这一章超难，暂时读不懂。 要使线程安全、快速、可靠地停止下来，并不是一件容易的事，Java没有提供任何机制来安全地终止线程。但Java提供了中断（Interruption），这是一种协作机制，能够使一个线程终止另一个线程的当前工作。 一个行为良好的软件，与勉强运行的软件之间的最主要区别就是，行为良好的软件能很完善地处理失败、关闭和取消等过程。 任务取消取消的原因： 用户请求取消 有时间限制的操作 应用程序事件 错误 关闭 其中一种协作机制是设置某个“已请求取消（Cancellation Requested）”标识，而任务定期查看该标识。 1234567private volatile boolean cancelled;public void run() &#123; while(!cancelled) &#123; doTask(); &#125;&#125; 中断上述的取消机制下，如果任务调用了一个阻塞方法，例如BlockingQueue.put，那么可能产生一个严重的问题————任务永远不会检查取消标志，因此永远不会结束。 一些阻塞库的方法支持中断，线程中断是一种协作机制，线程可以通过这种机制来通知另一个线程，告诉它在合适的或者可能的情况下停止当前工作，并转而执行其他工作。 每个线程都有一个boolean类型的中断状态，中断线程时被设置为true。 12345public class Thread &#123; public void interrupt()&#123;&#125; public boolean isInterrupted()&#123;&#125; public static boolean interrupted() &#123;&#125;&#125; 调用interrupt并不意味着立即停止目标线程正在进行的工作，而只是传递了请求中断的消息。 通常，中断是实现取消最合理的方式。 中断策略由于每个线程拥有各自的中断策略，因此除非你知道中断对该线程的含义，否则就不应该中断这个线程。 响应中断通过Future来实现取消处理不可中断的阻塞采用newTaskFor来封装非标准的取消停止基于线程的服务","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://xudongye.github.io/xdlog/tags/多线程/"},{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"任务执行","slug":"java/concurrency/Java并发编程实战学习笔记/6任务执行","date":"2017-08-07T16:00:00.000Z","updated":"2020-12-18T02:51:05.417Z","comments":true,"path":"java/concurrency/Java并发编程实战学习笔记/6任务执行/","link":"","permalink":"https://xudongye.github.io/xdlog/java/concurrency/Java并发编程实战学习笔记/6任务执行/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"任务执行在线程中执行任务串行地执行任务显式地为任务创建线程无限制创建线程的不足 创建生命周期的开销非常高 资源消耗 稳定性 Executor框架在Java类库中，任务执行的主要抽象不是Thread，而是Executor： 123public interface Executor &#123; void execute(Runnable command);&#125; Executor基于生产者-消费者模式，提交任务相当于生产者，执行任务相当于消费者。 执行策略线程池Executors静态工厂方法： newFixedThreadPool newCachedThreadPool newSingleThreadExecutor newScheduledThreadPool Executor生命周期为了解决执行任务的生命周期问题，Executor扩展了ExecutorService接口，增加了一些用于生命周期管理的方法。 延迟任务与周期任务Timer有一些缺陷，应该使用ScheduledThreadPoolExecutor","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://xudongye.github.io/xdlog/tags/多线程/"},{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"基础构建模块","slug":"java/concurrency/Java并发编程实战学习笔记/5基础构建模块","date":"2017-08-02T16:00:00.000Z","updated":"2020-12-18T02:51:05.417Z","comments":true,"path":"java/concurrency/Java并发编程实战学习笔记/5基础构建模块/","link":"","permalink":"https://xudongye.github.io/xdlog/java/concurrency/Java并发编程实战学习笔记/5基础构建模块/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"基础构建模块Java平台类库包含了丰富的并发基础构建模块，例如线程安全的容器类以及同步工具类。 同步容器类同步容器包括Vector、HashTable，Collections.synchronizedXxx等工厂方法创建的同步封装器类。 这些类实现线程同步的方式是：将状态封装起来，并对每个公有方法同步，使得每次只有一个线程能访问容器的状态。 同步容器类的问题复合操作，如：迭代、跳转、条件运算等，需要额外的客户端加锁来保证线程安全性。 迭代器与ConcurrentModificationException在设计同步容器类的迭代器时并没有考虑到并发修改的问题，并且表现出的行为是“及时失败”（fail-fast）：当发现容器在迭代时被修改，会抛出ConcurrentModificationException。 在迭代过程中持有容器的锁，可以避免ConcurrentModificationException，但长期持有锁可能会造成饥饿或者死锁，降低程序的可伸缩性。 如果不希望加锁，那么替代方式就是克隆容器，在副本上迭代。但是克隆容器时存在着显著的性能开销。 隐藏迭代器容器的toString()/hashCode()/equals()方法，都可能间接迭代容器，造成ConcurrentModificationException异常。 并发容器通过并发容器来替代同步容器，可以极大地提高伸缩性并降低风险。 ConcurrentHashMap实现机制：分段锁 额外的原子Map操作增加了一些常见的复合操作： 123456public interface ConcurrentMap&lt;K, V&gt; extends Map&lt;K, V&gt; &#123; V putIfAbsent(K key, V value); boolean remove(K key, V value); boolean replace(K key, V oldValue, V newValue); boolean replace(K key, V newValue);&#125; CopyOnWriteArrayList“写入时复制”容器每次修改时，都会创建并重新发布一个新的容器副本。 仅当迭代操作远远多于复制操作时，才应该使用“写入时复制”容器，这个准则很好地描述了许多事件通知系统：大多数情况下，注册、注销监听器的操作远少于接收事件并分发通知的操作。 阻塞队列和生产者-消费者模式在构建高可靠的应用程序时，有界队列是一种强大的资源管理工具：它能够抑制并防止产生过多的工作项，使应用程序在负荷过载的情况下变得更加健壮。 串行线程封闭对于可变对象，阻塞队列促进了串行线程封闭，将对象的所有权从生产者交付给消费者。线程封闭对象只能由单个线程拥有，独占访问权。 双端队列与工作密取BlockingDeque 应用场景看不懂 阻塞方法与中断方法同步工具类闭锁闭锁可以用来确保某些活动直到其他活动都完成后才继续执行。 CountDownLatch#await()/countDown() FutureTaskFutureTask实现了Future语义，表示一种抽象的可生成结果的计算。FutureTask表示的计算是通过Callable实现的，相当于一种可生成结果的Runnable，并处于三种状态：等待运行、正在运行、运行完成。 FutureTask.get()取决于任务的状态，如果任务已经完成，那么get立即返回结果，否则get将阻塞直到任务进入完成状态，然后返回结果或抛出异常。 信号量计数信号量用来控制同时访问某个特定资源的操作数量，或者同时执行某个操作的数量。 Semaphore管理着一组虚拟的许可，许可的初始数量可通过构造函数指定。在执行操作时可以首先获得许可，使用后释放许可。如果没有许可，acquire将阻塞直至有许可。 栅栏栅栏（Barrier）类似于闭锁，能阻塞一组线程直到某个事件发生。栅栏的区别在于，所有线程必须同时到达栅栏位置，才能继续执行。闭锁用于等待事件，栅栏用于等待其他线程。例如：所有人6:00在麦当劳碰头，到了以后要等其它人，人齐了才能走。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://xudongye.github.io/xdlog/tags/多线程/"},{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"对象的组合","slug":"java/concurrency/Java并发编程实战学习笔记/4对象的组合","date":"2017-07-30T16:00:00.000Z","updated":"2020-12-18T02:51:05.417Z","comments":true,"path":"java/concurrency/Java并发编程实战学习笔记/4对象的组合/","link":"","permalink":"https://xudongye.github.io/xdlog/java/concurrency/Java并发编程实战学习笔记/4对象的组合/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"对象的组合本章将介绍一些组合模式，将一些现有的线程安全组件组合为更大规模的组件或程序，并且在维护这些类时，不会无意中破坏线程安全性保证。 设计线程安全的类设计线程安全的类需要考虑以下三个基本要素： 找出构成对象状态的所有变量 找出约束状态变量的不变性条件 建立对象状态的并发访问管理策略 收集同步需求依赖状态的操作状态的所有权实例封闭当一个对象被封装到另一个对象时，能够访问被封装对象的所有代码路径都是已知的，更易于对代码分析。 将数据封装在对象内部，可以将数据的访问限制在对象的方法上，从而更容易确保线程在访问数据时总能持有正确的锁。 1234567891011@ThreadSafepublic class PersonSet &#123; @GuardBy(\"this\") private final Set&lt;Person&gt; mySet = new HashSet(); public synchronized void addPerson(Person p) &#123; mySet.add(p); &#125; public synchronized boolean containsPerson(Person p) &#123; return mySet.contains(p); &#125;&#125; JDK类库中有很多线程封闭的示例，其中有些类的唯一用途就是将非线程安全的类转化为线程安全的类，如ArrayList并非线程安全的，但类库提供了装饰器工厂方法，如Collections.synchronizedList，使得他们能在多线程环境中安全使用。 Java监视器模式遵循Java监视器模式的对象会把对象所有的可变状态封装起来，并由自己的内置锁来保护，JDK中许多类都使用了Java监视器模式，如Vector、HashTable。 Java监视器模式的主要优势在于其简单性。 线程安全性的委托独立的状态变量我们可以将线程安全性委托给多个状态变量，只要这些变量是彼此独立的，即组合而成的类并不会在其包含的多个状态变量上增加任何不变性条件。 当委托失效时举了一个NumberRange使用AtomicInteger类来保存数字范围的上限与下限，却并不能保证线程安全性的例子。因为状态变量upper/lower不是彼此独立的。 如果一个类由多个独立且线程安全的状态变量组成，并且所有的操作中都不包含无效状态装换，那么可以将线程安全性委托给底层的状态变量。 发布底层的状态变量如果一个状态变量是线程安全的，并且没有任何不变性约束来约束它的值，在变量操作上也不存在任何不允许的状态转换，那么就可以安全地发布这个变量。 在现有的线程安全类中添加功能修改原始类代码通常无法做到。 继承原始类并扩展方法可以做到，但比直接将代码添加到类中更加脆弱，因为同步策略被分布到多个单独维护的源代码中，如果底层的类改变了同步策略并选择了不同的锁来保护它的状态变量，那么子类的线程安全性将会被破坏。 客户端加锁机制1234567891011121314@ThreadSafepublic class ListHelper&lt;E&gt; &#123; public List&lt;E&gt; list = Collections.synchronizedList(new ArrayList&lt;E&gt;()); ... public boolean putIfAbsent(E e) &#123; synchronized(list) &#123; boolean absent = !list.contains(e); if(absent) &#123; list.add(e); &#125; return absent; &#125; &#125;&#125; 客户端加锁将类List的加锁代码放到了与之无关的ListHelper类中，同样会破坏同步策略的封装性。 组合123456789101112131415161718@ThreadSafepublic class ImprovedList&lt;T&gt; implements List&lt;T&gt; &#123; private final List&lt;T&gt; list; public ImprovedList(List&lt;T&gt; list) &#123; this.list = list; &#125; public synchronized boolean putIfAbsent(T t) &#123; boolean absent = !list.contains(t); if(absent) &#123; list.add(t); &#125; return absent; &#125; public synchronized void clear() &#123; list.clear(); &#125; // ... 按照类似的方法委托List接口的其他方法&#125; ImprovedList通过内置锁增加了一层额外的加锁，它不必关心底层的list是否线程安全，ImprovedList提供了一致的加锁机制来实现线程安全性。虽然额外的同步层可能带来轻微的性能损失，但其线程安全性更为健壮。 将同步策略文档化","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://xudongye.github.io/xdlog/tags/多线程/"},{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"对象的共享","slug":"java/concurrency/Java并发编程实战学习笔记/3对象的共享","date":"2017-07-26T16:00:00.000Z","updated":"2020-12-18T02:51:05.417Z","comments":true,"path":"java/concurrency/Java并发编程实战学习笔记/3对象的共享/","link":"","permalink":"https://xudongye.github.io/xdlog/java/concurrency/Java并发编程实战学习笔记/3对象的共享/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"对象的共享上一章《线程安全性》介绍了如何通过同步来避免多个线程同时访问相同的数据，本章将介绍如何共享和发布对象，从而使之能够安全地有多个线程访问。 可见性当多个线程在没有同步机制的情况下共享数据，可能出现读线程不能按照预期地读取到写线程对共享数据的修改。 重排序：在没有同步的情况下，编译期、处理器以及运行时等，都可能对操作的顺序进行一些意想不到的调整。在缺乏足够同步的多线程程序中，想要对内存操作的执行顺序进行判断，几乎无法得出正确的结论。 失效数据除非在每次访问变量时都使用同步，否则很有可能获得该变量的一个失效值。 1234567@ThreadSafepublic class SynchronizedInteger &#123; @GuardedBy(\"this\") private int value; public synchronized int get() &#123;return value;&#125; public synchronized void set(int value) &#123;this.value = value;&#125;&#125; 非原子的64位操作当线程在没有同步的情况读取变量，可能得到一个失效值，但至少这个值至少是之前某个线程设置的值，而不是一个随机值：这种安全性保证也被称为最低安全性。 但是非volatile的64位数值（double/long）可能无法保证最低安全性，可能读取到某个值的高32位和另一个值的低32位。 加锁与可见性加锁的含义不仅局限于互斥性，还包含可见性。为了确保所有线程都能看到共享变量的最新值，所有读写操作的线程都必须在同一个锁上同步。 volatile变量volatile变量上的操作不会与其他内存操作一起重排序。volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，因此读取volatile变量总是会返回最新值。 访问volatile变量不会加锁，不会使线程堵塞，是一种比synchronized更轻量级的同步机制。 仅当volatile能简化代码的实现以及对同步策略的验证时，才应该使用。如果在验证正确性时，需要对可见性进行复杂的判断，那么就不要使用volatile。 典型用法：检查某个状态标识以判断是否退出循环。 12345volatile boolean asleep;... while (!asleep) &#123; countSheep(); &#125; volatile不能保证i++的原子性，除非你确保只有一个线程对变量执行写操作。 使用volatile必须满足以下所有条件： 对变量的写入操作不依赖变量的当前值，或者能确定只有单个线程更新变量。 该变量不与其他变量一起纳入不变性条件。 不需要加锁。 发布与逸出发布（Publish）：使对象在当前作用域之外的代码使用。如： 将一个指向该对象的引用保存到其他代码能访问的地方 在一个非私有方法中返回该引用 将引用传递到其他类的方法中 逸出（Escape）：某个不应该发布的对象被发布。 当某个对象逸出后，你必须假设某个类或线程会误用该对象。这正是使用封装的主要原因：封装使得对程序的正确性分析变得可能，并使无意中破坏设计约束条件变得很难。 线程封闭一种避免使用同步的方式就是不共享数据，如果仅在单线程内访问，就不需要同步，这种技术被称为“线程封闭”。 栈封闭只通过局部变量访问对象。 ThreadLocal类ThreadLocal通常用于防止对可变的单实例变量或全局变量共享。 不变性不可变对象一定是线程安全的。 当满足以下条件时，对象才是不可变的： 对象创建以后其状态不能修改 所有域都是final 对象是正确创建的（创建期间this引用没有逸出） 保存在不可变对象中的状态仍然可以更新，即通过一个保存新状态的实例来替换原有的不可变对象。 final域除非需要某个域是可变的，否则将其声明为final域，是很好的编程习惯。 安全发布12345public Holder holder;public void initialize() &#123; holder = new Holder();&#125; 这种不正确的发布导致其他线程看到尚未构建完成的对象。 不正确的发布：正确的对象被破坏你不能指望一个尚未被完全创建的对象拥有完整性。 12345678910public class Holder &#123; private int n; public Holder(int n) &#123; this.n = n; &#125; public void assertSanity() &#123; if (n != n) &#123; // 可能抛出异常 throw new AssertionError(\"this statement is false.\"); &#125; &#125;&#125; 不可变对象与初始化安全性任何线程都可以在不需要额外同步的情况下安全地访问不可变对象，即使在发布这些对象时没有使用同步。 安全发布的常用模式要安全地发布一个对象，对象的引用以及对象的状态必须同时对其他线程可见。一个正确构造的对象可以通过以下方式来安全地发布： 在静态初始化函数中初始化一个对象引用。 public static Holder holder = new Holder(); 静态初始化器在jvm类的初始化阶段执行，由于jvm内部存在同步机制，这种对象可以安全发布。 将对象的引用保存到volatile的域或者AtomicReference对象中。 将对象的引用保存到某个正确构造对象的final域中。 将对象的引用保存到一个由锁保护的域中。 将键或值放入HashTable、synchronizedMap、ConcurrentMap中 将元素放入Vector、CopyOnWriteArrayList、CopyOnWriteArraySet、synchronizedList、synchronizedSet中 放入BlockingQueue、ConcurrentLinkedQueue中 事实不可变对象与上面定义的技术不可变对象一样，任何线程都可以在不需要额外同步的情况下安全地访问事实不可变对象。 可变对象要安全地共享可变对象，这些对象必须安全发布，并且必须是线程安全的，或者由某个锁保护起来。 总结在并发程序中使用共享变量，可以使用如下策略： 线程封闭。 只读共享。 包括不可变对象和事实不可变对象 线程安全共享。 线程安全的对象在其内部实现同步，因此多个线程可以通过对象的公有接口来访问而不需要进一步的同步。 保护对象。 被保护的对象只能通过持有特定的锁来访问。包括封装在其他线程安全对象中的对象，以及已发布的并且由某个特定锁保护的对象。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://xudongye.github.io/xdlog/tags/多线程/"},{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"线程安全性","slug":"java/concurrency/Java并发编程实战学习笔记/2线程安全性","date":"2017-07-25T16:00:00.000Z","updated":"2020-12-18T02:51:05.417Z","comments":true,"path":"java/concurrency/Java并发编程实战学习笔记/2线程安全性/","link":"","permalink":"https://xudongye.github.io/xdlog/java/concurrency/Java并发编程实战学习笔记/2线程安全性/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"线程安全性Java中主要的同步机制： synchronized关键字 volatile类型变量 显式锁 原子变量 面向对象的程序状态的封装性越好，访问某个变量的代码越少，就越容易确保对变量的所有访问实现正确同步，同时也更容易找出变量在哪些条件下被访问，也就越容易实现线程安全性。 什么是线程安全性正确性：某个类的行为与其规范完全一致。 线程安全性：当多个线程访问某个类时，不管运行时环境运用何种调度方式，或者这些线程如何交替执行，并且在调用代码中不需要任何额外的同步或协同，这个类始终表现正确的行为，那么就称这个类是线程安全的。 书中举了一个无状态Servlet的例子，表示无状态对象一定是线程安全的。 原子性在Servlet中增加一个实例变量，并且多线程调用i++的方式，说明非线程安全。 竞态条件当某个计算的正确性取决于多个线程的交替执行时序时，就会发生竞态条件。 常见的竞态条件类型就是“先检查后执行”操作，即通过一个可能失效的观测结果来决定下一步的动作：首先观察到某个条件为真（例如文件X不存在），然后根据这个结果采用相应的动作（创建文件X），但事实上，在你观察到结果以及开始创建文件之间，观察结果可能会失效（另一个线程在此期间创建了文件X），从而导致各种问题（某预期的异常、数据被覆盖、文件被破坏等）。 示例：延迟初始化中的竞态条件线程不安全的懒汉单例模式。 复合操作我们将“先检查后执行”、“读取-修改-写入”等称为复合操作：包含了一组必须以原子方式执行的操作以确保线程安全性。 书中采用了现有的线程安全类java.util.concurrent.atomic.AtomicLong原子变量，来实现在数值和对象引用上的原子状态转换（AtomicLong#incrementAndGet()）。 加锁机制如何想在Servlet中添加更多的状态，是否只需要增加更多的线程安全状态变量（如AtomicReference）就可以了？ 要保持状态的一致性，就需要在单个原子操作中更新所有相关的状态变量。 内置锁synchronized修饰的方法的锁就是方法调用所在的对象，static synchronized方法以Class对象为锁。 Java内置锁（也成为监视器锁Monitor Lock），相当于一种互斥锁，最多只有一个线程能持有。 重入内置锁是可重入的，如果某个线程试图获取一个已经由自己持有的锁，那么这个请求可以成功。 可重入意味着获取锁的粒度是线程，而不是调用。 重入的一种实现方式是，为每个锁关联一个所有者线程与获取计数器，计数器为0表示未被任何锁持有；重入时，计数器递增。 重入提升了加锁行为的封装性，简化了面向对象并发代码的开发。 同一对象内，一个synchronized方法调用另外一个synchronized不会出现死锁。 用锁来保护状态你需要自行构造加锁协议或者同步策略来实现对共享状态的安全访问，并且在程序中自始至终使用它。 一种常见的加锁约定：将所有可变状态都封装在对象内部，并通过对象的内置锁对所有访问可变状态的代码路径同步，使得在该对象上不会出现并发访问。常见的线程安全集合类如Vector、HashTable都使用了这种模式。 当类的不变性条件涉及到多个状态变量时，那么还有另外一个需求：在不变性条件中的每个变量都必须有同一个锁来保护。 另外，如果只是将每个方法加上synchronized，并不能保证符合操作都是原子的，如Vector： 123if (vector.contains(element)) &#123; vector.add(element);&#125; 活跃性与性能将Servlet#service()方法声明为synchronized虽然可以同步，每次只有一个线程可以执行，但这背离了Servlet框架的初衷。这种程序称之为不良并发（Poor Concurrency）：可同时调用的数量，不仅受到可用处理资源的限制，还受到程序本身结构的限制。 需要缩小同步代码块范围。 使用synchronized后不再使用Atomic变量，不推荐使用多种不同的同步机制。 使用锁时，如果持有锁时间过长（如执行时间很长的计算、网络IO等无法快速完成的操作），那么会带来活跃性或性能问题。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://xudongye.github.io/xdlog/tags/多线程/"},{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"请停止误用http-patch","slug":"design/请停止误用http-patch","date":"2017-04-13T16:00:00.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"design/请停止误用http-patch/","link":"","permalink":"https://xudongye.github.io/xdlog/design/请停止误用http-patch/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"请停止误用http-patch 修改http资源不是什么新鲜的话题。绝大多数现有的http或REST api都提供了修改资源的方式。他们通常通过对资源使用PUT动词来提供这样的特性，要求客户端发送整个资源实体被更新后的值。但是那就需要先对这个资源发一个GET请求，并且需要一种可以保证在这次GET调用与PUT调用之间不丢失任何更新的方法。（译者注：如果在GET调用之后，其他的客户端修改了这个资源，那么后面的这次PUT请求就会将这个修改覆盖掉。）并且，有的时候我们必须要考虑到，发送一个完整的实体，需要使用更多的带宽。很多时候你并不想更新所有的值，只是想更新资源的一两个属性值。所以PUT动词很可能不是部分更新————我们用来描述这种情况的术语 的正确的解决方式。 另外一种解决方式是暴露你想要编辑的属性名称，然后使用PUT动词发送更新后的值。在下面的例子中，user 123 的 email属性被暴露出来： 123PUT /users/123/emailnew.email@example.com 这种方式看上去是个很不错的方法，可以自行决定暴露什么不暴露什么。但是这也为你的API引入了许多复杂性（controller中更多的actions，路径定义，接口文档等等）。然而，REST是允许这样做的，这也是个不坏的方式。但是有一个更好的方案：PATCH。 PATCH是RFC5789中定义了的http动词。最开始想法是为了提出一个修改已存在资源的新的方式。这个动词最大的问题在于很多人误解了它的用途。不！PATCH 完全不是像第一段里描述的那样，关于用发送更新后的部分数值而不是整个资源的问题。请现在就停止那样使用！这是错误的： 123PATCH /users/123&#123; &quot;email&quot;: &quot;new.email@example.org&quot; &#125; 这也不对： 1PATCH /users/123?email=new.email@example.org PATCH动词在其请求体中发送了必须运用在URI指定的资源上的一系列变化。这一系列变化，包含了描述目前在服务器上的一个原始资源，应该怎样去修改，来产生一个新版本资源的指令。你可以把它看做一个diff。 123PATCH /users/123[description of changes] 通过PATCH动词，这个变化集合必须自动地完全被应用，API必须从不提供一部分成功的修改结果。（译者注：原子性，参考数据库事务进行理解。）值得一提的是，PATCH的请求体，可以是与被修改的资源不同的content-type。你必须使用一种为PATCH语义定义的media type，否则你就失去了这个动词的优势，可以使用PUT或者POST了。RFC里这样描述： The difference between the PUT and PATCH requests is reflected in the way the server processes the enclosed entity to modify the resource identified by the Request-URI. In a PUT request, the enclosed entity is considered to be a modified version of the resource stored on the origin server, and the client is requesting that the stored version be replaced. With PATCH, however, the enclosed entity contains a set of instructions describing how a resource currently residing on the origin server should be modified to produce a new version. The PATCH method affects the resource identified by the Request-URI, and it also MAY have side effects on other resources; i.e., new resources may be created, or existing ones modified, by the application of a PATCH. 对于这个改变的集合，你可以使用任意的格式，只要清晰定义了其语义。这也就是为什么用PATCH仅仅来发送更新后的值是不合适的。 RFC6902定义了一种使用于PATCH方式，来表达应用在JSON形式资源上的一系列操作 的JSON文档结构。 12345678[ &#123; \"op\": \"test\", \"path\": \"/a/b/c\", \"value\": \"foo\" &#125;, &#123; \"op\": \"remove\", \"path\": \"/a/b/c\" &#125;, &#123; \"op\": \"add\", \"path\": \"/a/b/c\", \"value\": [ \"foo\", \"bar\" ] &#125;, &#123; \"op\": \"replace\", \"path\": \"/a/b/c\", \"value\": 42 &#125;, &#123; \"op\": \"move\", \"from\": \"/a/b/c\", \"path\": \"/a/b/d\" &#125;, &#123; \"op\": \"copy\", \"from\": \"/a/b/d\", \"path\": \"/a/b/e\" &#125;] 这里依赖与JSON指针（详见RFC 6901）来定位JSON文档，也就是HTTP资源中的具体值。 通过PATCH方式修改user123的email应该像这样： 12345PATCH /users/123[ &#123; &quot;op&quot;: &quot;replace&quot;, &quot;path&quot;: &quot;/email&quot;, &quot;value&quot;: &quot;new.email@example.org&quot; &#125;] So readable, and expressive! Wonderful ♥这才是PATCH的正确使用方法。如果成功了，状态码返回200。 RFC5261为XML爱好者定义了一个用XML PATH语言（XPath）选择器来更新XML资源的XML PATCH框架。 2014年末，RFC提倡了一种新的JSON Merge Patch格式来发送变化的集合。这与只发送需要被修改的值的想法十分相似，但是由于application/merge-patch+json content-type使得它如此清晰明确。 总的来说，PATCH不是POST或者PUT方式的一个替代品。它是用来diff而不是替代整个资源。PATCH请求体是与被修改的资源不同的content-type。它是描述应用在资源上的改变，而不是整个资源的表现。 从现在起，如果不能正确地使用PATCH，那么就不要使用。 值得一提的是，PATCH其实不是为真正的REST API设计的。因为Fielding的论文没有定义任何一种部分修改资源的方式。但是Roy Fielding自己说了，PATCH是他为原始的HTTP/1.1协议设计的，因为部分的PUT根本就不RESTful。 原文地址：http://williamdurand.fr/2014/02/14/please-do-not-patch-like-an-idiot/","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"http","slug":"http","permalink":"https://xudongye.github.io/xdlog/tags/http/"},{"name":"翻译","slug":"翻译","permalink":"https://xudongye.github.io/xdlog/tags/翻译/"}]},{"title":"特殊字符u2028造成的javascript错误","slug":"javascript/特殊字符u2028造成的javascript错误","date":"2017-04-11T16:00:00.000Z","updated":"2020-12-18T02:51:05.441Z","comments":true,"path":"javascript/特殊字符u2028造成的javascript错误/","link":"","permalink":"https://xudongye.github.io/xdlog/javascript/特殊字符u2028造成的javascript错误/","excerpt":"","keywords":[{"name":"Javascript","slug":"Javascript","permalink":"https://xudongye.github.io/xdlog/categories/Javascript/"}],"text":"特殊字符u2028造成的javascript错误症状运用selenium RemoteWebDriver驱动phantomjs执行javascript脚本时，phantomjs抛出异常：123456789101112[ERROR - 2017-04-12T03:36:45.349Z] Session [feec3570-1f2a-11e7-8c8f-2d5cfc43fe3a] - page.onError - msg: SyntaxError: Unexpected EOF :262 in error[ERROR - 2017-04-12T03:36:45.350Z] Session [feec3570-1f2a-11e7-8c8f-2d5cfc43fe3a] - page.onError - stack: evaluateJavaScript (phantomjs://webpage.evaluate():14) evaluate (:387) _executeCommand (:/ghostdriver/request_handlers/session_request_handler.js:404) _handle (:/ghostdriver/request_handlers/session_request_handler.js:142) _reroute (:/ghostdriver/request_handlers/request_handler.js:61) _handle (:/ghostdriver/request_handlers/router_request_handler.js:78) :262 in error 背景知识学习RemoteWebDriverRemoteWebDriver是一个远程控制浏览器的规范接口。它提供了跨平台-语言无关的远距离查看与控制浏览器状态与行为的协议。 它提供了一系列的接口，来发现与操作网页中的dom元素，以及控制user agent的行为。它的原始意图是允许网站作者能够写出以一个单独的进程控制的自动化测试，也可以用作运行在浏览器内部的脚本来控制其他独立的浏览器。 比如： POST /session 新建会话 POST /session/{session id}/url 修改浏览器的地址并转向 POST /session/{session id}/refresh 刷新 POST /session/{session id}/elements 查找元素 POST /session/{session id}/element/{element id}/click 点击元素 POST /session/{session id}/execute/sync 同步执行脚本 可以看出，RemoteWebDriver试图模拟人类用户对浏览器的大部分操作，以实现自动化测试的目的。 selenium-remote在了解了RemoteWebDriver的基本原理之后，selenium-remote的功能就已经呼之欲出了：封装对RemoteWebDriver的访问过程，管理session，简化开发。 在debug了一遍其源代码之后，总结其主要功能有： 利用命令行启动phantomjs进程，如何调用GET /status接口查看其是否启动完成 管理session，对应的WebDriver对象 组织http request 利用Apache http client发送请求 解析http response，包括成功结果与错误信息 问题追踪 在了解了selenium-remote的基本原理后，怀疑其组织http request或解析http response有问题，将运行过程中的http request数据完全复制出来，拿到另外的发包工具（Fiddler）里发送后，得到如下错误： 12345678910111213141516171819202122232425262728293031323334353637&#123; &quot;errorMessage&quot;: &quot;Command failed without producing the expected error report&quot;, &quot;request&quot;: &#123; &quot;headers&quot;: &#123; &quot;Accept&quot;: &quot;application/json, image/png&quot;, &quot;Connection&quot;: &quot;Keep-Alive&quot;, &quot;Content-Length&quot;: &quot;136661&quot;, &quot;Content-Type&quot;: &quot;application/json; charset=utf-8&quot;, &quot;Host&quot;: &quot;localhost:26246&quot; &#125;, &quot;httpVersion&quot;: &quot;1.1&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;post&quot;: &quot;&#123;\\&quot;args\\&quot;:[],\\&quot;script\\&quot;:&quot;实际的js语句&quot;, &quot;url&quot;: &quot;/execute&quot;, &quot;urlParsed&quot;: &#123; &quot;anchor&quot;: &quot;&quot;, &quot;query&quot;: &quot;&quot;, &quot;file&quot;: &quot;execute&quot;, &quot;directory&quot;: &quot;/&quot;, &quot;path&quot;: &quot;/execute&quot;, &quot;relative&quot;: &quot;/execute&quot;, &quot;port&quot;: &quot;&quot;, &quot;host&quot;: &quot;&quot;, &quot;password&quot;: &quot;&quot;, &quot;user&quot;: &quot;&quot;, &quot;userInfo&quot;: &quot;&quot;, &quot;authority&quot;: &quot;&quot;, &quot;protocol&quot;: &quot;&quot;, &quot;source&quot;: &quot;/execute&quot;, &quot;queryKey&quot;: &#123;&#125;, &quot;chunks&quot;: [ &quot;execute&quot; ] &#125;, &quot;urlOriginal&quot;: &quot;/session/010c8a30-1c06-11e7-bf38-73a6c09b43c0/execute&quot; &#125;&#125; 基本看不出错误的原因，但是可以排除是类库组织http request的问题。 查看phantomjs日志 123456789101112[ERROR - 2017-04-12T03:36:45.349Z] Session [feec3570-1f2a-11e7-8c8f-2d5cfc43fe3a] - page.onError - msg: SyntaxError: Unexpected EOF :262 in error[ERROR - 2017-04-12T03:36:45.350Z] Session [feec3570-1f2a-11e7-8c8f-2d5cfc43fe3a] - page.onError - stack: evaluateJavaScript (phantomjs://webpage.evaluate():14) evaluate (:387) _executeCommand (:/ghostdriver/request_handlers/session_request_handler.js:404) _handle (:/ghostdriver/request_handlers/session_request_handler.js:142) _reroute (:/ghostdriver/request_handlers/request_handler.js:61) _handle (:/ghostdriver/request_handlers/router_request_handler.js:78) :262 in error 这个错误也相当模糊，看上去是js语法出现了问题。 将运行的js代码复制到chrome控制台执行，这时候才第一次仔细观察要执行的js语句。 1window.articles = [&#123;\"id\":26802,\"title\":\"猫驯记_12_小白\",\"content\":\"&lt;div class=\\\"show-content\\\"&gt;\\n &lt;blockquote&gt;&lt;p&gt;猫也是人类最好的朋友，但它们绝不会屈尊承认这件事。&lt;br&gt; \\u2014\\u2014Doug Larson，作家&lt;\\/p&gt;&lt;\\/blockquote&gt;\\n&lt;p&gt;很久以前的那只小白猫似乎没有这么活泼。不知道是星座、血型还是性别原因\\u2026\\u2026反正小白就是比较沉稳。对，他叫小白。&lt;\\/p&gt;\\n&lt;p&gt;那时我在一个旧小区里租了套旧房子住，房东是个酷爱安利产品、并且将推广安利视为人生目标的老太太。安利老太太本来打算把这套房子按照学校宿舍风格装修\\u2014\\u2014在所有空间里都摆上双层铁架床，而且尽量省钱\\u2014\\u2014不过可能是高估了租客对双层床的偏好，最终剩下大堆床架床板，都胡乱塞在厅里。&lt;\\/p&gt;\\n&lt;p&gt;那套房间在一楼，空间不大，阳光不多，水泥地面冰凉。厨房和洗手间几乎是原生态，木门上涂了层黄漆，早已片片斑驳。&lt;\\/p&gt;\\n&lt;p&gt;小白第一次看见这套房子，抬头看了看我，然后往我手里吐了个泡泡。那天天气很热，他中暑了。&lt;\\/p&gt;\\n&lt;p&gt;当时小白很小，才和我手掌差不多长。尾巴细细瘦瘦，脑袋大大的，总是睁一只眼闭一只眼。脑袋上一小撮黑毛滑稽地竖着，身上的白毛还不够长，能看见粉红色的皮肤。&lt;\\/p&gt;\\n&lt;p&gt;小白在我手里不住吐泡泡，口水把下巴洇湿了一片。我也没什么经验，只能捧着他走来走去通风，帮他擦嘴角的口水。又倒了点水端到他嘴边，直到他开始喝水，才放心了下来。&lt;\\/p&gt;\\n&lt;p&gt;我去跟附近工地的工人们要了些沙子，又去买了点肉。回到家，发现小白不见了。&lt;\\/p&gt;\\n&lt;p&gt;那套房子基本上一览无余。两个旧沙发、一张折叠桌，剩下就是几张双层床。窗户和门都关好了，小家伙能跑到哪里去呢？&lt;\\/p&gt;\\n&lt;p&gt;不在厨房，也不在洗手间。唯一的可能，就是在那堆床板床架里。&lt;\\/p&gt;\\n&lt;p&gt;\\u201c喵？\\u201d我叫。&lt;\\/p&gt;\\n&lt;p&gt;没有回应。&lt;\\/p&gt;\\n&lt;p&gt;那堆床板床架结构很复杂，充满巧夺天工的随意感，像是实体化的混沌。我不敢动任何一块，因为那东西倒下来的方向和位置完全无法预测。我只能向每个缝隙里张望，点亮手机屏幕来照明，一边喵喵叫个不停。&lt;\\/p&gt;\\n&lt;p&gt;该死，我甚至连个手电都没有。&lt;\\/p&gt;\\n&lt;p&gt;我在考虑要不要去买个手电的时候，听到一声细细的\\u201c喵~~\\u201d。声音弱得让我怀疑自己幻听。&lt;\\/p&gt;\\n&lt;p&gt;\\u201c喵~~\\u201d又一声，细细弱弱怯生生的。是真的。&lt;\\/p&gt;\\n&lt;p&gt;我终于看见小白，在靠墙的角落里，紧贴着墙。两只大眼睛望着我，小下巴微微发抖。&lt;\\/p&gt;\\n&lt;p&gt;可是我够不着他。&lt;\\/p&gt;\\n&lt;p&gt;我坐在地上，和小白隔着一大堆杂物沟通。&lt;\\/p&gt;\\n&lt;p&gt;\\u201c过来吧，来喝水？\\u201d&lt;\\/p&gt;\\n&lt;p&gt;\\u201c过来，来吃肉？\\u201d\\u2028&lt;\\/p&gt;\\n&lt;p&gt;小白惊恐地望着我。&lt;\\/p&gt;\\n&lt;p&gt;\\u201c乖，来，要上厕所吗？\\u201d我尽可能把声调再调整柔和一点。&lt;\\/p&gt;\\n&lt;p&gt;小白犹犹豫豫走近了两步，站住了。我伸出手，他又退后两步。&lt;\\/p&gt;\\n&lt;p&gt;我们就这样僵持了一下午。直到第二天早上，小白还缩在杂物堆里，偶尔轻轻叫一声。&lt;\\/p&gt;\\n&lt;p&gt;我下班回来，才看见杂物堆里探出一颗小脑袋，圆溜溜两只眼睛盯着我。头顶上的一撮黑毛还竖着，身上的颜色像是用久了的白麻布。&lt;\\/p&gt;\\n&lt;p&gt;\\u201c小白？\\u201d我慢慢走近。&lt;\\/p&gt;\\n&lt;p&gt;\\u201c喵~~\\u201d他回应，退后了一步，站住了。&lt;\\/p&gt;\\n&lt;p&gt;我伸手把他抱起来，他没躲开。小肚子扁扁的，细细的小肋骨根根分明。&lt;\\/p&gt;\\n&lt;p&gt;\\u201c我们是室友啦。\\u201d我对他说，\\u201c请多多关照啊。\\u201d&lt;\\/p&gt;\\n&lt;p&gt;小白的肚子贴在我手心，轻轻叫了一声。&lt;\\/p&gt;\\n\\n &lt;\\/div&gt;\"&#125;];window.pageSizeId = 1; 敏锐的观察到，其中有些很奇怪的Unicode字符。我好好的发送http请求，为什么要把我的字符转化为Unicode形式呢，看来还是组织http request的代码出了问题。 跟踪selenium-remote源码，发现其使用的json化工具org.json:json会将某些字符转化为Unicode 123456789default: if (c &lt; ' ' || (c &gt;= '\\u0080' &amp;&amp; c &lt; '\\u00a0') || (c &gt;= '\\u2000' &amp;&amp; c &lt; '\\u2100')) &#123; t = \"000\" + Integer.toHexString(c); sb.append(\"\\\\u\" + t.substring(t.length() - 4)); &#125; else &#123; sb.append(c); &#125;&#125; 尝试缩小js范围，将每个Unicode替换为其实际字符，最后发现/u2028不是正常字符，而是一个Line Separator。反复对比后发现，这个字符是造成phantomjs执行js报错的直接导火索。 找出直接原因，u2028为行分隔符，而javascript中字符串表达式不允许换行，从而导致执行错误。 问题总结这里javascript对行分隔符的解析，可以看出一个动态语言的尴尬之处：不同于Java等静态语言，由于这个javascript表达式是运行时生成的，所以解释器很难判断出，这个行分隔符是源代码中作者在试图换行，还是字符串的内容包含了航分隔符。显然，这里javascript解释器认为脚本中包含了一个包含真正断行，而不是行分隔符的字符串表达式，于是判定为语法错误。 而这个数据的来源，可能是Java语言，在处理这个字符串的过程中，就不存在这个问题，于是可以顺利得将数据传递到这里交由javascript执行。 那么问题来了，javascript中，到底要如何表示多行字符串呢？ 可行的方法： 手动\\n 1var multiple_lines = \"举头望明月\\n低头思故乡\"; 结尾反斜线 12var multiple_lines = \"举头望明月\\ 低头思故乡\"; 字符串join(‘\\n’) 1var multiple_lines = [\"举头望明月\", \"低头思故乡\"].join('\\n'); 修复问题在数据源头将u2048字符删去 Reference WebDriver 特殊字符_u2028导致的Javascript脚本异常 - 良村 - 博客园 javascript的几种使用多行字符串的方式","categories":[{"name":"Javascript","slug":"Javascript","permalink":"https://xudongye.github.io/xdlog/categories/Javascript/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://xudongye.github.io/xdlog/tags/Javascript/"},{"name":"编码","slug":"编码","permalink":"https://xudongye.github.io/xdlog/tags/编码/"}]},{"title":"IOC容器之根接口BeanFactory","slug":"java/spring/spring源代码学习笔记/1IOC容器之根接口BeanFactory","date":"2017-03-15T16:00:00.000Z","updated":"2020-12-18T02:51:05.425Z","comments":true,"path":"java/spring/spring源代码学习笔记/1IOC容器之根接口BeanFactory/","link":"","permalink":"https://xudongye.github.io/xdlog/java/spring/spring源代码学习笔记/1IOC容器之根接口BeanFactory/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"IOC容器之根接口BeanFactoryBeanFactoryBeanFactory提供了ioc容器最基础的访问接口，可以说是spring框架庞大的ioc体系的树根。 BeanFactory接口规定了其实现必须具有以下特性： 装载了一定数量的bean定义，每个定义以一个独一无二的spring name来标识。 bean定义了某种scope:Singleton/Prototype singleton: 对单例模式的优化，实例在factory范围内唯一 prototype: 原型模式，每次返回一个独立的实例 BeanFactory乃至其背后的ioc思想，本质上代表了应用组件的中心化注册、配置与管理，采用依赖注入的Push模式，而不是类似于主动查找的Pull模式。 BeanFactory的方法十分简单，主要分为以下几组： 根据名称、类型获取bean，包括一些简单的泛型重载 查询一个bean的存在与否/scope/type/alias HierarchicalBeanFactoryHierarchicalBeanFactory为BeanFactory扩展了层级特性，提现在两个增加的方法定义上： 12BeanFactory getParentBeanFactory();boolean containsLocalBean(String name); SingletonBeanRegistry定义了单例bean的registry，通常被BeanFactory实例所实现，暴露出统一的单例bean管理行为。主要包括注册singleton、获取singleton等系列方法。 ConfigurableBeanFactory看过HierarchicalBeanFactory的定义，很奇怪，为什么只有getParentBeanFactory方法，没有set。spring开发者将set方法放在HierarchicalBeanFactory的子接口ConfigurableBeanFactory中，ConfigurableBeanFactory同时extends SingletonBeanRegistry。为什么没有直接将setParentBeanFactory放在HierarchicalBeanFactory中呢？","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"},{"name":"spring","slug":"spring","permalink":"https://xudongye.github.io/xdlog/tags/spring/"}]},{"title":"隐式依赖也是依赖","slug":"design/隐式依赖也是依赖","date":"2016-12-22T16:00:00.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"design/隐式依赖也是依赖/","link":"","permalink":"https://xudongye.github.io/xdlog/design/隐式依赖也是依赖/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"隐式依赖也是依赖 Implicit Dependencies Are also DependenciesOnce upon a time a project was developed in two countries. It was a large project with functionality spread across different computers. Each development site became responsible for the software running on one computer, had to fulfill its share of requirements and do its share of testing. The specification of the communication protocol became an early architectural cornerstone. 从前，有一个在2个国家开发的项目，它的功能分散在不同的电脑上。每个开发站负责这个软件在一台电脑上运行，并且必须完成被分配的需求及测试。这个交流协议的规定，变成了项目最早的架构基础。 A few months later, each site declared victory: The software was finished! The integration team took over and plugged everything together. It seemed to work. A bit. Not much though: As soon as the most common scenarios were covered and the more interesting scenarios were tested, the interaction between the computers became unreliable. 几个月之后，各个站点都宣布胜利：这个软件完成了！集成团队接管了工程，并将一切组合在一起。好像可以了。等等，现在有个小问题：虽然大部分的模块都覆盖了测试，但电脑之间的相互作用却十分不可靠。 Confronted with this finding, both teams held up the interface specification and claimed their software conformed to it. This was found to be true. Both sides declared victory, again. No code was changed, and they developed happily ever after. 面对这个发现，各个团队都举起了接口规范书，表示自己的软件完全符合规范。这确实是真的。然后双方又宣布了成功。他们没有修改任何代码，从此还是高高兴兴地开发。 The moral is that you have more dependencies than all your attempts for decoupling will let you assume you have. 这个故事的寓意是，经过各种解耦的努力，你比你自以为的解耦具有更多的依赖。 Software components have dependencies, more so in large projects, even more when you strive to increase your code reuse. But that doesn’t mean you have to like them: Dependencies make it hard to change code. Whenever you want to change code others depend on, you will encounter discussion and extra work, and resistance from other developers who would have to invest their time. The counterforces can become especially strong in environments with a lengthy development micro cycle, such as C++ projects or in embedded systems. 软件组件之间相互依赖，在大项目中依赖更多，当你努力提高代码重用性时，依赖甚至更多。但是那并不意味着你必须喜欢依赖：依赖让修改代码十分困难。每当你想修改他人依赖的代码时，你就会遇到讨论以及他们额外的工作，以及来自其他必须要投入自己时间的开发者的阻力。在经过长期开发的C++项目或者嵌入式系统的环境中，这个阻力会变得特别大。 Many technical approaches have been adopted to reduce suffering from dependencies. On a detailed level, parameters are passed in a string format, keeping the interface technically unchanged, even though the interpretation of the string’s contents changes. Some shift in meaning could be expressed in documentation only; technically the client’s software update could happen asynchronously. At a larger scale, component communication replaces direct interface calls by a more anonymous bus where you do not need to contact your service yourself. It just needs to be out there somewhere. 人们采用了很多技术手段来减轻依赖带来的痛苦。比如在细节层面，用字符串传递参数，来保证即使这个字符串内容的解释发生了变化，但接口形式技术上保持不变。一些意义的改变只能用文档材料来表达；技术上来说，客户端软件可以异步更新。比如说更高的层面，使用匿名事件总线代替直接的接口调用来完成组件之间的交流通信，这样你都不用自己去联系你的服务，它只需要在某个地方是存在的就好了。 These techniques actually make it harder to spot the underlying implicit dependencies. Let’s rephrase the moral a bit: Obfuscated dependencies are still dependencies. 实际上，这些技术使潜在的隐形依赖更加难以辨认。让我们稍微改一下寓言的表述：模糊的依赖也是依赖。 Source-level or binary independence does not relieve you or your team from dependency management. Changing an interface parameter’s meaning is the same as changing the interface. You may have removed a technical step such as compilation, but you have not removed the need for redeployment. Plus, you’ve added opportunities for confusion that will boomerang during development, test, integration, and in the field — returning when you least expect it. 代码或二进制层面的解耦，并不会把你或你的团队从依赖管理中解脱出来。改变接口参数的意义与改变接口是一样的。也许你去掉了比如编译期的技术改动，但是你根本没有改变需要改动的事实。并且，你还增加了在开发、测试、集成、回归过程中产生混淆的机会，而这，是你最不想要的。 Looking at sound advice from software experts, you hear Fred Brooks talking you into conceptual integrity, Kent Beck urging once and only once, and the Pragmatic Programmers advising you to keep it DRY (Don’t Repeat Yourself). While these concepts increase the clarity of your code and work against obfuscation, they also increase your technical dependencies — those that you want to keep low. 听听软件专家们的忠告，Fred Brooks告诫你概念完整性，Kent Beck 敦促你程序员要保持DRY(Don’t Repeat Yourself)。当这些理念在提高你代码的清晰度、与混淆与困惑对抗时，他们也在增加你想保持在低水平的表面的技术依赖。 The moral is really about: Application dependencies are the dependencies that matter. 这个寓言其实是说：应用的依赖，就是与之相关的依赖的总和。（垃圾翻译，请看原文） Regardless of all technical approaches, consider all parts of your software as dependent that you need to touch synchronously, in order to make the system run correctly. Architectural techniques to separate your concerns, all technical dependency management will not give you the whole picture. The implicit application dependencies are what you need to get right to make your software work. 不管所有技术上的手段，为了确保整个系统能正确地运行，必须把软件当做需要同时去考虑的独立部分。作为分割你关注点的架构技巧，所有的依赖管理技术都不能给你一个完整的图景。为了保证你系统最终能够工作，你需要清晰地了解应用的隐形依赖。 原文地址","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"面向对象","slug":"面向对象","permalink":"https://xudongye.github.io/xdlog/tags/面向对象/"},{"name":"解耦","slug":"解耦","permalink":"https://xudongye.github.io/xdlog/tags/解耦/"},{"name":"翻译","slug":"翻译","permalink":"https://xudongye.github.io/xdlog/tags/翻译/"}]},{"title":"单线程的javascript","slug":"javascript/单线程的javascript","date":"2016-11-30T06:51:49.000Z","updated":"2020-12-18T02:51:05.441Z","comments":true,"path":"javascript/单线程的javascript/","link":"","permalink":"https://xudongye.github.io/xdlog/javascript/单线程的javascript/","excerpt":"","keywords":[{"name":"Javascript","slug":"Javascript","permalink":"https://xudongye.github.io/xdlog/categories/Javascript/"}],"text":"单线程的javascript一个有趣的死循环bug在略去这个bug所有的外围细节后，我试图还原一个最小化的场景： 现在需要使用js将一个图片列表依次动态添加到页面上，但是有一个限定条件，在前一张图片没有加载完成之前，后一张图片不得抢先加载，必须等待前一张load事件触发。 这有何难： 1234567891011121314// 引入jQuery// imgs 是图片数组for (var i = 0, len = imgs.length; i &lt; len; i ++)&#123; var img = imgs[i]; $(document.body).append(img); var imgLoadSuccess = false; img.on('load', function() &#123; imgLoadSuccess = true; console.log('img ' + img.attr('src') + ' load success.ready to load the next one.'); &#125;); while(!imgLoadSuccess) &#123; // wait until im load success &#125;&#125; 从一个java开发者看来，这里的流程是这样的： 然而结果是，浏览器的javascript进入了一个可耻的死循环，并且图片也没有添加成功，load事件的回调方法也从来没有执行过。 javascript为什么是单线程的很多javascript开发者在接触js的第一天就会看到一句话：JavaScript是单线程运行的。 结合javascript语言作为浏览器脚本语言的最初用途，其实这个设定还是比较容易被接受的：作为浏览器脚本语言，javascript的主要用途，就是与用户互动以及操作DOM元素，很明显如果多线程操作dom元素，将会大大提高问题的复杂度。 所以javascript在设计之初就定下了单线程这个核心特征。 随着js应用开发经验的日渐丰富，甚至promise编程的熟悉，这句话令一个java开发者更加百思不得其解，这么多的事件回调、ajax异步请求、promise编程，都是在做异步编程的事情，明明是在并发，为什么说javascript是单线程运行呢？ 任务队列javascript语言的单线程特性，就意味着所有的任务其需要排队。那么各种各样的回调与异步编程是如何实现的呢？ 稍有js异步编程经验的开发者其实都知道，通常需要使用异步编程的场景，都是与IO操作有关。由于IO操作的速度与cpu运算有数量级上的差距，所以将这些IO操作返回结果之后的任务都设置为异步任务。 所以单线程js的异步运行机制如下： 所有同步任务都在主线程上执行，形成了一个“执行栈” 主线程之外，存在一个“任务队列”，只要异步任务返回了结果，就向“任务队列”中添加一个事件 一旦“执行栈”中所有同步任务执行完毕，执行引擎就会去读取“任务队列”，将其队头的异步任务加入执行栈，开始执行 主线程不停重复以上三步 所以，上面那个死循环的代码其实是这样运行的： 利用事件机制实现异步编程俗话说，在什么山上唱什么歌。在单线程、使用任务队列的javascript语境下，就不应该再使用多线程同步的思维，类似于java中Object#await()/notifyAll()方法来锁住/唤醒线程，而应该也运用事件机制，将某些需要唤醒的进程任务，用事件来触发。 为了不让数组中的图片在主线程中一次性全部添加进页面，将每个添加单张图片的行为封装成一个函数，并且利用图片加载事件来触发。为了保存待添加图片的数组下标，必须将这个参数保存在函数之外的内存区域。 重构后的伪代码：123456789101112131415var imgIndex = 0;function appendImg() &#123; if (imgIndex &gt;= imgs.length) &#123; return; &#125; var img = imgs[imgIndex]; $(document.body).append(img); img.on('load', function() &#123; console.log('img ' + img.attr('src') + ' load success.ready to load the next one.'); imgIndex ++; appendImg(); &#125;); console.log('img ' + img.attr('src') + ' append to document. wait util loaded.');&#125;appendImg(); 与多线程实现方式的对比将之前运用多线程思维的bug版代码与重构后的代码对比，可以看出其中关键性的区别，在于保存了图片数组的当前被处理的元素下标。 这个下标，其实相当于循环中的局部变量。对应于多线程语言如Java在单CPU下的线程切换，其实这个下标就是方法执行的栈桢。线程切换时，执行引擎必须将这个失去CPU的线程的栈桢保存起来，以便下次这个线程重新获得CPU时间的时候，能够把这个栈桢中的数据取出来，重新恢复上下文的执行环境。 而这里的javascript单线程实现方式，也可以类比为：添加图片元素的线程appendImg()方法，通过结束代码的方式放弃CPU使用权，将栈桢中的数据，也就是数据下标保存到不被GC的window对象中。下次appendImg()方法重新被任务队列唤醒，获取到CPU时，可以直接从window对象中获取上下文环境，继续执行添加任务。 某种程度上说，我这里是在用java的思想，实现本应由底层实现的线程调度。 对于我需要实现的排版算法，基本思路已有蓝图，对于习惯了多线程的开发者来说，利用单线程的事件机制来实现异步编程主要要处理好三件事情： 线程通过代码执行完毕来放弃CPU时间 在js中，是绝不会出现阻塞主线程的方式的，因为根本没有主线程，js只有一个线程。 如果希望代码停止执行，那么必须让同步任务执行完毕。 线程通过注册事件来给自己定义下次获取CPU时间的时机 如果希望线程在某种情况下被唤醒，那么可以通过注册事件（定时器本质上也是一种事件：时间到了），将自己作为回调函数保存起来。 栈桢数据的保存与恢复 为了下次线程重新获取CPU时能够正常执行，必须将线程内部的局部变量情况–栈桢自行保存，下次再进行恢复。 在本文的最小化demo中，只有一个循环的逻辑，所以栈桢结构非常简单，只是一个简单的数组下标。 但是在真实的方法层层调用、各种逻辑分支的控制情况下，其实上下文执行环境的数据必然是一个先进后出的栈的结构，如何妥善地保存与恢复这些数据，可以参考jvm底层原理。 致歉本文完全从一个习惯了多线程运行的java开发者的视角去思考javascript异步机制，js原住民请忽略。 参考文献 JavaScript 运行机制详解：再谈Event Loop - 阮一峰网络日志 深入理解JavaScript定时机制|Sina App Engine Blog 细说JavaScript单线程的一些事 — 好JSER [译]解析JavaScript的事件循环机制","categories":[{"name":"Javascript","slug":"Javascript","permalink":"https://xudongye.github.io/xdlog/categories/Javascript/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://xudongye.github.io/xdlog/tags/Javascript/"},{"name":"多线程","slug":"多线程","permalink":"https://xudongye.github.io/xdlog/tags/多线程/"}]},{"title":"利用浏览器优化排版算法的方案","slug":"algorithm/利用浏览器优化排版算法的方案","date":"2016-11-29T03:19:40.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"algorithm/利用浏览器优化排版算法的方案/","link":"","permalink":"https://xudongye.github.io/xdlog/algorithm/利用浏览器优化排版算法的方案/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"利用浏览器优化排版算法的方案问题分析无论是犁书项目之前的将社交网络的简单文本与图片列表信息整理排版，还是将富文本内容排版成册，其本质是两件事： 将原有的数据按照我们的样式规则进行排列，如果是带有样式的富文本，那么将原有样式与模板样式相结合 根据DOM元素的高度除以页的高度进行断页(break page) 那么对于排版算法，尤其是富文本的排版，其最大的难点与工作量在于： 解析各种html标签与样式，计算出dom元素的高度，以便在合适的地方断页 递归dom树形结构，将其转换为以树为元素的线性集合 浏览器计算元素高度对于解析html标签、样式来说，如果不拘泥于现在的用java代码的Font库逐步计算每个字符的宽高、何时换行这种造轮子的方式，很容易想到，最简单直接的方法，就是利用浏览器的渲染引擎以及javascript代码来获取dom元素的高度。 那么问题就在于，谁来打开这个浏览器，谁来输入这样的url进行访问，谁来向服务器报告dom元素的高度？很显然，不可能是用户，用户的浏览器千差万别，把数据交由一个情况不明的用户浏览器来创造肯定是不符合常理的。 于是希望尝试使用“服务端无图形界面虚拟浏览器”————phantomjs来担此重任。 排版步骤 服务器获取内容数据 提供一个查询内容数据的Rest API接口 服务器启动一个phantomjs的子线程，打开对应url的网页，载入内容数据 在网页中，使用javascript代码完成实际排版 将html文本解析为虚拟dom树，并准备活动页dom树 递归遍历dom树元素，并准备两个集合作为主要操作对象： dom元素类型栈：保存由根元素向当前被操作的叶元素的类型，注意ol.li是第几个以设置新的ol.start 活动原子队列：根据排版逻辑确定不可分割的最小原子元素，如单个字符、单张图片、一条标题，将已经开始排列的原子元素逐一向网页中添加 监听实际dom树的元素增加事件，获取页面已有元素高度，判断是否达到书页底部 监听断页事件，将活动页dom元素回滚一个版本后，保存至实际dom树列表 排版完成后，将dom元素情况提交服务器 将排版情况数据发送到服务器进行保存 网页利用事件通知phantomjs结束线程 模型设计 TableOfContents 保存目录结构 PageLayout 保存单页的排版数据 isValid() 判断是否有效，如果无效，客户端必须等待 当work内容发生变化时，必须将isValid()设置为false","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"lebooks-private","slug":"lebooks-private","permalink":"https://xudongye.github.io/xdlog/tags/lebooks-private/"},{"name":"phantomjs","slug":"phantomjs","permalink":"https://xudongye.github.io/xdlog/tags/phantomjs/"}]},{"title":"基于angular与nginx的SPA的SEO方案","slug":"design/基于angular与nginx的SPA的SEO方案","date":"2016-11-24T02:38:24.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"design/基于angular与nginx的SPA的SEO方案/","link":"","permalink":"https://xudongye.github.io/xdlog/design/基于angular与nginx的SPA的SEO方案/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"基于angular与nginx的SPA的SEO方案问题背景出于动静分离的考虑，喵书项目选择了SPA(Single Page Application)，并且也从中尝到了很大的甜头： 用户体验好，响应速度快 前后分离，各司其职，并行开发 减轻服务器压力，主要输出数据 同一套后台代码可用于Web与app 同时，对于一个以生产内容为主的SPA，就面临了一个十分严峻的问题：SEO(search engine optimization)。 这个问题的本质其实是由于搜索引擎的爬虫不会执行网页的javascript代码，所有依靠javascript获取的数据、改变的dom元素都无法被收录，与SPA这种形式并没有关系，只是对SPA来说尤为突出。 Googlebot的协议google应该早就为开发者考虑到这个问题，所以googlebot（google搜索引擎的爬虫程序）为SPA开发者建立了一个协议，专门来解决javascript动态渲染的网站的爬取问题。 googlebot会将http://localhost:3000/#!/profiles/1234改成http://localhost:3000/?_escaped_fragment_=/profiles/1234爬取。 基于这个协议，只需要为带有_escaped_fragment_参数的请求提供不依靠javascript动态渲染的静态页面，就可以让爬虫拿到开发者希望被收录的数据。 而phantomjs就是这个帮助开发者由动态渲染生成静态文件的，基于Webkit的服务端javascript API。在这里起到的作用，就是模拟用户的浏览器，来生成与用户所看到的页面类似的html页面。 各种爬虫的兼容性难题如果只需要支持googlebot的爬取，那么基于上面的协议就已经能着手解决问题。 但是，由于我们生活在一个特殊的国度，这里的搜索引擎不是google，而是百度、360、搜狗、有道等，以他们各自为战互相抹黑的态势，根本没办法保证他们遵守google的协议。 所以必须采用各种搜索引擎都能兼容的方案，才能做出本土化的SEO方案。 用mod_rewrite自定协议检查http请求的user-agent，应该是最快的识别出搜索引擎网络爬虫的方法。 再运用服务端的某种设置，就完全可以自己制定一个类似于Googlebot escaped fragment协议的协议（推荐直接相同）。 实现原理如下： 服务端检测http-request.user-agent是否是爬虫，如果不是，则正常返回用户页面； 如果是网络爬虫，那么将经过一定规则改变的静态页面作为响应返回给爬虫。 由于我们使用nginx提供服务，nginx配置范例： 12345678910location / &#123; if ($http_user_agent ~* &apos;(Googlebot|Mediapartners-Google|AdsBot-Google|bingbot|Baiduspider|yahooseeker)&apos;) &#123; rewrite ^(.*)$ /seo-site/$1; &#125; ...用户浏览器服务配置&#125;location /seo-site/ &#123; ...静态页服务配置&#125; 那么问题就只剩下如何搭建这个提供静态页的服务，以及如何制定一个合理的rewrite规则来同时兼容SPA带#号的地址与HTML5模式不带#的地址了。 Prerender参考文献google ajax crawling nginx配置location总结及rewrite规则写法 nginx配置范例","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://xudongye.github.io/xdlog/tags/nginx/"},{"name":"SPA","slug":"SPA","permalink":"https://xudongye.github.io/xdlog/tags/SPA/"},{"name":"SEO","slug":"SEO","permalink":"https://xudongye.github.io/xdlog/tags/SEO/"}]},{"title":"Server和Service","slug":"java/tomcat/深入剖析tomcat学习笔记/14Server和Service","date":"2016-11-15T10:11:01.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"java/tomcat/深入剖析tomcat学习笔记/14Server和Service/","link":"","permalink":"https://xudongye.github.io/xdlog/java/tomcat/深入剖析tomcat学习笔记/14Server和Service/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"Server和ServiceServer接口Server接口的实例，表示Catalina整个servlet容器，囊括了所有组件。 服务器组件提供了一种非常优雅的方法来启动/关闭整个系统，不再对连接器和容器分别操作：当启动服务器组件时，它会启动其中所有的组件，然后就无限期地等待关闭命令；如果需要关闭服务器组件，向指定端口发送一条关闭命令，服务器组件接收到关闭命令后，就会关闭其中的所有组件。 123456789101112131415161718192021222324public interface Server &#123; // ------------------------------------------------------------- Properties // 顶级的全局naming resource public NamingResources getGlobalNamingResources(); public void setGlobalNamingResources(NamingResources globalNamingResources); // 关闭命令的监听接口 public int getPort(); public void setPort(int port); // 关闭命令字符串 public String getShutdown(); public void setShutdown(String shutdown); // --------------------------------------------------------- Public Methods public void addService(Service service); public Service findService(String name); public Service[] findServices(); public void removeService(Service service); public void await(); // 启动之前的初始化行为 public void initialize() throws LifecycleException;&#125; StandardServer类StandardServer类有4个与生命周期有关的方法：initialize()/start()/await()/stop() initialize()方法initialize()方法主要用来初始化其中的服务组件。12345678910public void initialize() throws LifecycleException &#123; if (initialized) throw new LifecycleException ( sm.getString(\"standardServer.initialize.initialized\")); initialized = true; // Initialize our defined Services for (int i = 0; i &lt; services.length; i++) &#123; services[i].initialize(); &#125;&#125; start()/stop()方法与initialize()类似，触发相应的事件，循环遍历逐一启动其中service组件。 await()方法await()方法负责等待关闭整个tomcat部署的命令。 await()方法创建一个监听默认为8005端口的server socket，循环调用serverSocket.accept()方法等待连接，得到其中字符串时与约定的关闭命令字符串相比较，如果匹配成功，则跳出循环，结束await()方法。 Service接口Service接口实例是一个或多个组成的一组连接器共享一个单独的servlet容器来处理接受到的请求。这样的设定允许了一个http和一个https连接器共享同一个web应用程序。 StandardService类connector和containerStandardService实例中有两种组件，connector和container，其中servlet容器只有一个，而连接器可以多个，使tomcat可以为多种不同的协议提供服务。 StandardService类的属性：12private Container container = null;private Connector connectors[] = new Connector[0]; 与生命周期有关的方法initialize()：循环遍历调用了connectors[i].initialize()来初始化所有的连接器。 start()/stop()：触发相关事件，并循环遍历启动/关闭其中连接器以及容器。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://xudongye.github.io/xdlog/tags/tomcat/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"电商系统运费计算模块设计","slug":"design/电商系统运费计算模块设计","date":"2016-11-15T03:17:45.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"design/电商系统运费计算模块设计/","link":"","permalink":"https://xudongye.github.io/xdlog/design/电商系统运费计算模块设计/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"电商系统运费计算模块设计本文试图做一个模型设计上的思考试验，试图在需求没有细化、很有可能需要变更的情况下，做一个高度弹性、能充分应对需求变更的数据结构设计。 而电商系统的运费计算模板设计，是一个很常见的功能，虽然每个系统可能有一些定制化的要求，但总体的方式应该是在一定范围内的，主要参考淘宝、京东（有自营店）的常见方式。 所以以此做一个数据结构设计训练的发端与范例。 总体需求说明系统能够根据客户选择的运送方式快递类型，以及用户所在的地区自动计算运费 设计需求与约束说明 模板需要支持包邮与不包邮 计费方式需要支持固定邮费、按件、按重量、按体积，并且需要支持2段计费，如10kg以内10元，每增加1kg加0.5元 支持用户选择不同的快递类型，但计费方式与运送区域可由商家配置 支持条件包邮，条件包括订单满一定金额（考虑跨店订单不能累加）、处于一定区域、商品数量在一定范围内，条件可并列，且支持多个条件（可支持and/or） 分区域计费的粒度暂时定为省级别，且可以直接设置全国默认 表结构设计从上述需求可以看到有三个对象：整体计费模板、包邮条件、计费方式 初步表设计如下： 运费计算规则-FreightRule 列名 数据类型 备注 规则名称-name string - 是否包邮-free boolean 不包邮规则必须绑定计费方式 是否条件包邮-freeConditional boolean 选择条件包邮的规则必须绑定包邮条件数据 计费方式-chargeMode enum 固定、按件、按重量、按体积 包邮条件-FreightFreeCondition 列名 数据类型 备注 运费规则外键-FreightRuleId foreign key - 包邮地区-regions string 将地区名或id用连字符连接，留空表示全国 包邮件数-minPiece int 超过此件数包邮 包邮重量-minWeight int 超过此重量包邮 包邮体积-minVolume int 超过此体积包邮 包邮金额-minAmount int 超过此金额包邮 运费计算方式-FreightChargeMode 列名 数据类型 备注 运费规则外键-FreightRuleId foreign key - 适用地区-regions string 将地区名或id用连字符连接，留空表示全国 是否默认-default boolean 如果地区匹配失败，那么选中此条 快递公司-expressType enum - 固定邮费-fixedPrice int - 首件数量-firstPiece int - 首重数量-firstWeight int - 首体积-firstVolume int - 首段费用-firstPrice int - 续件数量-secondPiece int - 续重数量-secondWeight int - 续体积-secondVolume int - 续段费用-secondPrice int - 运费计算方法设计单商品运费计算方式 判断是否包邮 判断是否满足条件包邮的条件 根据客户选择的运送方式、所在地区查询计费方式 计算运费 多商品（购物车）运费计算方式 如果多商品全部属于同一种计费方式，那么计算出最大首费+最小续费 如果多商品不属于同一种计费方式，此处将成为业务设定的难点，也从没在各大电商网站看到解决此问题的好方案，可选方案： 将相同计费方式合算，最后累加不同计费方式（背后的逻辑是，相同的计费方式的商品会在同一个快递，不同的计费方式会在不同的快递） 全部累加（背后的逻辑是，即使是相同的计费方式，也不一定或者不会发一份快递，比如同样按重量计费的大米与木地板，不会放在同一个包裹） 喵书商城表结构待改造部分订单表订单表需要添加字段标识用户选择的运送方式，增加字段保存运费值，将商品金额转移到订单行表上，并且记录原价与实际支付价格。 关于网站自营与商家店铺的区分由于商家店铺与网站自营的商品不可能放在同一份快递，所以必须拆订单，分别计算运费。 参考文献http://www.cnblogs.com/lintao0823/p/4230425.html","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"数据结构设计","slug":"数据结构设计","permalink":"https://xudongye.github.io/xdlog/tags/数据结构设计/"}]},{"title":"Host和Engine","slug":"java/tomcat/深入剖析tomcat学习笔记/13Host和Engine","date":"2016-11-14T09:26:48.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"java/tomcat/深入剖析tomcat学习笔记/13Host和Engine/","link":"","permalink":"https://xudongye.github.io/xdlog/java/tomcat/深入剖析tomcat学习笔记/13Host和Engine/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"Host和EngineHost接口Host代表了Catalina servlet引擎中的一个虚拟主机。 主要用于以下场景： 为指定虚拟主机的每个请求使用拦截器 需要将Catalina与一个独立的http连接器配合使用，但是仍然支持多虚拟主机 StandardHost类StandardHost类是Catalina中Host接口的标准实现。 StandardHost类的构造器与StandardWrapper/StandardContext类类似，设置StandardHostValve实例作为管道对象的基础阀。1234public StandardHost() &#123; super(); pipeline.setBasic(new StandardHostValve());&#125; StandardHost#start()方法中，为StandardHost添加了两个阀，分别是： ErrorReportValve，输出HTML错误页的实现阀 ErrorDispatcherValve，处理错误分发（即在必要情况下，转发到合适的错误页）的实现阀 类似于StandardContext，StandardHost类并没有重写其父类的invoke()方法，所以直接调用其父类ContainerBase#invoke()方法，最终调用了其基础阀StandardHostValve#invoke()，第一件事还是寻址：找到合适的Context容器。最终实现寻址的方法是StandardHost#map(String)：1234567891011121314151617181920212223242526272829303132333435363738394041public Context map(String uri) &#123; if (debug &gt; 0) log(\"Mapping request URI '\" + uri + \"'\"); if (uri == null) return (null); // Match on the longest possible context path prefix if (debug &gt; 1) log(\" Trying the longest context path prefix\"); Context context = null; String mapuri = uri; while (true) &#123; context = (Context) findChild(mapuri); if (context != null) break; int slash = mapuri.lastIndexOf('/'); if (slash &lt; 0) break; mapuri = mapuri.substring(0, slash); &#125; // If no Context matches, select the default Context if (context == null) &#123; if (debug &gt; 1) log(\" Trying the default context\"); context = (Context) findChild(\"\"); &#125; // Complain if no Context has been selected if (context == null) &#123; log(sm.getString(\"standardHost.mappingError\", uri)); return (null); &#125; // Return the mapped Context (if any) if (debug &gt; 0) log(\" Mapped to context '\" + context.getPath() + \"'\"); return (context);&#125; StandardHostValve类StandardHostValve类是StandardHost实例的基础阀，其invoke()方法主要实现以下处理： 验证request/response对象类型的合法性 选择合适的Context实例来处理请求 将context的类加载器设置为当前线程的classloader 更新session对象的last access time 将request交由context处理 Engine接口Engine代表了整个Catalina servlet引擎，当部署Tomcat时需要支持多个虚拟主机时，就需要Engine容器。 实际上，一般情况下部署的tomcat都会使用一个Engine容器。 StandardEngine类StandardEngine类是Engine接口的标准实现。 StandardEngine类的构造器还是老规矩，设置一个基础阀：1234public StandardEngine() &#123; super(); pipeline.setBasic(new StandardEngineValve());&#125; StandardEngineValve类StandardEngineValve类是StandardEngine实例的基础阀，其invoke()方法主要实现以下处理： 验证request/response对象类型的合法性 验证任意一个HTTP/1.1请求包含一个server_name 选择合适的Host实例来处理请求 将request交由host处理","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://xudongye.github.io/xdlog/tags/tomcat/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"StandardContext","slug":"java/tomcat/深入剖析tomcat学习笔记/12StandardContext","date":"2016-11-11T07:30:26.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"java/tomcat/深入剖析tomcat学习笔记/12StandardContext/","link":"","permalink":"https://xudongye.github.io/xdlog/java/tomcat/深入剖析tomcat学习笔记/12StandardContext/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"StandardContextContext实例表示一个具体的Web应用，其中包含多个Wrapper，每个Wrapper表示一个具体的servlet定义。StandardContext是对Context接口的标准实现。 StandardContext的配置StandardContext类的构造函数12345public StandardContext() &#123; super(); pipeline.setBasic(new StandardContextValve()); namingResources.setContainer(this);&#125; 主要是将StandardContextValve类型的实例设置成了自身管道任务的基础阀，并且将自身的namingResources与自身绑定。 启动StandardContext实例StandardContext实现了Lifecycle接口，方便使用父子关系组件统一启动、停止。 查看start()方法主要完成了以下工作： 触发before_start事件 setAvailable(false) setConfigured(false) 配置资源 设置载入器 设置Session管理器 初始化字符集映射器 启动与容器相关的子组件，如载入器、日志记录器、集群支持、领域、资源管理器、寻址器(Mapper)等 启动子容器 启动管道Pipeline 触发start事件 启动Session管理器 如果启动成功，创建context属性，loadOnStartup(findChildren())，载入启动时就载入的子容器，即Wrapper容器 触发after_start事件 invoke()方法StandardContext#invoke()方法比较简单，先检查应用程序是否在重载中，若是，等待重载完成。然后调用父类ContainerBase#invoke()，即pipeline.invoke();。 StandardContextMapper类StandardContext管道对象的基础阀是StandardContextValve，其invoke()方法实现了StandardContext的基础功能。 StandardContextValve#invoke()的第一件事，就是获取一个要处理HTTP请求Wrapper实例，而负责这个查找工作的组件就是Mapper映射器。 StandardContext#start()方法中，调用了其父类addDefaultMapper(this.mapperClass);方法来添加Mapper对象，而StandardContext定义的private String mapperClass = &quot;org.apache.catalina.core.StandardContextMapper&quot;;，将StandardContextMapper类设置成了StandardContext的默认映射器。 Mapper接口最重要的方法map()签名如下：1Container map(Request request, boolean update); StandardContextMapper#map()先标识出相对于Context的URL，然后试图应用匹配规则找到一个合适的Wrapper实例。 查看源代码可知，具体的匹配规则按照优先级从高到低有如下： 精确匹配 前缀匹配 后缀扩展名匹配 默认匹配 对重载的支持StandardContext类定义了reloadable属性来指明该应用是否启用了重载功能。当启用了重载功能后，当web.xml发生变化或WEB-INF/classes下的一个文件被重新编译，应用将会重载。 StandardContext类是通过其载入器实现应用的重载的，tomcat4中，StandardContext对象在的属性WebappLoader类（implements Runnable）实现了Loader接口，并使用另一个线程检查对应目录下所有类和JAR文件的时间戳。 backgroundProcess()方法Context容器需要许多组件的支持，这些组件需要使用各自的线程执行一些后台处理任务，如载入器的周期性检查时间戳来实现自动重载、Session管理器的周期性检查来失效Session对象等。 在tomcat4中，这些组件各自拥有线程。在tomcat5中，为了节省资源，所有的后台处理共享一个线程。 如果某个组件或者servlet容器需要周期性地执行一个操作，只需要将其写到backgroundProcess()方法中即可。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://xudongye.github.io/xdlog/tags/tomcat/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"StandardWrapper","slug":"java/tomcat/深入剖析tomcat学习笔记/11StandardWrapper","date":"2016-11-10T02:09:28.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"java/tomcat/深入剖析tomcat学习笔记/11StandardWrapper/","link":"","permalink":"https://xudongye.github.io/xdlog/java/tomcat/深入剖析tomcat学习笔记/11StandardWrapper/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"StandardWrapper方法调用序列对于每个引入的http请求，具体的方法调用过程如下： 连接器(Connector)创建request/response对象 连接器调用StandardContext实例的invoke()方法 StandardContext实例invoke()方法调用其管道实例的invoke()方法，StandardContext中pipeline的基础阀是StandardContextValve StandardContextValve实例invoke()方法获取相应的Wrapper实例，调用Wrapper实例的invoke()方法 StandardWrapper类是Wrapper接口的标准实现，StandardWrapper实例的invoke()会调用其管道对象的invoke()方法，StandardWrapper中pipeline的基础阀是StandardWrapperValve StandardWrapperValve实例的invoke()方法调用Wrapper实例的allocate()方法获取servlet实例 allocate()方法调用load()方法载入相应servlet类，若已载入，则无需重复载入 load()方法调用servlet实例的init()方法 StandardWrapperValve调用servlet实例的service()方法 这一块的源代码相当有意思，主要涉及到接口Container、Pipeline，这两个接口分别制定了作为容器与管道的标准。 而在这两个接口与标准实现类之间，加入了一个基础抽象类ContainerBase，这个类的声明是public abstract class ContainerBase implements Container, Lifecycle, Pipeline，这个抽象类提供了基本每一个Container实现类都需要的通用功能，最典型的就是其invoke()方法：委托一个protected的Pipeline实例的invoke()方法来完成Container的invoke()方法。 而这个实现了Pipeline接口的StandardPipeline实例的invoke()方法，其内部是一个被抽象掉细节的阀invoke()调用链条。 而StandardContext与StandardWrapper都继承自ContainerBase抽象类，并且在自己的构造器中设置Pipeline对象的基础阀，这个基础阀实现了容器最基础的功能。 StandardContextValve是StandardContext的基础阀，除了禁止访问META-INF/WEB-INF这两个保留目录外，主要功能就是根据请求找到合适的Wrapper实例。而这个寻找的过程，其实就是后端路由的寻址，从面向对象角度来说，这个是不可能靠这个Valve来实现的，于是代码中也是找到关联的Context容器来寻址。 类似的，StandardWrapperValve是StandardWrapper的基础阀，其主要的功能就是让servlet被调用，而具体的调用方法，仍然是交由与其关联的Wrapper容器。 于是，一个精彩的责任链模式已经跃然纸上，容器-管道-阀三者之间实现了功能上的组合，但是代码逻辑上的松耦合。 容器的标准实现将自己的核心功能作为基础阀，放在了自己的管道里，但是基础阀主要是对容器API功能的调用来实现要求，并没有将容器的功能搬到阀中。 但是由于管道模型的出现，让开发者有机会在各个级别的容器中增加自己的阀来定制处理流程，而开发者只需要编写自己的阀代码加入管道即可。 SingleThreadModelSingleThreadModel接口是一个标记性接口，实现了SingleThreadModel的servlet被称为STM servlet类。 根据Servlet规范，实现此接口的目的，是为了保证servlet实例一次只处理一个请求，即不会出现两个线程同时执行一个servlet实例的service()方法。 其实该接口并不能防止servlet访问共享资源造成的同步问题，因为出现争用的不一定是servlet的实例变量，也有可能是其他类的静态变量或者servlet作用域之外的类，而后者这种情况不胜枚举。 StandardWrapper类StandardWrapper对象的主要任务，是载入所需的servlet类，并进行实例化，交由StandardWrapperValve调用servlet的service()方法。 分配servlet实例Wrapper接口定义了allocate()方法：1Servlet allocate() throws ServletException; 要求分配一个准备好执行service()方法的已经初始化完成的servlet实例。如果这个servlet类没有实现SingleThreadModel接口，那么立即返回已初始化的实例；如果实现了SingleThreadModel接口，Wrapper实现类必须保证，直到调用deallocate()取消这个servlet实例的分配，才重新分配这个servlet实例。 所以StandardWrapper类的allocate()方法主要分为两个部分，分别处理实现STM servlet与非STM servlet。 对于非STM servlet类，或者初次加载servlet类还不知道是否是STM servlet，只是使用了一个private Servlet instance的变量来保存这个唯一的servlet实例。1234567891011121314if (instance == null) &#123; synchronized (this) &#123; if (instance == null) &#123; try &#123; instance = loadServlet(); &#125; catch (ServletException e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new ServletException (sm.getString(\"standardWrapper.allocate\"), e); &#125; &#125; &#125;&#125; 在loadServlet()中会判断servlet是否STM。 对于STM servlet类，StandardWrapper会试图从一个对象池中获取可用实例，这个对象池的类型：1234/** * Stack containing the STM instances. */private Stack instancePool = null; 代码与所有的池设计类似，不再赘述。与之相关的变量有： private int countAllocated = 0; 当前活跃的分配个数 private int nInstances = 0; 当前已加载的实例个数 private int maxInstances = 20; 对象池最大容量 载入servlet类Wrapper接口声明了load()方法：1void load() throws ServletException; 要求加载和初始化一个servlet实例，即载入servlet类，并调用其init()方法。 下面看一下StandardWrapper类loadServlet()方法是如何工作的：123// Nothing to do if we already have an instance or an instance poolif (!singleThreadModel &amp;&amp; (instance != null)) return instance; 如果不是STM Servlet并且实例存在，则直接返回该实例。 123456if ((actualClass == null) &amp;&amp; (jspFile != null)) &#123; Wrapper jspWrapper = (Wrapper) ((Context) getParent()).findChild(Constants.JSP_SERVLET_NAME); if (jspWrapper != null) actualClass = jspWrapper.getServletClass();&#125; 如果Servlet是一个JSP页面，那么获取jsp页面对应的实际Servlet类。 123456// Complain if no servlet class has been specifiedif (actualClass == null) &#123; unavailable(null); throw new ServletException (sm.getString(\"standardWrapper.notClass\", getName()));&#125; 如果没有指定class名，抛出异常，终止后续操作。 1234567// Acquire an instance of the class loader to be usedLoader loader = getLoader();if (loader == null) &#123; unavailable(null); throw new ServletException (sm.getString(\"standardWrapper.missingLoader\", getName()));&#125; 获取载入器，如果找不到载入器，抛出异常。 123456// Special case class loader for a container provided servletif (isContainerProvidedServlet(actualClass)) &#123; classLoader = this.getClass().getClassLoader(); log(sm.getString (\"standardWrapper.containerServlet\", getName()));&#125; 如果servlet是Catalina提供的一些用于访问servlet容器内部数据的专用servlet类，那么将classLoader赋值为容器的ClassLoader实例。 之后是用classloader载入servlet类-实例化-触发相关事件-调用servlet#init()-判断是否是STM servlet-初始化对象池的过程。 StandardWrapperFacade类Servlet实例的init()方法需要传入javax.servlet.ServletConfig类型的参数，而StandardWrapper类本身其实是实现了ServletConfig接口的，所以理论上将StandardWrapper本身this传递给servlet就可以了。 但还是老生常谈，这里运用了一个StandardWrapperFacade类作为外观类来隐藏掉StandardWrapper的方法。 StandardWrapperValve类StandardWrapperValve类是StandardWrapper实例中的基础阀，完成两个操作： 执行与servlet相关的全部过滤器 调用servlet的service()方法 实际操作步骤如下： 调用StandardWrapper实例allocate()获取servlet实例 调用私有方法createFilterChain()创建过滤器链 调用ApplicationFilterChain#doFilter()执行过滤以及调用service()方法 释放过滤器链 调用Wrapper实例的deallocate()方法取消分配 若该servlet不再被使用到，则调用Wrapper#unload()方法 FilterDef类FilterDef表示一个过滤器的定义，正如在部署描述器(web.xml)中定义的\\节点那样。12345678public final class FilterDef &#123; // 实现这个过滤器的java class全限定名 private String filterClass = null; // 过滤器名称，在特定的web应用中必须是唯一的 private String filterName = null; // 过滤器的初始化参数集合 private Map parameters = new HashMap();&#125; ApplicationFilterConfig类ApplicationFilterConfig类实现javax.servlet.FilterConfig接口，用于管理Web应用第一次启动时创建的过滤器实例。12345678public ApplicationFilterConfig(Context context, FilterDef filterDef) throws ClassCastException, ClassNotFoundException, IllegalAccessException, InstantiationException, ServletException &#123; super(); this.context = context; setFilterDef(filterDef);&#125; 它的构造函数，接受一个Context对象表示一个Web应用程序，FilterDef表示一个过滤器定义。ApplicationFilterConfig#getFilter()方法会返回一个javax.servlet.Filter对象，如果未实例化，则在此方法中定位classloader-加载类-实例化对象-调用Filter#init()方法。 ApplicationFilterChain类ApplicationFilterChain类实现javax.servlet.FilterChain接口。StandardWrapperValve#invoke()方法会创建ApplicationFilterChain实例，并调用其doFilter()方法。而ApplicationFilterChain#doFilter()的实现中，会调用第一个过滤器Filter#doFilter(ServletRequest, ServletResponse, FilterChain)，并将自身作为第三个参数传入Filter实例，以达到链式调用的目的。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://xudongye.github.io/xdlog/tags/tomcat/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"Session管理","slug":"java/tomcat/深入剖析tomcat学习笔记/9Session管理","date":"2016-11-09T06:17:12.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"java/tomcat/深入剖析tomcat学习笔记/9Session管理/","link":"","permalink":"https://xudongye.github.io/xdlog/java/tomcat/深入剖析tomcat学习笔记/9Session管理/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"Session管理Catalina通过一个称为Session管理器的组件来管理建立Session对象，当请求到来时，要可以返回一个有效的session对象。 Session对象这里还是一个老生常谈的外观模式，JEE要求的Session接口是javax.servlet.http.HttpSession，Catalina内部的外观接口是Session，标准实现是StandardSession，用一个StandardSessionFacade的外观包装类来掩盖掉具体实现类的细节。 ManagerManager接口Manager管理一个关联了特定容器的session池，定义了一些创建、销毁、失效检查、持久化与读取的行为。不同的Manager实现可能会支持一些不同的附加特性，如session数据持久化、分布式应用服务器的session迁移等。 ManagerBase抽象类所有的Session管理器组件都会继承此类，此类提供了createSession(),add(Session),remove(Session),findSession(String)等诸多功能。 StandardManager类StandardManager类是Manager接口的标准实现，该类将Session存储在内存中。StandardManager类实现了Lifecycle接口，这样可以由与其关联的Context容器来启动和关闭。其中stop()方法的实现会调用unload()方法，以便将有效的session对象序列化到一个名为SESSION.ser的文件中（该文件在$Catalina_home/work目录下）。当StandardManager实例再次启动，会调用load()方法将这些对象重新读入内存中。 StandardManager类还会负责销毁那些已经失效的Session对象，在tomcat4中，这项工作是由一个专门的线程来完成的。详见StandardManager类的run()方法：12345678910/** * The background thread that checks for session timeouts and shutdown. */public void run() &#123; // Loop until the termination semaphore is set while (!threadDone) &#123; threadSleep(); processExpires(); &#125;&#125; PersistentManagerBase抽象类PersistentManagerBase类是所有持久化Session管理器的父类。StandardManager类和持久化Session管理器的区别在于后者中存储器的表现形式，即存储Session对象的辅助存储器的形式，使用Store接口的对象来表示。 在持久化Session管理器中，Session对象可以备份，也可以换出，节省了内存空间。 在tomcat4中，PersistentManagerBase抽象类实现了Runnable接口，使用一个专门的线程来执行备份与换出活动的Session对象的任务。123456789101112131415161718192021222324/** * The background thread that checks for session timeouts and shutdown. */public void run() &#123; // Loop until the termination semaphore is set while (!threadDone) &#123; threadSleep(); processExpires(); processPersistenceChecks(); &#125;&#125;/** * Called by the background thread after active sessions have * been checked for expiration, to allow sessions to be * swapped out, backed up, etc. */public void processPersistenceChecks() &#123; // 换出空闲时间过长的session到辅助存储器中 processMaxIdleSwaps(); // 当活动session过多时换出部分相对空闲的session到辅助存储器中 processMaxActiveSwaps(); // 备份空闲session processMaxIdleBackups();&#125; PersistentManager类继承自PersistentManagerBase抽象类，没有添加或重新新的方法，只是改变了自身的info属性。 DistributedManager类DistributedManager类用于2个或多个节点的集群环境，来支持复制Session对象。为了实现复制Session的目的，DistributedManager类中创建或销毁Session对象时，会向其他节点发送消息，所以集群中的每个节点也必须能够接收其他节点的消息。集群间的发送和接收行为，分别被定义成了ClusterSender/ClusterReceiver接口。 存储器存储器是org.apache.catalina.Store接口的实例，是为Session管理器管理的Session对象提供持久化存储的一个组件。 12345678910public interface Store &#123; // 查询所有的session_id String[] keys(); // 载入指定session_id的session Session load(String id); // 移除指定session_id的session void remove(String id); // 持久化指定session_id的session void save(Session session);&#125; Catalina提供了几个常用实现类： StoreBase抽象类提供了processExpires()功能来销毁过期的session对象，但是load()/save()这些方法都依赖具体的存储媒介，交由子类实现。 FileStore类文件存储媒介是.session的文件 JDBCStore类将Session对象通过JDBC存入数据库","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://xudongye.github.io/xdlog/tags/tomcat/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"http缓存机制及nginx相关配置","slug":"design/http缓存机制及nginx相关配置","date":"2016-11-08T12:11:37.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"design/http缓存机制及nginx相关配置/","link":"","permalink":"https://xudongye.github.io/xdlog/design/http缓存机制及nginx相关配置/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"http缓存机制及nginx相关配置浏览器http缓存，既是网页静态资源服务性能优化的一把利器，也是无数web开发者在工作之初谈之色变的一大难题。在开发过程中我们极力避免缓存，但在生产环境中，我们又在想尽办法利用缓存。所以了解浏览器缓存的机制，是一个优秀开发者绕不开的重要基础知识。 各种缓存的命中与否，说到底不过是几个与之相关的http header数据的匹配与校验。如果了解了每个相关header的意义与关系，那么就能将缓存策略运用自如。 缓存分类 在浏览器的缓存模型中，一次成功（能拿到想要的数据）的请求，会有以上三种情况。 200 from cache 直接从本地缓存（有的文章称之为强缓存）中获取响应，返回200状态，chrome网络面板中的size项显示(from cache)。 最快速，最省流量，因为根本没有向服务器发送请求。 304 Not Modified 在本地缓存没有命中的情况下，请求头中发送一定的校验数据到服务端，校验成功后服务器返回304 not modified表示资源未被修改，浏览器从本地缓存中获取响应，这种缓存方式通常被称为协商缓存。 快速，发送的数据很少，只返回一些基本的响应头信息，数据量很小，不发送实际响应体。 200 OK 以上两种缓存全都失败，服务器返回完整响应。 没有用到缓存，相对最慢。 本地缓存本地缓存的使用，相当于基于之前服务器的response header，浏览器认为当前的缓存可以直接使用，于是不再与服务器进行任何交互而直接使用缓存的过程。 与本地缓存命中相关的http header： Pragma 这个是http1.0时代的遗留产物，该字段被设置为no-cache时（实际上现有的RFC标准标明只有这个可选值），会告知浏览器禁用本地缓存，即每次都向服务器发送请求。 Expires http1.0时代用来启用本地缓存的字段，expires值对应一个形如Thu, 31 Dec 2037 23:55:55 GMT的格林威治时间，告诉浏览器缓存实现的时刻，如果还没到该时刻，标明缓存有效，无需发送请求。 但是这个方式有个很明显的问题，就是浏览器与服务器的时间是不能保证一致的，如果时间差距较大，那么会影响缓存管理的结果。 Cache-Control http1.1针对Expires时间不一致的问题，采取了一个十分聪明的设定，运用Cache-Control来告知浏览器缓存过期的时间间隔而不是时刻，那么即使具体时间不一致，也不影响缓存的管理。 Cache-Control允许的值如下： no-store 禁止浏览器缓存响应，通常一些非常隐私的数据会启用这个值 no-cache 不允许直接使用本地缓存，必须先发起请求和服务器协商。 max-age=delta-seconds 告知浏览器该响应本地缓存有效的最长期限，以秒为单位。 其他可选值不常见，以后遇到再补充 这三个字段主要用来告知浏览器的本地缓存管理策略，优先级为Pragma &gt; Cache-Control &gt; Expires。 协商缓存当浏览器没有命中本地缓存，如本地缓存过期或者响应中声明不允许直接使用本地缓存，那么浏览器肯定会发起请求。 在http缓存模型中，即使浏览器向服务器发起请求，服务器也不一定要返回整个资源的实体内容。而可以返回协商结果：“浏览器，我的资源没有修改过，你可以直接使用你的本地缓存”。 很显然，服务器要判断浏览器的缓存是否可用，那么必须浏览器告诉服务器一些自己缓存的信息，所以协商缓存相关的header字段，必然是成对出现的。 Last-Modified 格式：Last-Modified: Tue, 08 Nov 2016 01:50:36 GMT 告诉浏览器资源的最后修改时间，相当于对资源进行了版本管理，至于这个时间怎么生成的，那是服务器的事儿，不在这里讨论。 得知资源的最后修改时间后，客户端会将这个信息提交到服务器做检查，如果服务器验证出最后修改时间是一致的，那么表示该资源没有修改过，可以返回304状态。 浏览器请求头中标记最终修改时间的header字段： If-Modified-Since: Thu, 31 Mar 2016 07:07:52 GMT ETag 即使我没有讨论服务器怎么生成最终修改时间，也可以相见，这个模式会存在不准确的问题：如果资源明明没有改变，但是Last-Modified发生了变化，那么就会返回整个资源实体。 针对这个问题，http1.1还推出了ETag字段，服务器会根据某种计算方式（常见的如md5）给出一个标识符，这个标识符其实标记的是资源的实际内容。 格式：ETag:&quot;58212f6c-22f23&quot; 检测过程与Last-Modified类似，浏览器请求头中标记ETag的字段： If-None-Match:&quot;58212f6c-22f23&quot; 浏览器行为对缓存的影响注意观察浏览器行为的开发者很容易发现，输入url访问与f5刷新，各个资源的请求速度好像不太相同。 常见的浏览器会将访问行为分为3种： 地址栏输入URL或书签访问 按照正常策略使用缓存 F5刷新 跳过强缓存，但是会使用协商缓存 Ctrl+F5 跳过强缓存与协商缓存，直接加载资源实体 具体的实现方式可以想见的是发送不同的请求头。 缓存策略的选择对大多数站点来说，以下内容是非常适合缓存的： 普通不变的图像，如logo，图标等 js、css静态文件 可下载的内容，媒体文件 这些文件很少改变，适合长时间强缓存。 以下内容是做缓存时需要注意的，建议主要使用协商缓存的： HTML文件 经常替换的图片 经常修改的js、css文件 其中，js、css文件可以通过md5修改文件名的方式改变url来失效缓存，即在文件内容变化后将main.95d21235.css改为main.1bcbf5de.css，由于url变化，所以不存在缓存的问题。 以下内容从来都不应该使用缓存： 用户隐私等敏感数据 经常改变的api数据接口 其中，后台rest api数据接口的如果需要引入缓存策略，必须要进行比较谨慎的规划，将频繁改变的接口与基本不变的接口区分，并且在应用服务器中实现Last-Modified/ETag的生成机制以保证缓存不会造成错误的结果。 从这里延伸出去的话，理想情况下，一切网络资源都应该尽可能选择不同策略的缓存，但考虑到开发的成本与难度，这在现实中很难发生，因此应该尝试设置一些明智的缓存策略（最常见的就是给大量的静态图片设置缓存），以在长期缓存和站点改变的需求间达到平衡。 nginx配置缓存策略 强缓存相关配置 add_header指令 123Syntax: add_header name value [always];Default: —Context: http, server, location, if in location 给状态码2,3开头的响应添加响应头，如Pragma/Expires/Cache-Control，可以继承。 expires指令 12345Syntax: expires [modified] time; expires epoch | max | off;Default: expires off;Context: http, server, location, if in location expires为负值时，表示Cache-Control: no-cache; 当为正或者0时，就表示Cache-Control: max-age=指定的时间(秒); 当为max时，会把Expires设置为 “Thu, 31 Dec 2037 23:55:55 GMT”， Cache-Control 设置到 10 年; 协商缓存相关配置 ETag 1234Syntax: etag on | off;Default: etag on;Context: http, server, location Last-Modified add_header指令，默认开启 参考文献 http://imweb.io/topic/5795dcb6fb312541492eda8c https://developers.google.com/web/fundamentals/performance/optimizing-content-efficiency/http-caching?hl=zh-cn http://web.jobbole.com/84888/ http://nginx.org/en/docs/http/ngx_http_headers_module.html https://linux.cn/article-5456-1.html","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"http","slug":"http","permalink":"https://xudongye.github.io/xdlog/tags/http/"},{"name":"nginx","slug":"nginx","permalink":"https://xudongye.github.io/xdlog/tags/nginx/"}]},{"title":"载入器","slug":"java/tomcat/深入剖析tomcat学习笔记/8载入器","date":"2016-11-08T06:14:35.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"java/tomcat/深入剖析tomcat学习笔记/8载入器/","link":"","permalink":"https://xudongye.github.io/xdlog/java/tomcat/深入剖析tomcat学习笔记/8载入器/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"载入器载入器是Catalina最重要的组件，servlet容器需要实现一个自定义的类载入器，出于以下原因： 将WEB-INF/classes目录下的应用类与更高级别的容器类用不同的classloader隔离开来 根据classes文件是否发生变化实现类的自动重新装载 Java的类加载器类加载器的双亲委托模型 Loader接口Loader接口指的是Web应用程序载入器，而不仅仅是类载入器。 1234567891011121314151617181920public interface Loader &#123; // properties // 使用的classloader实例 ClassLoader getClassLoader(); // 绑定的context级别的container Container getContainer(); DefaultContext getDefaultContext(); // 是否委托给一个父类载入器 boolean getDelegate(); String getInfo(); // 是否支持自动重载 boolean getReloadable(); // method void addPropertyChangeListener(PropertyChangeListener listener); void addRepository(String repository); String[] findRepositories(); // 仓库中的class被修改了，触发类重新加载事件 boolean modified(); void removePropertyChangeListener(PropertyChangeListener listener);&#125; WebappLoader类WebappLoader类实现了Loader接口，其实例就是Web应用的载入器。像其他Catalina组件一样，WebappLoader类也实现了Lifecycle接口，可以由其关联的容器来启动、关闭组件。此外，WebappLoader类还实现了Runnable接口，可以指定一个线程来不断调用modifed()方法来检查class是否被修改。 当调用WebappLoader类的start()方法时，会完成以下工作： 创建类加载器WebappLoader类并没有声明setClassLoader()方法来直接设置classloader，而是声明了setLoaderClass()来设置其私有变量loaderClass的值。这个私有变量保存了字符串类型的classloader类全名，其默认值是&quot;org.apache.catalina.loader.WebappClassLoader&quot;。 WebappLoader类在启动时调用其方法createClassLoader()来创建类加载器。 12345678910111213141516private WebappClassLoader createClassLoader() throws Exception &#123; Class clazz = Class.forName(loaderClass); WebappClassLoader classLoader = null; if (parentClassLoader == null) &#123; // Will cause a ClassCast is the class does not extend WCL, but // this is on purpose (the exception will be caught and rethrown) classLoader = (WebappClassLoader) clazz.newInstance(); &#125; else &#123; Class[] argTypes = &#123; ClassLoader.class &#125;; Object[] args = &#123; parentClassLoader &#125;; Constructor constr = clazz.getConstructor(argTypes); classLoader = (WebappClassLoader) constr.newInstance(args); &#125; return classLoader;&#125; 设置仓库调用setRepositories()方法，利用classloader.addRepository()将&quot;/WEB-INF/classes&quot;新增仓库，利用classLoader.setJarPath()将&quot;/WEB-INF/lib&quot;设置为jar仓库。 设置类路径调用setClassPath()方法，解析classloader链条中的repository集合，组装classpath信息。 设置访问权限调用setPermissions()方法为类载入器设置访问相关目录的权限。 开启新线程执行类的重新载入1234567891011121314151617181920public void run() &#123; // Loop until the termination semaphore is set while (!threadDone) &#123; // Wait for our check interval threadSleep(); if (!started) break; try &#123; // Perform our modification check if (!classLoader.modified()) continue; &#125; catch (Exception e) &#123; log(sm.getString(\"webappLoader.failModifiedCheck\"), e); continue; &#125; // Handle a need for reloading notifyContext(); break; &#125;&#125; 循环调用classLoader.modified()方法检查是否被修改。一旦为true，通知context容器去重新载入类。 WebappClassLoader类WebappClassLoader类的设计方案考虑到了优化和安全两方面，例如： 缓存之前已经载入成功或失败的类来提升性能 禁止载入指定类（如javax.servlet.Servlet） 委托系统类载入器载入指定包下的类(如javax, org.xml.sax等) 类缓存每个由WebappClassLoader载入的类都被视作“资源”，对应class是org.apache.catalina.loader.ResourceEntry 123456789public class ResourceEntry &#123; public long lastModified = -1; public byte[] binaryContent = null; public Class loadedClass = null; public URL source = null; public URL codeBase = null; public Manifest manifest = null; public Certificate[] certificates = null;&#125; 所有已加载的类都保存在protected HashMap resourceEntries中，其key就是资源的名称。所有载入失败的类都保存在protected HashMap notFoundResources中。 载入类载入类时，遵循如下规则： 先检查本地缓存 如果本地缓存中没有，则检查上一层缓存，即调用java.lang.ClassLoader#findLoadedClass(String)方法 若2个缓存都没有，则使用系统的类载入器加载，防止Web应用中的类覆盖JEE类 若采用了SecurityManager，则检查是否允许载入该类 若打开delegate标志位，或待载入的类属于1234567891011/*** Set of package names which are not allowed to be loaded from a webapp* class loader without delegating first.*/private static final String[] packageTriggers = &#123; \"javax\", // Java extensions \"org.xml.sax\", // SAX 1 &amp; 2 \"org.w3c.dom\", // DOM 1 &amp; 2 \"org.apache.xerces\", // Xerces 1 &amp; 2 \"org.apache.xalan\" // Xalan&#125;; 则委托父载入器来加载相关类 从仓库中加载类 如果delegate关闭，委托父载入器加载类 抛出ClassNotFoundException","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://xudongye.github.io/xdlog/tags/tomcat/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"日志记录器","slug":"java/tomcat/深入剖析tomcat学习笔记/7日志记录器","date":"2016-11-08T03:02:49.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"java/tomcat/深入剖析tomcat学习笔记/7日志记录器/","link":"","permalink":"https://xudongye.github.io/xdlog/java/tomcat/深入剖析tomcat学习笔记/7日志记录器/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"日志记录器日志记录器作为任何一个系统最重要的组件，可以说没有一套完善的日志组件的系统，是无法投入使用的。tomcat开发者也对其做出了一个相当优雅的设计实现。 Logger接口org.apache.catalina.Logger接口描述了一个通用的信息与异常的Logger，理论上logger能被用在任何container上，但是实际的典型应用中，Logger只会用在Context或更高的级别容器上。 12345678910public interface Logger &#123; // 定义了一些日志级别的常量，fatal/error/warning/information/debug public static final int FATAL = Integer.MIN_VALUE; // 属性： container, info, verbosity日志级别 Container getContainer(); ... // 定义了一些重载的log方法 void log(String message); void log(Exception exception, String msg); ...&#125; Tomcat的日志记录器LoggerBase类LoggerBase这个抽象类提供了Logger接口的基础实现，但将核心方法log(String)交由子类实现，类似于模板方法模式。 SystemOutLogger/SystemErrLogger类继承自LoggerBase，分别以System.out.println(String)/System.err.println(String)实现了抽象方法log(String)。 FileLogger类这个类将servlet容器中接受到的日志消息写到一个文件中，并且可以选择添加时间戳，并且会根据日期的变化创建新的文件，同时提供了文件名称的前缀与后缀设置接口。 这个类的具体实现无需赘述，可以看出，tomcat引擎级别的日志catalina.2016-11-08.log，主机级别的日志localhost.2016-11-08.txt都是由此类生成的。具体设置在$CATALINA_BASE/conf/logging.properties。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://xudongye.github.io/xdlog/tags/tomcat/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"生命周期","slug":"java/tomcat/深入剖析tomcat学习笔记/6生命周期","date":"2016-11-07T12:07:39.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"java/tomcat/深入剖析tomcat学习笔记/6生命周期/","link":"","permalink":"https://xudongye.github.io/xdlog/java/tomcat/深入剖析tomcat学习笔记/6生命周期/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"生命周期tomcat开发者将Catalina中的各种组件的启动、关闭行为，都抽象为一个接口org.apache.catalina.Lifecycle，进而可以在管理生命周期相关行为时面向接口编程。通过实现Lifecycle接口完成单一启动/关闭机制，并且以一种优雅的方式（观察者模式）向其他组件发送事件消息。 Lifecycle接口Catalina在设计上允许一个组件包含其他组件，父级组件负责启动/关闭它的子组件，这样的层层设计，使得所有的组件都置于顶级组件的监护下，这样Catalina的启动类只需要启动一个组件，就可以将全部的应用组件都启动起来。 123456789public interface Lifecycle &#123; // 几种关于启动、停止的事件名称 static final String START_EVENT = \"start\"; void addLifecycleListener(LifecycleListener listener); LifecycleListener[] findLifecycleListeners(); void removeLifecycleListener(LifecycleListener listener); void start() throws LifecycleException; void stop() throws LifecycleException;&#125; LifecycleEvent类通知实现了Lifecycle接口的组件上的监听者组件发生了变化的通用event类。 123456789public final class LifecycleEvent extends EventObject&#123; // properties // 关联在事件上的数据 private Object data; // 事件发生的Lifecycle private Lifecycle lifecycle; // 事件实例的类型 private String type;&#125; LifecycleListener接口定义了组件生命周期事件的监听者 123public interface LifecycleListener &#123; void lifecycleEvent(LifecycleEvent event);&#125; LifecycleSupport类一个帮助管理监听者，并触发相应生命周期事件的Support类。 123456789public final class LifecycleSupport&#123; private Lifecycle lifecycle = null; // 已注册的事件监听者集合，用一定的同步机制管理它的增删改查 private LifecycleListener listeners[] = new LifecycleListener[0]; public void addLifecycleListener(LifecycleListener listener)&#123;&#125; public void removeLifecycleListener(LifecycleListener listener)&#123;&#125; public LifecycleListener[] findLifecycleListeners()&#123;&#125; public void fireLifecycleEvent(String type, Object data) &#123;&#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://xudongye.github.io/xdlog/tags/tomcat/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"servlet容器","slug":"java/tomcat/深入剖析tomcat学习笔记/5servlet容器","date":"2016-11-04T08:51:41.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"java/tomcat/深入剖析tomcat学习笔记/5servlet容器/","link":"","permalink":"https://xudongye.github.io/xdlog/java/tomcat/深入剖析tomcat学习笔记/5servlet容器/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"servlet容器Container接口Catalina中的servlet容器，共有4种类型： Engine： 表示整个Catalina servlet引擎 Host： 表示包含多个Context容器的虚拟主机 Context： 表示一个包含多个wrapper的web应用程序 Wrapper： 表示一个独立的servlet 可以看出，“容器”这个命名还是比较通俗的，因为每个容器都在盛装东西嘛。 由于不同级别之间container是一种类似树形结构的关系，所以会有一些相关的方法： 1234Container findChild(String name);Container[] findChildren();void addChild(Container child);void removeChild(Container child); 容器的设计上会包含一些组件化的功能，所以也定义了一些属性，如： Loader： 加载容器中新的类的classloader Logger： 日志记录器 Manager： session池管理器 Realm： 只读的安全领域接口，做身份验证 Resources： 静态资源访问器 管道任务管道包含了servlet容器所要调用的任务，一个阀表示一个具体的执行任务，阀都装在管道上。这个模型的比喻其实相当好理解，也会让人不禁想到了责任链模式，让人不禁想到了servlet编程中的filterChain过滤器链。 一个Pipeline有多个Valve，但是只有一个会被标记为BasicValve。 tomcat的设计者没有使用一个循环遍历Valve数组的方式来执行任务，而是使用了一个ValveContext来实现责任链模式的遍历执行。 Pipeline接口描述了一个应该顺序执行invoke()方法的Valve集合，通常每个容器都绑定一个Pipeline实例，并且容器的请求处理功能点是封装在管道内部的特定阀，通常将最基础的功能定义为Basic阀，在管道的最后执行。其他的阀会按照它们被添加的顺序依次执行。接口主要定义了增加减少阀、设置查找Basic阀以及invoke 12345678public interface Pipeline &#123; Valve getBasic(); void setBasic(Valve valve); void addValve(Valve valve); Valve[] getValves(); void removeValve(Valve valve); void invoke(Request request, Response response)throws IOException, ServletException;&#125; Valve接口123public interface Valve &#123; void invoke(Request request, Response response, ValveContext context);&#125; ValveContext接口描述了管道内一个阀能够触发下一个阀的执行的机制，而无需知道其内部的实现细节（上文所提到的循环遍历数据就是其中一种实现细节）。 123public interface ValveContext &#123; void invokeNext(Request request, Response response);&#125; Contained接口一个解耦一个class必须绑定至多一个container实例的接口，描述这个类是带有容器的。 1234public interface Contained &#123; Container getContainer(); void setContainer(Container container);&#125; Wrapperwrapper级别容器代表一个web应用部署后独立的servlet定义，并且其实现负责管理该servlet的生命周期。 Context大部分的web应用中，需要多个servlet合作，这时需要的servlet容器是Context，而不是Wrapper。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://xudongye.github.io/xdlog/tags/tomcat/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"tomcat的默认连接器","slug":"java/tomcat/深入剖析tomcat学习笔记/4tomcat的默认连接器","date":"2016-11-04T05:40:16.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"java/tomcat/深入剖析tomcat学习笔记/4tomcat的默认连接器/","link":"","permalink":"https://xudongye.github.io/xdlog/java/tomcat/深入剖析tomcat学习笔记/4tomcat的默认连接器/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"tomcat的默认连接器本章介绍的“默认连接器”是指tomcat的默认连接器，在新的tomcat中已经被弃用，被Coyote取代，但是其中很多优化的思想，仍然是不错的学习工具。 HTTP1.1新特性主要引入了connection: keep-alive来使用持久连接，用块编码来切断不同请求，服务器不再立即关闭连接，使用同一个连接来下载所有的资源，减少建立/关闭Http连接的系统开销。 Connector接口12345678public interface Connector &#123; // ---- properties Container getContainer(); 绑定相关联的servlet容器 void setContainer(Container container); // ---- method Request createRequest(); Response createResponse();&#125; 在模型设计上，Connector与Processor是一对多关系。 HttpConnector类org.apache.catalina.connector.http.HttpConnector实现了LifeCycle接口，会基于事件地被调用initialize(),start()方法。 创建ServerSocket通过一个ServerSocketFactory工厂模式来创建ServerSocket实例 维护HttpProcessor实例HttpConnector内部维护了一个java.io.Stack栈结构的HttpProcessor对象池，避免每次重新创建对象。而每个HttpProcessor运行在自己的线程中，这样同一个HttpConnector实例就可以处理多个HTTP请求了。 处理request请求时，会根据如下规则维护HttpProcessor对象池 12345678910// Create the specified minimum number of processors// 一直创建到最小对象池容量以上while (curProcessors &lt; minProcessors) &#123; // 一直创建到最大对象池容量为止 if ((maxProcessors &gt; 0) &amp;&amp; (curProcessors &gt;= maxProcessors)) break; HttpProcessor processor = newProcessor(); // 将HttpProcessor实例入栈 recycle(processor);&#125; 提供HTTP请求服务1234567891011// Hand this socket off to an appropriate processorHttpProcessor processor = createProcessor();if (processor == null) &#123; try &#123; log(sm.getString(\"httpConnector.noProcessor\")); socket.close(); &#125; catch (IOException e) &#123; &#125; continue;&#125;processor.assign(socket); 如果由于对象池满了拿不到processor，那么跳出循环不做处理，并且关闭socket连接。否则，交由processor处理该请求。 HttpProcessor类此处着重介绍“连接器线程”和“处理器线程”的异步实现。 HttpProcessor的LifeCycle接口实现的start()方法 12345678910111213141516171819202122232425/** * Start the background thread we will use for request processing. * * @exception LifecycleException if a fatal startup error occurs */public void start() throws LifecycleException &#123; if (started) throw new LifecycleException (sm.getString(\"httpProcessor.alreadyStarted\")); lifecycle.fireLifecycleEvent(START_EVENT, null); started = true; threadStart();&#125;/** * Start the background processing thread. */private void threadStart() &#123; log(sm.getString(\"httpProcessor.starting\")); thread = new Thread(this, threadName); // 连接器线程不存在时，处理器线程就没有意义了，所以设置为守护线程 thread.setDaemon(true); thread.start();&#125; 于是HttpProcessor实例就运行在自己的线程中了，再看一下在运行什么： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * The background thread that listens for incoming TCP/IP connections and * hands them off to an appropriate processor. */public void run() &#123; // Process requests until we receive a shutdown signal while (!stopped) &#123; // Wait for the next socket to be assigned Socket socket = await(); if (socket == null) continue; // Process the request from this socket try &#123; process(socket); &#125; catch (Throwable t) &#123; log(\"process.invoke\", t); &#125; // Finish up this request connector.recycle(this); &#125; // Tell threadStop() we have shut ourselves down successfully synchronized (threadSync) &#123; threadSync.notifyAll(); &#125;&#125;/** * Await a newly assigned Socket from our Connector, or &lt;code&gt;null&lt;/code&gt; * if we are supposed to shut down. */private synchronized Socket await() &#123; // Wait for the Connector to provide a new Socket while (!available) &#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; &#125; &#125; // Notify the Connector that we have received this Socket Socket socket = this.socket; available = false; notifyAll(); if ((debug &gt;= 1) &amp;&amp; (socket != null)) log(\" The incoming request has been awaited\"); return (socket);&#125; 可以看出，在没有新的socket之前，这个run()方法其实是一直在阻塞在第一行代码的。 这时候，再看看HttpConnector中调用的assign()方法 123456789101112131415161718synchronized void assign(Socket socket) &#123; // Wait for the Processor to get the previous Socket while (available) &#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; &#125; &#125; // Store the newly available Socket and notify our thread this.socket = socket; available = true; notifyAll(); if ((debug &gt;= 1) &amp;&amp; (socket != null)) log(\" An incoming request is being assigned\");&#125; 由于这时候available是false，那个wait()此时是不执行的，于是在将socket的引用赋给属性变量后，notifyAll()唤醒了所有等待中的线程。于是run()方法中的process()终于开始处理socket连接，进行很多比较耗时的解析处理操作。 那么assign()方法中的wait()是在什么时候阻塞自己呢，也就是available是true到底代表了什么状态？很明显，assign()方法是有synchronized修饰符的，也就是说，available肯定不是用来锁住这个方法本身的。 将await()/assign()方法成对观察，可以发现，这个available标志在为true时，assign()方法中的wait()方法其实卡住了调用它的连接器线程，因为这个时候，socket还没有被正确地处理。于是就可以解释，为什么这里真正处理的socket引用，是一个局部变量而不是成员变量，因为这样，可以在当前socket被处理完成之前，继续接收下一个socket对象。成员变量的socket对象引用，其实只是一个接受后的暂存处，并不是真正的处理socket时的引用。 未解之谜： 既然是暂存处，为什么不设置成集合类型（如队列）呢？ 所以，这个available，并不是在表达当前的processor是不是可用，而表示this.socket这个暂存处是不是有未处理的socket：如果有，表示暂存处还有任务没处理，assign()方法必须等待；如果没有，表示没有新的任务，await()方法必须等待。 其实不难看出，这里tomcat的开发者利用了available这个flag位，以及wait()/notifyAll()这对睡眠/唤醒方法，实现了一个精彩的异步编程，使得一个连接器对应多个处理器，将监听socket与处理socket放在了不同的线程中。 处理请求 解析连接 解析请求 解析请求头 使用字符数组避免代价高昂的字符串操作 让servlet容器处理请求","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://xudongye.github.io/xdlog/tags/tomcat/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"连接器","slug":"java/tomcat/深入剖析tomcat学习笔记/3连接器","date":"2016-11-03T08:24:14.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"java/tomcat/深入剖析tomcat学习笔记/3连接器/","link":"","permalink":"https://xudongye.github.io/xdlog/java/tomcat/深入剖析tomcat学习笔记/3连接器/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"连接器本章主要构建一个tomcat4中默认连接器的简化版。主要演示了一下如何去解析http的内容。 StringManager类一个基于properties文件、支持国际化的单例模式的字符串信息管理器。 应用程序HttpConnector类123456789101112131415public class HttpConnector implements Runnable &#123; public void run() &#123; ServerSocket serverSocket = new ServerSocket(port, 1, InetAddress.getByName(\"127.0.0.1\")); while (!stopped) &#123; Socket socket = serverSocket.accept(); HttpProcessor processor = new HttpProcessor(this); processor.process(socket); &#125; &#125; public void start() &#123; Thread thread = new Thread(this); thread.start(); &#125;&#125; HttpProcessor类主要完成以下操作： 创建HttpRequest对象 创建HttpResponse对象 解析http请求第1行内容和请求头，填充HttpRequest对象 将request/response传递给ServletProcessor#process()方法，向客户端发送响应 HttpRequest类HttpRequest类实现了javax.servlet.HttpServletRequest接口，并使用一个外观类HttpRequestFacade。 解析http请求主要分为如下步骤： 读取socket输入流 1SocketInputStream input = new SocketInputStream(socket.getInputStream(), 2048); 解析请求行 解析http请求第一行内容，用char[]数组而不是字符串对象以减少字符串操作开销，主要考虑了相对路径、键值对形式的查询字符串、jsessionid等问题。 解析请求头 逐行循环读取http请求内容直到出现空行间隔，将每行按照字符规则定义成键值对类型的header[]保存，并将如content-length,content-type等一些特殊字段记录到对应的属性。 解析cookie 获取参数 利用一个继承HashMap并扩展了锁机制的map保存参数列表，根据content-type,encoding解析请求体 HttpResponse类提供了一个finishResponse()方法flush输出流，以解决最后一行输出内容不能输出的bug。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://xudongye.github.io/xdlog/tags/tomcat/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"一个简单的servlet容器","slug":"java/tomcat/深入剖析tomcat学习笔记/2一个简单的servlet容器","date":"2016-11-03T06:39:07.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"java/tomcat/深入剖析tomcat学习笔记/2一个简单的servlet容器/","link":"","permalink":"https://xudongye.github.io/xdlog/java/tomcat/深入剖析tomcat学习笔记/2一个简单的servlet容器/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"一个简单的servlet容器javax.servlet.Servlet接口Servlet接口定义了servlet的基本行为，是JavaEE的标准部分。 主要定义了如下方法：123init(config);service(request, response);destroy(); 应用程序一个功能齐全的servlet容器，应该要处理以下事情： 当第一次调用某个servlet时，载入该servlet类，并调用其init()方法 针对每次请求，创建request/response实例 调用service()方法 当关闭servlet时，调用destroy()方法，并卸载该类 ServletProcessor1类1234567891011public class ServletProcessor1&#123; public void proccess(Request request, Response response)&#123; String servletName = request.getUri().substring(request.getUri().lastIndexOf(\"/\") + 1); URLClassloader loader = new URLClassloader(new URL[]&#123; new URL(null, repository) &#125;); Class clazz = loader.loadClass(servletName); Servlet servlet = (Servlet)clazz.newInstance(); servlet.service(request, response); &#125;&#125; 一个关于外观模式的说明在上述的代码实现中，将request/response实例传递给service方法时，相当于出现了向上转型。 而这是一种不安全的做法，了解实现细节的servlet程序员就有可能将这两个实例向下转型并调用其实现方法如request.parse()/response.sendStaticResource()，而这种方法是不应该设置为私有的，因为容器代码可能会调用他们。 相比用默认包级别的访问修饰符，熟悉设计模式的开发者肯定就想到了专门用来隐藏实现细节的设计模式————外观模式。 添加外观类实现ServletRequest接口，但是委托具体的实现类实例的私有属性提供能被调用的方法实现。（懂的人应该看模式名称就懂了，在此不赘述设计模式。） 这样的外观模式在tomcat的整个代码实现中会多次出现。 看到这里，我真的不知道是tomcat的开发者过于学院派，还是开发一个平台、框架、类库的时候，确实需要把使用的开发者当做恶人。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://xudongye.github.io/xdlog/tags/tomcat/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"一个简单的Web服务器","slug":"java/tomcat/深入剖析tomcat学习笔记/1一个简单的Web服务器","date":"2016-11-03T02:57:15.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"java/tomcat/深入剖析tomcat学习笔记/1一个简单的Web服务器/","link":"","permalink":"https://xudongye.github.io/xdlog/java/tomcat/深入剖析tomcat学习笔记/1一个简单的Web服务器/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"一个简单的Web服务器概述相信了解一定socket知识的开发者都应该可以想象得到，即使tomcat的功能再怎么丰富多彩绚烂多姿，其最最基础的第一行代码仍然不过是普普通通的socket编程。至于什么“容器”、“连接器”不过发展之后的模块化划分。 HTTPhttp协议是建立在在可靠tcp连接之上的一个基于请求-响应的网络协议。 其基础的约定，就是用一些回车换行、空格之类的特殊字符来将网络传输的字符串进行功能的划分，于是就有了所谓的请求头-URI-协议版本号、请求头、请求实体，协议-状态码-描述、响应头、响应体，其本质上不过是些按照一定标准格式书写的字符。 但话说回来，人类社会的共同协作，不正是基于这些想象中的共同标准吗。 Socket类这个鬼名词被翻译成了“套接字”，如果评选计算机专业十大糟糕翻译，它肯定是第一名的强力候选。 Socket是数据传输的端点，使得计算机之间可以通过网络读写数据。 java.net.Socket这个类类似于客户端，主要用来请求数据。 ServerSocket类java.net.ServerSocket相当于服务端，主要用来等待、处理客户端的通信请求。 应用程序为了节省篇幅文章中全部都是伪代码 HttpServer1234567891011121314151617public class HttpServer &#123; public static void main(String[] args)&#123; HttpServer server = new HttpServer(); server.await(); &#125; public void await() &#123; ServerSocket serverSocket = new ServerSocket(...parameters); while(true)&#123; Socket socket = serverSocket.accept(); InputStream input = socket.getInputStream(); OutputStream output = socket.getOutputStream(); // 将input/output即对应了request response ... &#125; &#125;&#125; Request/Response 根据http协议解析输入/输出流中的字符串","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://xudongye.github.io/xdlog/tags/tomcat/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"}]},{"title":"虚拟机字节码执行引擎","slug":"java/jvm/深入理解jvm学习笔记/8虚拟机字节码执行引擎","date":"2016-10-29T13:05:59.000Z","updated":"2020-12-18T02:51:05.425Z","comments":true,"path":"java/jvm/深入理解jvm学习笔记/8虚拟机字节码执行引擎/","link":"","permalink":"https://xudongye.github.io/xdlog/java/jvm/深入理解jvm学习笔记/8虚拟机字节码执行引擎/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"虚拟机字节码执行引擎概述执行引擎是Java虚拟机的最核心组成部分。JVM规范制定了字节码执行引擎的模型概念，称为执行引擎的统一外观(Facade)：输入的是字节码文件，处理过程是字节码解析的等效过程，输出的是执行结果。 运行时栈帧结构栈帧(Stack Frame)是用于支持虚拟机进行方法调用和方法执行的数据结构，它是虚拟机运行时数据区中的虚拟机栈(Virtual Machine Stack)的栈元素。 每个方法从调用开始到执行完成的过程，都对应着一个栈帧在虚拟机栈从入栈到出栈的过程。 在编译程序代码的时候，栈帧中需要多大的局部变量表、多深的操作数栈都已经完全确定了，并且写入到方法表的Code属性之中(参考类文件结构)，因此一个栈帧需要分配多少内存，不会受到程序运行期间变量数据的影响，仅仅取决于具体的jvm实现。 一个线程中的方法调用链可能很长，对活动线程来说，只有位于栈顶的栈帧才是有效的，称之为当前栈帧(Current Stack Frame)，与这个栈帧相关联的方法称为当前方法(Current Method)。 局部变量表局部变量表(Local Variable Table)是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量。 局部变量表的容量以变量槽(Variable Slot)为最小单位。虚拟机规范并没有明确指明一个Slot所占用的内存空间大小，只是很有导向性地说到每个Slot可以存放一个boolean/byte/char/short/int/float/refrence/returnAddress类型的数据。 在方法执行时，虚拟机使用局部变量表完成参数值到参数变量列表的传递，如果执行的是实例方法(非static)，那局部变量表的第0位Slot默认是用于传递方法所属对象实例的引用，即关键字this。 为了节省栈帧空间，Slot是可以复用的，当字节码的PC计数器的值已经超出了某个变量的作用域，那这个变量对应的Slot就可以交给其他变量使用。这样的设计会伴随一些副作用，如系统的GC行为。 局部变量不会像类变量那样存在“准备阶段”：一次赋予系统初始值，一次赋予程序员定义的初始值。所以局部变量不经过初始化是不能使用的。 操作数栈操作数栈(Operand Stack)的每个元素可以是任意的Java数据类型，当一个方法刚开始执行的时候，这个方法的操作数栈是空的，在方法的执行过程中，会有各种字节码指令往操作数栈中写入和提取内容，也就是出栈/入栈操作。 方法返回地址当一个方法开始执行后，只有两种方式可以退出这个方法： 正常完成出口(Normal Method Invocation Completion) 异常完成出口(Abrupt Method Invocation Completion) 方法退出的过程实际上就等同于把当前栈帧出栈：恢复上层方法的局部变量表和操作数栈，把返回值（如果有的话）压入调用者栈帧的操作数栈中，调整PC计数器的值以指向方法调用指令后面的一条指令等。 方法调用方法调用并不等同于方法执行，方法调用阶段的唯一任务，就是确定被调用方法的版本（即调用哪个方法）。因为在Class文件中，一切的方法调用都是存储的符号引用，而不是方法在实际运行时内存布局中的入口地址（相当于之前所说的直接引用）。 解析调用目标在程序代码写好、编译器进行编译时就能确定下来，这类方法的调用成为解析(Resolution)。 在Java中，主要包括静态方法和私有方法。 解析调用一定是一个静态的过程，在编译期间就完全确定，在类装载的解析阶段就会把涉及的符号引用全部转变为可确定的直接引用，不会延迟到运行期再去完成。 分派 静态分派 重载方法分派： 123456789101112131415161718192021222324252627public class StaticDispatch &#123; static abstract class Human &#123;&#125; static class Man extends Human &#123;&#125; static class Woman extends Human &#123;&#125; public void sayHello(Human guy)&#123; System.out.println(\"hello guy!\"); &#125; public void sayHello(Man guy)&#123; System.out.println(\"hello gentleman!\"); &#125; public void sayHello(Woman guy)&#123; System.out.println(\"hello lady!\"); &#125; public static void main(String[] args) &#123; Human man = new Man(); Human woman = new Woman(); StaticDispatch sd = new StaticDispatch(); sd.sayHello(man); sd.sayHello(woman); &#125;&#125; 虽然代码中刻意定义了两个静态类型相同但是实际类型不同的变量，但虚拟机在重载时是通过参数的静态类型而不是实际类型作为判定依据，并且静态类型是编译期可知的，因此，javac编译器会根据参数的静态类型决定使用哪个重载版本，所以选择了sayHello(Human)作为调用目标，并把这个方法的符号引用写到main()方法的两条invokevirtual指令参数中。 所有依赖静态类型来定位方法执行版本的分派动作称为静态分派，典型的就是方法重载。 在很多情况下，重载版本不是“唯一的”，往往只能确定出“更加适合的”版本，这种模糊性在计算机世界十分罕见，主要原因是字面量不需要定义，所以字面量没有显式的静态类型，只能从语言规则上去理解和推断。 动态分派 方法重写的jvm实现原理，指令invokevirtual的运行时解析过程： 找到操作数栈顶的第一个元素所指向的对象的实际类型，记作C 如果在C中找到与常量中描述符和简单名称都相符的方法，则进行访问权限校验，如果通过则返回这个方法的直接引用，查找过程结束；如果不通过，则返回java.lang.IllegalAccessError 否则，按照继承关系，从下往上依次对C的各个父类进行第2步的搜索和验证过程 如果始终没有找到合适的方法，则抛出java.lang.AbstractMethodError 这种在运行期根据实际类型确定方法执行版本的分派过程被称为动态分派。 单分派与多分派 java是一门静态多分派、动态单分派的语言。 虚拟机动态分派的实现 稳定优化：为类的方法区建立一个虚方法表，使用虚方法表索引来代替元数据查找以提高性能。 虚方法表中存放了各个方法的实际入口地址，如果某个方法在子类中没有被重写，那子类的虚方法表里面的地址入口和父类一致。如果子类重写了这个方法，子类方法表中的地址将会替代为指向子类实现版本的入口地址。 动态类型语言支持 动态类型语言 动态类型语言的关键特征，在于它的类型检查的主体过程是在运行期而不是编译器，如Javascript/Python等。相对的，在编译期就进行类型检查过程的语言，就是常用的静态类型语言，如C++/Java。 通俗的说，运行时异常，就是只要代码不运行到这一行就不会出现问题。与之相对的连接时异常，即使导致异常的代码在无法执行到的分支，类加载时也照样会抛出异常。 变量无类型而变量值才有类型，这也是动态类型语言的一个重要特征。 静态类型语言在编译期确定类型，最显著的好处，就是编译器可以提供严谨的类型检查，与类型相关的问题就能在编码时及时发现，利于稳定性及代码达到更大规模。而动态语言在运行期确定类型，为开发人员提供了更大的灵活性，在某些静态类型语言中需要大量的臃肿代码来实现的功能，由动态语言来实现可能会更加清晰简洁，于是意味着开发效率的提升。 JDK1.7与动态类型 详见invokedynamic指令与java.lang.invoke包。 基于栈的字节码解释执行引擎这里都是编译原理，看不懂。 解释执行基于栈的指令集与基于寄存器的指令集基于栈的解释器执行过程","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"},{"name":"jvm","slug":"jvm","permalink":"https://xudongye.github.io/xdlog/tags/jvm/"}]},{"title":"一次看似诡异的maven依赖导致NoSuchFieldError异常","slug":"java/maven/一次看似诡异的maven依赖导致NoSuchFieldError异常","date":"2016-10-27T08:33:40.000Z","updated":"2020-12-18T02:51:05.425Z","comments":true,"path":"java/maven/一次看似诡异的maven依赖导致NoSuchFieldError异常/","link":"","permalink":"https://xudongye.github.io/xdlog/java/maven/一次看似诡异的maven依赖导致NoSuchFieldError异常/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"一次看似诡异的maven依赖导致NoSuchFieldError异常问题背景在使用maven多项目构建的web project打成war包，部署到tomcat后，发现有一个Enum class，其中的部分枚举属性一直不能访问（编译肯定能通过，否则无法打成WAR包），程序抛出java.lang.NoSuchFieldError异常。 java.lang.NoSuchFieldError的出现情况我猜测很多人对这个异常是很熟悉的，java.lang.NoSuchFieldError意味着试图访问一个类、接口、枚举不存在的属性。 那么问题来了，为什么这样的“编译错误”没有在编译期被检测出来，而在运行期被当做一个异常抛出呢。 我们试图来还原一下最微型的犯罪现场： 12345678public class A &#123; public static int a = 1;&#125;public class B &#123; public static void main(String[] args) &#123; System.out.println(A.a); &#125;&#125; 当我们javac编译java运行之后，一切正常。 现在我们删除A中的static int a，然后重新编译A。 很明显，B是不可能知道A发生了变化的，于是执行B的时候，会抛出java.lang.NoSuchFieldError异常。 本质上，java.lang.NoSuchFieldError通常反映的是class文件版本的不匹配，B和一个不与自己版本匹配的A一起协作，所以发生了异常。 真实出现的场景但真实开发场景下，我们有各种各样的构建工具（我这里的maven）和集成开发环境（比如我的intellij idea），一个project是肯定会被当做一个整体进行编译与打包的，实际上不可能出现上文所说的情况。 所以，通常情况下，这个异常主要是在我们使用第三方类库的时候出现，最典型的就是当我们不用maven管理的情况下，引入纷繁复杂的spring jar包时，这个鲜艳的红字会在控制台显示100次。很容易理解，这就是因为jar包作为已经编译完成的class文件的打包版本，是无法得知与之协作jar包的情况的，他们也不可能作为一个整体进行构建与打包。于是ClassLoader只能无奈地抛出这个异常。 类似的还有ClassNotFoundException, NoSuchMethodError等 整体重新编译也解决不了的情况即使你将整个项目作为整体重新编译，也有一种情况是解决不了的： 那就是这个class被放在了extension libraries或bootstrap libraries。由于ClassLoader的双亲委托模型，jvm会优先加载启动类加载器和扩展类加载器对应目录的class，所以应用类加载器的class根本没有机会被加载，那么无论如何重编译都不可能解决问题。 我的问题的困境根据上面的理论，我依次检查了我的tomcat webapp目录下的lib目录中的的jar包，我甚至将其解压、反编译以确定是否出现了编译上的问题。 接着我检查了我的启动类加载目录与扩展类加载器目录中的jar包，很明显，这种情况下，不可能作死把我的class或者jar包放在这里。 stackoverflow网友的启发stackoverflow.com上的网友提示，很有可能是在应用中有多份全限类名完全一致的class。 于是我在抛出异常的语句之前，加了一句log，打印这个class的getResource(“”)结果。结果出人意料，这个class的资源位置并不是我想象的位置。 还记得吗，我在开头就说明了，我是运用一个maven多项目构建的web project。 在我的开发过程中，我曾经创建过一个module，姑且称之为base-module-old，其中包含了这个报错的类。我将其打包、安装、部署之后，我重构了这个模块，将其变成了base-module-new。但是base-module-old由于名字与base-module-new不一致，所以其文件永远留在了我的本地maven repository中。同时，我的众多子module中，有一个module的依赖没有删除掉base-module-old，虽然这个base-module-old实际没有任何用处，但是每次maven打包都会将他复制到web的lib目录中，于是就出现了多个版本的同名class。同时，由于这两个class其实都指向了相同的java源文件，于是IDE也没有发现任何问题，点击跳转时，十分顺利地会跳转到正确的java源代码，看上去一切OK。 由于相当于代码依赖路径中有两条不同的路径去加载该class，所以这个问题也具有很强的隐蔽性。 总结这里主要涉及到jvm classloader的相关知识，以及在一个classpath中出现了同样全限定名的class的经验。 另外，多熟悉java api以及一定的反射知识，方便在运行时检验class对象的实际情况。 referencesLatte Bloggerstackoverflow上的提问","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"maven","slug":"maven","permalink":"https://xudongye.github.io/xdlog/tags/maven/"}]},{"title":"虚拟机类加载机制","slug":"java/jvm/深入理解jvm学习笔记/7虚拟机类加载机制","date":"2016-10-23T03:57:50.000Z","updated":"2020-12-18T02:51:05.425Z","comments":true,"path":"java/jvm/深入理解jvm学习笔记/7虚拟机类加载机制/","link":"","permalink":"https://xudongye.github.io/xdlog/java/jvm/深入理解jvm学习笔记/7虚拟机类加载机制/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"虚拟机类加载机制概述类加载机制：虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型。 由于不需要在编译时进行连接，java语言的类型加载、连接和初始化过程都是运行期完成，这样的策略可以提供更高的灵活性： 面向接口的应用程序，在运行期再指定实际的实现类。 用户通过自定义的类加载器，让一个本地的应用程序可以在运行期从网络或者其他地方加载一个二进制流作为程序的一部分，如JSP、OSGi技术。 类加载的时机类的整个生命周期包括： 加载(Loading) 验证(Verification) 准备(Preparation) 解析(Resolution) 初始化(Intialization) 使用(Using) 卸载(Unloading) jvm规范严格规定了 有且只有 5种情况必须对类进行初始化： 使用new实例化对象、读取或设置一个类的静态字段（static final修饰的除外）、调用一个类的静态方法 java.lang.reflect包对类进行反射调用 初始化一个类，如果发现其父类没有初始化，需要先初始化其父类；但是接口不会先初始化其父类接口 虚拟机启动时，会先初始化执行主类（包含main()方法的类） 当使用JDK1.7动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getstatic/REF_putStatic/REF_invokeStatic的方法句柄对应的类没有初始化时，先触发其初始化 这5中场景中的行为称为对一个类进行主动引用，除此之外，所以引用类的方式都不会触发初始化，称为被动引用。 被动引用举例： 通过子类引用父类的静态字段，不会导致子类初始化 123456789101112131415161718public class SuperClass &#123; static &#123; System.out.println(\"SuperClass init\"); &#125; public static int value = 123;&#125;public class SubClass extends SuperClass &#123; static &#123; System.out.println(\"SubClass init\"); &#125;&#125;public class NoInitialization &#123; public static void main(String[] args) &#123; System.out.println(SubClass.value); &#125;&#125; 通过数组定义来引用类，不会触发该类的初始化 12345public class NoInitialization &#123; public static void main(String[] args) &#123; SuperClass[] sca = new SuperClass[10]; &#125;&#125; 此处没有初始化SuperClass，但是触发了一个叫做”[Lpackagename.SuperClass”的类的初始化。这个类有虚拟机自动生成，直接继承自Object类。 引用常量不会触发初始化 123456789101112public class ConstClass &#123; static &#123; System.out.println(\"ConstClass init\"); &#125; public static final String HELLOWORLD = \"hello world!\";&#125;public class NoInitialization &#123; public static void main(String[] args) &#123; System.out.println(ConstClass.HELLOWORLD); &#125;&#125; 这个在java中叫做常量传播优化，在编译阶段，已经将常量的值”hello world!”存储到NoInitialization类的常量池中，以后NoInitialization对ConstClass.HELLOWORLD的引用实际上都转换为对自身常量池的引用，与ConstClass没有关系了。 类加载的过程 加载 加载阶段虚拟机完成以下任务： 通过一个类的全限定名来获取定义此类的二进制字节流 jvm从未具体指定如何获取二进制字节流的方式，于是发展出了许多多样的加载方式： 从zip包读取，这是JAR/EAR/WAR格式的基础 从网络获取，如Applet 运行时计算生成，如动态代理技术，在java.lang.reflect.Proxy中使用了ProxyGenerator.generateProxyClass来生成”*$Proxy”的代理类字节流 由其他文件生成，如JSP 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个java.lang.Class对象（并没有明确规定是在java堆中，HotSpot中，虽然Class对象是对象，但是存放在方法区中），作为方法区这个类的各种数据的访问入口 验证 文件格式验证 验证字节流是否符合class文件格式的规范，是否能被当前虚拟机处理。 魔数0xCAFEBABE开头 版本号 常量池索引是否有指向不存在的常量 CONSTANT_Utf8_info是否有不适合UTF-8的数据 元数据验证 对字节码进行语义分析，以保证其符合java语言规范。 这个类是否有父类 是否继承了不允许被继承final的类 如果不是抽象类，是否实现了父类或者接口中要求实现的所有方法 类中字段、方法是否矛盾 字节码验证 通过数据流或控制流分析，确定程序语义是否合法、符合逻辑，对类的方法体进行校验分析。 保证任意时刻操作数栈的数据类型与指令代码序列能配合工作 保证跳转指令不会跳转到方法体之外的字节码指令上 保证方法体中的类型转换是有效的 符号引用验证 符号引用中通过字符串描述的全限定名是否能找到类 在指定类中是否存在符合方法的字段描述符以及简单名称所描述的方法和字段 访问性(private, protected, public, default)是否可达 准备 为类变量(static量而非实例变量)分配内存并设置类变量初始值(是数据类型的零值，int的0、boolean的false、reference的null等)的阶段，这些变量的内存都在方法区内进行分配。 解析 虚拟机将常量池中的符号引用替换为直接引用的过程。 符号引用(Symbolic References): 以一组符号来描述所引用的目标，可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。 直接引用(Direct References): 可以是指向目标的指针、相对偏移量或者一个能间接定位到目标的句柄。 类或接口的解析 假设当前代码所处的类是D，如果要把一个从未解析过的符号引用N解析为一个类或接口C的直接引用，需要如下3步： 如果C不是一个数组类型，jvm会将N的全限定名传递给D的类加载器去加载这个类C。 如果C是一个数组类型，并且数组的元素类型为对象，也就是N的描述符是类似”[Ljava/lang/Integer”的形式，那会按照第一点的规则加载数组元素类型。 如果上面的步骤没有异常，C已经在jvm中是个有效的类了，在解析完成之前，还要进行符号引用验证，确定D对C的访问权限。 字段解析 如果C本身就包含了简单名称和字段描述符相匹配的字段，则直接返回这个字段的直接引用，查找结束。 否则，如果C实现了接口，将会按继承关系从下往上递归搜索各个接口，如果出现了相匹配字段则返回直接引用，查找结束。 否则，如果C不是java.lang.Object的话，按继承关系从下往上递归搜索其父类，如果出现了相匹配字段则返回直接引用，查找结束。 否则，返回java.lang.NoSuchFieldError异常。 在成功返回引用后，将会对这个字段进行权限验证，如果不具备访问权限，会抛出java.lang.IllegalAccessError异常。 类方法解析 除了先要校验C是否是接口外，基本与字段解析类似。 接口方法解析 类似于类方法解析 初始化 初始化阶段是执行类构造器()方法的过程。 ()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块(static{}块)中的语句合并产生的，编译器收集的顺序由语句在源文件中出现的顺序所决定。 ()方法与类的构造函数()不同，它不需要显式调用父类构造器，因为虚拟机会保证在子类()调用之前父类已经初始化完毕。 ()方法对于类或者接口并不是必需的 接口在初始化时不会先执行父类接口的()方法 虚拟机会保证一个类的()在多线程环境下被正确加锁、同步 类加载器虚拟机设计团队将类加载阶段中“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放在jvm之外去实现，一遍让应用程序自己决定如何去获取所需要的类，这个动作的代码模块就是“类加载器”。 类与类加载器 两个类是否相等，只有在这两个类由同一个类加载器加载的前提下才有意义，否则，即使来自从一个Class文件，被同一个jvm加载，也必定不相等。 双亲委派模型 绝大多数java程序都会用到以下3种类加载器： 启动类加载器(Bootstrap ClassLoader) 加载\\lib中类库 扩展类加载器(Extension ClassLoader) 加载\\lib\\ext中的类库 应用程序类加载器(Application ClassLoader) 加载用户ClassPath上指定的类库 类加载器的双亲委派模型(Parents Delegation Model) 使用组合而不是继承来复用父类加载器的代码。 保证了一种带有优先级的层次关系。 实现代码： 12345678910111213141516171819202122protected synchronized Class&lt;?&gt; loadClass (String name, boolean resolve) throws ClassNotFoundException &#123; Class c = findLoadedClass(name); if (c == null) &#123; try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125;else &#123; c = findBootstrapClassOrNull(name); &#125; &#125;catch (ClassNotFoundException e) &#123; &#125; if (c == null) &#123; c = findClass(name); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c;&#125; 破坏双亲委派模型 JDK1.2双亲委派模型引入之前 基础类需要调用回用户代码，如JNDI/JDBC等 追求程序动态性，如HotSwap、Hot Deployment等","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"},{"name":"jvm","slug":"jvm","permalink":"https://xudongye.github.io/xdlog/tags/jvm/"}]},{"title":"类文件结构","slug":"java/jvm/深入理解jvm学习笔记/6类文件结构","date":"2016-10-22T05:43:14.000Z","updated":"2020-12-18T02:51:05.425Z","comments":true,"path":"java/jvm/深入理解jvm学习笔记/6类文件结构/","link":"","permalink":"https://xudongye.github.io/xdlog/java/jvm/深入理解jvm学习笔记/6类文件结构/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"类文件结构这一章节主要讲述了class数据结构的规范以及一些细节，不可避免的十分枯燥，但这部分也是jvm运行的重要基础，是深入了解jvm不可不接触的知识。 无关性的基石class字节码实现平台无关性甚至语言无关性（包括除了java之外能运行在jvm上的语言：Clojure、Groovy、JRuby、Jython等）的基石，是一种字节码的存储格式，jvm不与包括Java在内的任何语言绑定，只与Class文件这种特定的二进制文件格式所关联，其中包含了jvm指令集、符号表以及若干其他辅助信息。 即jvm从不关心Class文件来源自何种语言。 Class类文件结构Class文件是一组以8位字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑排列，无任何分隔符。 Class文件采用一种类似C语言结构体的数据结构来存储数据，这种结构体中只有2中数据类型：无符号数和表。 魔数(Magic Number)与Class文件版本(Minor Version/Major Version) 每个Class文件头4个字节称为魔数（Magic Number），确定这个文件是否是Class文件，固定为0xCAFEBABE。 紧跟着魔数的4个字节存储了Class的版本号，JDK能向下兼容旧版本的Class文件，但不能向上兼容。 常量池(Constant Pool) Class文件的资源仓库，与其他项目关联最多的数据类型。 前置了u2类型的常量池容量计数器(constant_pool_count)，很奇葩，从1开始。 常量分为两大类： 字面量(Literal) 类似于Java语言的常量，如文本字符串、final值等。 符号引用(Symbolic References) 类和接口的全限定名(Fully Qualified Name) 字段的名称和描述符(Descriptor) 方法的名称和描述符 访问标志(access_flags) 是Class类还是接口，是否public，是否abstract，是否final等。 类索引、父类索引与接口索引集合 都是u2类型，各自指向CONSTANT_Class_info的类描述符常量，确定了这个类的全限定名、父类的全限定名，接口的全限定名集合。 字段表集合 描述接口或类中声明的变量，但不包括方法内部的局部变量。用一些修饰符(ACC_PUBLIC, ACC_STATIC, ACC_TRANSIENT等)的布尔值和常量池中的字段名、字段类型描述。 方法表集合 与字段表集合类似。 方法里面的Java代码，经过编译成字节码指令后，存在在方法属性表的一个名为Code的属性中。 编译器可能会自动添加一些方法，如类构造器和实例构造器 属性表集合 Code属性 Exception属性 LineNumberTable属性 描述Java源代码与字节码行号之间的对应关系，用以在出错时借此显示出错行号，调试时根据源代码设置断点。 LocalVariableTable 描述栈帧中局部变量表中的变量与Java源码中定义的变量之间的关系，不是运行时必需。 如果禁用，方法参数名会消失，显示arg0,arg1等占位符，断点调试时也无法根据参数名从上下文中获得参数值。 SourceFile属性 ConstantValue属性 InnerClasses属性 Deprecated/Synthetic属性 StackMapTable属性 Signature属性(泛型签名信息) BootstrapMethods属性 字节码指令简介 字节码与数据类型 很多运算类型都是先转换成相应的运算类型再进行操作，以减少指令数量。 加载和存储指令 运算指令 类型转换指令 对象创建与访问指令 操作数栈管理指令 控制转移指令 方法调用和返回指令 异常处理指令 同步指令 公有设计与私有实现公有设计：Java虚拟机规范 私有实现：Java虚拟机实现 私有实现必须能够读取Class文件并精确实现包含在其中的jvm代码的语义，与此同时，一个优秀的虚拟机实现，在必须的满足虚拟机规范约束下，对具体实现做出修改和优化。 这也是软件世界乃至所有行业制定标准者对实现标准者的约束，与实现者对制定者的反推动的经典模型。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"},{"name":"jvm","slug":"jvm","permalink":"https://xudongye.github.io/xdlog/tags/jvm/"}]},{"title":"angular-mvc解构web-im","slug":"javascript/angularjs/angular-mvc解构web-im","date":"2016-10-20T06:16:51.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"javascript/angularjs/angular-mvc解构web-im/","link":"","permalink":"https://xudongye.github.io/xdlog/javascript/angularjs/angular-mvc解构web-im/","excerpt":"","keywords":[{"name":"Javascript","slug":"Javascript","permalink":"https://xudongye.github.io/xdlog/categories/Javascript/"}],"text":"angular-mvc解构web-im问题背景之前喵书项目需要一个网页版即时通讯工具，即Web-im，只需要发文字信息跟图片，基本没有产品原型设计。考虑到服务器的分发能力，以及开发成本问题，最终选择了接入第三方即时通讯云服务器的方式，将开发工作的重点放在了前端上。 平心而论，这个任务其实是并没有什么困难的，无非是组织一下web im SDK的使用，难点都由第三方帮我们搞定了，总结这么一个文章对老鸟来说意义也很小。 但在实际开发中，由于缺乏全局性的设计和组件式的划分，最终造成这个小小的功能代码十分糟糕，忍无可忍必须重构。 以下主要记录一下思考的纲要图，另一方面，也简单做了一个mvc分层思想的demo。 view显示层directive抽象123456789101112131415&lt;chat-window window-status=\"max/min/normal\"&gt; &lt;chat-contacts-bar&gt;&lt;/chat-contacts-bar&gt; &lt;div class=\"chat-timeline-wrapper\"&gt; &lt;chat-timeline active=\"\"&gt; &lt;chat-msg&gt;aloha&lt;/chat-msg&gt; &lt;chat-msg&gt;bye[bye]&lt;/chat-msg&gt; &lt;/chat-timeline&gt; &lt;chat-timeline&gt;&lt;/chat-timeline&gt; &lt;/div&gt; &lt;chat-sender-wrapper&gt; &lt;chat-emoji-sender&gt;&lt;/chat-emoji-panel&gt; &lt;chat-image-sender&gt;&lt;/chat-image-sender&gt; &lt;textarea&gt;&lt;/textarea&gt; &lt;/chat-sender-wrapper&gt;&lt;/chat-window&gt; directive: chat-window 聊天窗体外壳，包含了聊天窗体的标题栏、外框等部分。 其scope维护了一个窗体状态（最大化、最小化、正常，如果需要拖拽聊天窗体则也在此保存left/top等位置）的参数 chat-contacts-bar 左侧的联系人列表，每个列表项目包含了联系人头像、昵称等内容显示。 其scope维护了自身的展开/收起状态。 chat-timeline 与某一个联系人的聊天时间线，包含了多个具体的聊天信息。 其scope维护了自身的显示/隐藏状态，这个状态也能够被外层作用域所改变，比如用户点击联系人头像，即切换了当前聊天对象。 chat-msg 单条聊天记录，包含了发起者的头像、昵称以及聊天内容。 这个指令应该能够自解析其内容，如表情及图片。 chat-sender-wrapper 整个聊天输入组件的外包装，包含了发送按钮。 chat-emoji-sender 聊天中使用到的emoji表情选择组件，包含表情按钮以及表情列表面板。 其scope维护了面板的展开/收起状态。 另外，其中由字符向表情图片的映射字典（如{‘[laugh]’: ‘images/faces/laugh.gif’}）应该依赖于外部常量模块，以保证与chat-msg解析表情数据的一致性。 chat-image-sender 发送图片的组件，如果比较简单可以直接用html原生的element model数据层结构设计此处数据层的设计，必须保存了的与业务逻辑耦合的数据，只标记组件的展示参数（典型的如组件的显隐）的参数不会在此处涉及，但不排除很多时候，组件的显示参数，是其背后业务数据发生变化的一种投射。 先定义几个基本原型(Class)： Contact username 发消息时唯一标识 nickname 显示用的昵称 avatar 头像 initFromAppServer proto:Function 从数据库获取头像昵称信息 GenericMessage from 谁发的 to 发给谁 timestamp 发送时间 type 消息类型 isFromMe(me) proto:Function 是否是我发的 TextMessage extends GenericMessage text 文本内容 ImageMessage extends GenericMessage url 图片地址 此处假定将聊天数据模型设计在一个对象中，其属性及原型主要有如下： connection 维护了实际的聊天连接 me proto:Contact chatting proto:Contact 当前正在与之聊天的联系人 timelines proto:Object[] contact proto:Contact msgs proto:GenericMessage[] inputtingMsg proto:String isChatWindowActive proto:Boolean hasUnreadMsg proto:Boolean 该对象自身的行为： init() 初始化 initMe() 初始化me initConnection() 初始化WebSocket连接 receiveMsg(msg) 接收到信息 timelines.pushIfNotExisted() 如果需要的话添加新的timeline timelines.findByContact(msg.from).msgs.push(msg) 找到对应的timeline并将msg加入其中 setChatting(msg.from) setHasUnreadMsg() 根据窗体的active情况设置hasUnread标识 toggleChatting(contact) sendMsg(msg) controller控制层方法定义 chat-window controller 作为整个聊天组件的最高层外包装，负责了所有与外部组件的交互动作，主要包括 初始化im连接 用户想与特定的人聊天或者只是想打开聊天窗体 此处运用了一个angular的解耦思想：当事件发布者与事件监听者的父子关系无法确定时，借助顶级作用域发送事件，并且处理者自行订阅该事件，实现基于事件机制的松耦合。 chat-contacts-bar controller 点击列表单项切换当前聊天对象 关闭单个聊天对象 chat-sender-wrapper controller 点击发送按钮发消息 chat-emoji-sender 选中了某个表情，将数据传递给wrapper service服务层定义全局事件在全局中设置了一些全局事件传播的传播api，目前设计了如下： chat 打开聊天窗体，与某人聊天 remindUnreadMsg 提醒监听者，出现了未读消息，执行比如显示小红点等页面行为","categories":[{"name":"Javascript","slug":"Javascript","permalink":"https://xudongye.github.io/xdlog/categories/Javascript/"}],"tags":[{"name":"面向对象","slug":"面向对象","permalink":"https://xudongye.github.io/xdlog/tags/面向对象/"},{"name":"angularjs","slug":"angularjs","permalink":"https://xudongye.github.io/xdlog/tags/angularjs/"}]},{"title":"java垃圾回收与内存分配策略","slug":"java/jvm/深入理解jvm学习笔记/3垃圾收集器与内存分配策略","date":"2016-10-16T01:56:24.000Z","updated":"2020-12-18T02:51:05.425Z","comments":true,"path":"java/jvm/深入理解jvm学习笔记/3垃圾收集器与内存分配策略/","link":"","permalink":"https://xudongye.github.io/xdlog/java/jvm/深入理解jvm学习笔记/3垃圾收集器与内存分配策略/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"java垃圾回收与内存分配策略判断对象是否存活 引用计数算法 无法解决循环引用问题： 1234567ReferenceCountingGC objA = new ReferenceCountingGC();ReferenceCountingGC objB = new ReferenceCountingGC();objA.instance = objB;objB.instance = objA;objA = null;objB = null;System.gc(); 可达性分析算法(Reachability Analysis) 以GC Roots对象作为起始点，树形搜索引用链(Reference Chain)，不可达对象为不可用对象。 GC Roots： 虚拟机栈中的本地变量表中的引用对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中引用对象 引用类型扩充 强引用(Strong Reference): 不会被GC 软引用(SoftReference): 在内存溢出溢出发生之前会被二次回收 弱引用(WeakReference): 下一次gc肯定会被回收 虚引用(PhantomReference): 专门用来发出一个被GC的系统通知 finalize() 一个对象只被执行一次 如果此方法中将this关联到一个强引用，那么可以避免被GC 从不会使用这个方法 回收方法区 回收废弃常量 回收类 该类的所有实例都已被回收，java堆中没有该类的任何实例 该类的ClassLoader已被回收 该类的java.lang.Class对象没有被引用，无法再任何地方运用反射来访问该类的方法 垃圾收集算法 标记-清除算法 简单直接 效率不高 产生大量的内存碎片 复制算法 将内存分块，每次gc时将存活对象复制到另一块，一次清理已使用块。 适合回收新生代，IBM研究表明98%的对象都是朝生夕死 标记-整理算法 让存活对象向内存的一端移动，直接清除掉边界以外的内存 避免了复制算法必须浪费一定空间或者需要额外空间做分配担保的缺点 适合老年代 java堆分代简述（主要来自Google）分代思想中，将内存对象分为新生代和老年代，以使用不同的gc机制。 新生代/老年代 大小默认比例为1/2(jvm参数为–XX:NewRatio) 新生代又被分为Eden、From Survivor、To Survivor，默认比例为8:1:1 这两个单词神级命名，伊甸园与幸存者，传神了。 在不考虑内存不够的情形下： 新创建的对象实例会保存在Eden区 在经历第一次gc后，没被回收的幸存者会进入Survivor区，并对age计数为1岁 每次gc都会给Survivor中的对象加一岁 当age达到指定岁数后，默认15，该对象会进入老年代 在Survivor不足时，需要依赖其他内存区域（老年代）进行分配担保(Handle Promotion) HotSpot算法实现 枚举根节点 由于Stop The World事情，如果每次从GC Roots节点遍历庞大的引用链，那么必然会消耗很多时间，所以必须优化gc roots的检查速度。 在HotSpot虚拟机中，使用了一组称为OopMap的数据结构，在类加载完成时，HotSpot将对象内什么偏移量上是什么类型的数据计算出来，一遍gc扫描时，直接可以通过查找这个map快速得到引用信息。 安全点(SafePoint) 安全点是为了解决一个问题：如果为每一条指令生成OopMap，那么需要消耗大量的额外空间，GC的空间成本将会很高。 其实HotSpot记录了一些特定位置，称为安全点，程序执行时并非在所有地方都可能停下来GC，只有在到达安全点时才暂停。 SafePoint通常是在指令序列复用的地方产生，如方法调用、循环跳转、异常跳转等。 GC中断进程的方案主要有2种： 抢先式中断(Preemptive Suspension) 主动式中断(Voluntary Suspension) GC需要中断线程时，不直接对线程操作，之为他设置一个标志，线程执行时主动轮询这个标志，发现为真时主动中断挂起。 安全区域(Safe Region) Safe Region是为了解决SafePoint设计的一个问题：如果程序没有占用CPU时间，如线程处于Sleep或者Blocked状态，这时线程不可能响应JVM的中断请求。 Safe Region: 在一段代码片段中，引用关系不会发生变化，在此区域的GC都是安全的。Safe Region是对SafePoint的一种扩展。 垃圾收集器 Serial收集器 新生代收集器 单线程收集器 由于其简单直接，是Client模式下的默认收集器 ParNew收集器 新生代收集器 Serial的并行多线程版本 Server模式下的默认收集器 Parallel Scavenge收集器 目标是为了追求可控制的吞吐量，所以Parallel Scavenge收集器又称为“吞吐量优先”收集器 吞吐量(Throughput)：CPU用于运行用户代码与CPU总耗时的比值，吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间) 提供了GC自适应的调节策略(GC Ergonomics)：虚拟机会根据当前系统运行情况收集性能监控信息，动态调整参数： 新生代大小-Xms Eden与Survivor区比例-XX:SurvivorRatio 晋升老年代对象的大小-XX:PretenureSizeThreshold 以提供最合适的停顿时间或最大吞吐量。 Serial Old收集器 Serial收集器的老年代版本 Parallel Old收集器 Parallel Scavenge收集器的老年代版本 CMS收集器 CMS(Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的收集器。 基于“标记-清除”算法，步骤： 初始标记(CMS initial mark) 并发标记(CMS concurrent mark) 重新标记(CMS remark) 并发清除(CMS concurrent sweep) G1收集器(Garbage-First) 并行与并发 分代收集 空间整合 可预测的停顿 核心思路–“化整为零”：将java堆划分为多个大小相等的独立区域（Region），保留新生代与老年代的概念，但不再是物理隔离，它们都是一部分Region的集合。 如何解决跨Region（分代回收中可达性分析必须扫描老年代的引用关系，因为有可能老年代引用指向了新生代对象）之间的对象引用关系问题： G1中每个Region都有一个Remembered Set。虚拟机发现程序对Reference类型数据进行写操作时，会产生一个Write Barrier暂时中断写操作，检查Reference是否与之处于不同的Region。如果是，则通过CardTable将相关引用信息记录到被引用对象所属的Region的Remembered Set中。这样就无需全堆扫描地进行GC Roots枚举。 回收步骤： 初始标记(Initial Marking) 并发标记(Concurrent Marking) 最终标记(Final Marking) 筛选回收(Live Data Counting and Evacuation) 内存分配策略 对象优先在Eden区分配 对象在新生代Eden区分配。如果Eden区没有足够空间，则发起一次Minor GC。 Minor GC： 新生代GC，Java对象大多朝生夕死，所以minor gc十分频繁，回收速度也较快。 Major GC/Full GC： 老年代GC，速度慢。 大对象直接进入老年代 大对象：需要大量连续内存空间的对象，典型的就是长字符串以及数组。 还有种更坏的对象，叫做“朝生夕灭”的“短命大对象”，写程序时应当避免。 /* 注释，看不见(误) 这个在犁书项目计算字符串在排版中的实际位置时总是出现，在方法本地栈区分配超大的字符串数组，然而这个对象会随着方法的执行完毕快速变成垃圾，替jvm抱怨一句：宝宝心里苦。 / 长期存活的对象将进入老年代 -XX:MaxTenuringThreshold设置对象晋升老年代的年龄阈值，默认15 动态对象年龄判定 如果Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，那么年龄大于或等于该年龄的对象将直接进入老年代，无需等到MaxTenuringThreshold中要求的年龄。 空间分配担保 发生Minor GC之前，jvm会检查老年代最大可用的连续空间是否大于新生代所有对象总和： 如果大于，那么Minor GC肯定是安全的，因为老年代提供了充分的晋升空间。 如果小于，那么jvm会查看HandlePromotionFailure的值是否允许冒险担保失败： 如果允许，那么会检查老年代最大可用的连续空间是否大于以往晋升到老年代对象的平均大小： 如果大于，尝试进行Minor GC 如果小于，Full GC 如果不允许担保失败，改为Full GC 这里有两个精彩的比喻： 担保 Minor GC采用了复制手机算法后，如果Survivor空间的轮换备份不足以容纳新生代对象时，必须委托老年代空间为其担保 冒险 与生活中的贷款相似，如果老年代提供担保，那么老年代本身必须有容纳这些对象的剩余空间（手头有足够的空闲现金）。而这个风险，就是老年代的剩余空间大于以往的平均晋升大小，但是这一次的担保空间不足，只能进行一次Full GC来腾出更多空间。 虽然担保失败时绕的圈子是很大的，但大部分情况，还是会允许冒险，避免Full GC过于频繁，而这基于了一个对动态概率取平均值大多数情况下有效的信心。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"},{"name":"jvm","slug":"jvm","permalink":"https://xudongye.github.io/xdlog/tags/jvm/"}]},{"title":"订单合并支付数据表设计","slug":"design/订单合并支付数据表设计","date":"2016-10-14T13:16:24.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"design/订单合并支付数据表设计/","link":"","permalink":"https://xudongye.github.io/xdlog/design/订单合并支付数据表设计/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"电商平台接入第三方支付时关于订单合并支付的数据表设计业务背景当引入了商家与购物车的模型后，无可避免地就会出现一下情况： 用户在购物车选择了多个商家的不同商品选择购买后，会创建多条订单。 多条订单创建完成之后， 不可能需要用户分开支付多次，一定是刷一次卡扫一次二维码输一次密码就支付完成 用户可能放弃合并支付，然后又选择了支付其中某一笔订单 在此情况下，订单与支付不可能再像没有合并支付功能那样，属于同一条数据或者一对一关系。 数据操作数据结构应该为算法服务，设计数据结构之前，先来尝试抽象总结需要满足的算法。 合并支付订单需要支持的数据操作： 查询已付款订单的支付情况 根据单个订单号查询已支付PayOrder PayOrder queryPaidByOrderIds(String orderId); 为单个或多个订单创建微信PrePay之前先查询是否已经生成过二维码 根据单个或多个订单号（且匹配所有订单号顺序：abc,bac,cba等）查询未支付PayOrder.codeUrl PayOrder/null queryNotPaidByOrderIds(String[] orderIds); 处理第三方支付平台的已支付通知时，根据外部订单号查询内部订单号（一个或多个） String[] queryOrderIdsByOutTradeNo(String outTradeNo); 第三方支付平台的约束 微信、支付宝对外部订单号的限制：32字符以内，必须保证唯一性，因此不能使用将内部订单号数组字符串连接的方式作为外部订单号 微信将订单号是否重复的判断任务丢给了开发者，如果申请相同订单号的预支付订单，微信会直接返回错误而不是相同的订单信息 外部订单都有自己的有效期规定，如果失效，不能再使用相同外部订单号去创建外部订单 表关联关系分析由于用户可以选择不支付合并订单，重新支付其中单个订单，所以内部订单与外部支付订单之间形成了一个多对多关联 不管使用数据库主外键显式关联还是某种字符串匹配规则进行隐式关联，都无法避免业务模型中的这种关联。 但从业务逻辑上： 订单模块不依赖于支付模块的实现方式，能否支持合并支付与此无关 支付模块也不依赖于订单模块的任何细节，只依赖于一个按订单号标记已支付状态的接口 所以此处不希望引入任何模型实现层面的紧耦合，只需要依赖上面提供的三个主要的操作的抽象方法。 目前方案此处只是记录方案，不是真实表、字段名 12345678910111213141516支付订单表 PayOrder &#123; id, outTradeNo, 外部订单号 3ndPayType, 第三方平台类型 prepayIdForWechat, 微信预支付id qrcode, 微信预支付二维码 expireDate, 过期时间 hasPaid, 是否已支付 totalFee 总价&#125;订单支付关联表 PayToOrder &#123; payOrderId, 指向PayOrder.id，考虑使用外键方便Hibernate innerOrderId 内部订单号，普通字符串，与Order表字符串相等，不设置外键&#125; sql PayOrder queryPaidByOrderIds(String orderId); 1234select p.* from PayOrder p JOIN PayToOrder pto ON(p.id=pto.payOrderId) where pto.innerOrderId=? and p.hasPaid=true PayOrder/null queryNotPaidByOrderIds(String[] orderIds); 1234SELECT p.id FROM PayOrder p JOIN PayToOrder pto1 ON ( p.id = pto1.PAY_ORDER_ID AND pto1.innerOrderId = '201608050005' ) JOIN PayToOrder pto2 ON ( p.id = pto2.PAY_ORDER_ID AND pto2.innerOrderId = '201708090004' ) WHERE p.isPaid = 0; String[] queryOrderIdsByOutTradeNo(String outTradeNo); 123select pto.innerOrderId from PayToOrder pto JOIN PayOrder p ON(p.id=pto.payOrderId) where p.outTradeNo=?","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"数据结构设计","slug":"数据结构设计","permalink":"https://xudongye.github.io/xdlog/tags/数据结构设计/"}]},{"title":"由一个bug窥探angular双向绑定的秘密","slug":"javascript/angularjs/由一个bug窥探angular双向绑定的秘密","date":"2016-10-09T14:16:24.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"javascript/angularjs/由一个bug窥探angular双向绑定的秘密/","link":"","permalink":"https://xudongye.github.io/xdlog/javascript/angularjs/由一个bug窥探angular双向绑定的秘密/","excerpt":"","keywords":[{"name":"Javascript","slug":"Javascript","permalink":"https://xudongye.github.io/xdlog/categories/Javascript/"}],"text":"由一个bug窥探angular双向绑定的秘密bug背景简述我试图封装一个“一加一减的数字输入框”的指令，点击左边的减号可以将输入框里的数字减一，点击右边的加号可以加一，这样的控件在电商网站的订单页面选择商品数量时十分常见。 我的指令代码如下：12345&lt;span&gt; &lt;a href=\"javascript: void(0);\" ng-click=\"addValue(-1)\"&gt;-&lt;/a&gt; &lt;input type=\"text\" ng-model=\"value\" ng-change=\"onValueChange()\"&gt; &lt;a href=\"javascript: void(0);\" ng-click=\"addValue(1)\"&gt;+&lt;/a&gt;&lt;/span&gt; 1234567891011121314151617angular.module('app').directive('numberInput', function () &#123; return &#123; restrict: 'E', replace: true, scope: &#123; value: '=', onValueChange: '&amp;' &#125;, templateUrl: 'components/number-input/number-input.html', controller: function ($scope) &#123; $scope.addValue = function (stepValue) &#123; $scope.value = $scope.value + stepValue; $scope.onValueChange(); &#125;; &#125; &#125;;&#125;); scope隔离了两个对象： value ‘=’双向绑定了内外层scope.value，使父级scope可以指定input的值，input被操作后的值也可以同步到父级scope。 onValueChange ‘&amp;’将外层函数传入scope，当value值发生变化时执行此函数 我尝试使用这个指令： 1&lt;number-input value=\"cart.quantity\" on-value-change=\"updateQuantity(cart.quantity)\"&gt;&lt;/number-input&gt; 123$scope.updateQuantity = function(quantity) &#123; console.log('quantity', quantity);&#125; bug出现： 当input中是1，我点击加号，使cart.quantity加到2时，updateQuantity方法被执行，但是打印的结果是1不是2。 直观bug判断： 两个scope对象的隔离都是达到预期的，这个bug体现了value值的动态绑定晚于我们的预期，即在onValueChange执行之后才改变了父级value的值。 那么问题来了： value的值到底是什么时候通过何种方式同步到父级scope中去的呢？ angular如何实现双向数据绑定以下都是个人理解，源代码没撸通，有错误概不负责 如果类比java的23种设计模式，angular实现双向数据绑定的核心，是两个无处不在的“代理模式”和“观察者模式” 由dom元素上的ng-model向scope中的属性绑定angular在初始化dom树的时候，遍历所有带有ng-model属性的元素，并将其类似onChange的函数表达式取出来，、用一个代理方法在执行了原有的逻辑之后，将ng-model的值赋予到scope[attributes[ng-model]]上去。 由于js中function也是对象，所以代码上不需要像java的代理模式那样手动或者使用动态字节码技术（如CGlib）生成一个子类来重写原有方法。 由scope中的属性值变化向dom树的元素内容绑定angular在初始化dom树时，将带有ng-bind、ng-model、表达式的元素以及表达式内容，保存在一个观察者序列中。如果仔细查看angular的scope对象，会发现其中private属性中有一个$$watcher数组，这个就是观察者模式中的订阅者，随时准备被scope通知到表达式值发生变化。至于变化后如何改变dom，那就是写普通的js操作dom，无须赘述。 那么，当某件事情发生时，反复遍历$$watcher中的表达式有没有变化，由于这样的遍历属于脏检测，检查效率也常常被不使用双向绑定或者使用基于setter机制的绑定技术使用者所诟病。 而这个检测同步的过程，就是大名鼎鼎的digest cycle（消化循环？？） 有个问题困扰了我很久，那就是上文所说的“某件事情”到底是什么事情，angular如何得知scope中的属性发生了变化。我甚至像某些误人子弟的博主一样，想到了是不是使用了定时任务轮询式检查。 然而angular的开发者是不可能这么僵化的，他们对网页中模型值变化的原因做了一个精彩绝伦的抽象与概括： dom事件，如点击、输入(ng-click) xhr网络响应($http) 浏览器Location变化($location) Timer事件($timeout) 于是angular只需要将这些事件用自己的模块封装起来，在事件发生时，触发digest cycle，那么$$watcher中的元素就会被改变，就实现了数据绑定。 这也解释了为什么在angular中使用很多jQuery插件时，经常出现双向绑定失败的情况，就是因为这些插件以jQuery的方式，避开了上面列出的事件操作了dom树，根本就没有进入digest cycle，双向绑定不可能凭空发生。 当然了，angular还是会把钩子留给开发者，那就是$apply/$digest方法。 但是在finally会触发digest cycle的方法中手动调用$digest，就会抛出digest cycle in progress错误，因为不可能需要同时运行2个digest cycle来脏检测数据。 分析问题于是，这个bug就很容易解释了： 当onValueChange执行时，digest cycle还没开始，父级scope的值还没有发生同步的变化，所以打1没打2。 解决问题目前有2种思路： 将双向绑定的值改成一个对象类型，即共享同一个指针，实际的值是对象的属性，这样就不需要digest cycle，子scope中跟父scope是同一份数据。 将onValueChange的执行时机改成digest cycle之后，或者提前用$timeout(onValueChange)触发digest cycle","categories":[{"name":"Javascript","slug":"Javascript","permalink":"https://xudongye.github.io/xdlog/categories/Javascript/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://xudongye.github.io/xdlog/tags/Javascript/"},{"name":"angularjs","slug":"angularjs","permalink":"https://xudongye.github.io/xdlog/tags/angularjs/"}]},{"title":"用户标签数据结构设计","slug":"design/用户标签数据结构设计","date":"2016-10-02T15:16:24.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"design/用户标签数据结构设计/","link":"","permalink":"https://xudongye.github.io/xdlog/design/用户标签数据结构设计/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"一次关于基于标签的查询与维护的数据结构设计探索需求背景对Author打标签（Tag），两者完全多对多映射：即一个author对应多个tag，一个tag也能被多个author所使用。 此数据结构设计需考虑一下操作的效率（实际耗时短）与便捷（使用hibernate ORM编码逻辑简单）。 给author增加tag 给author移除tag 查询所有的author关联的tag集合 查询某条author的所有tag集合 根据一条或多条tag查询同时带有这些标签的author集合 雏形 引入一个中间表Author_Tag，使用外键关联实现关系型数据库经典的ManyToMany关系 在author中保存用连接符（如逗号或空格）连接的tag名字长字符串 在author中保存用连接符连接的tag主键长字符串 基本行为对比 方案 增tag 删tag 查所有tag author查tags tag查authors 经典多对多 增加中间表 删除中间表 OK 中间表与tag表 查中间表与author表 保存tag名 直接修改author字段 直接修改author字段 OK 最快，只是普通的字段 很慢，全表like字段，并且索引基本无效果：中文，a+b的索引不等于b+a 保存tag.id 直接修改author字段 直接修改author字段 OK 将id.split后逐一查询tag表 较慢，内容都是数字，但仍然会由于顺序不同造成索引效果不佳 对比可见： 中间表多对多的方案在ORM的帮助下，编码最为方便，但需要查询多张表 保存tag名方案的最大优势在于又author查询tag是单表查询，但是浪费空间，并且反向查询效率极差 保存tag.id方案相对中庸，反向查询效率较高 实际开发小坑最开始选择的是方案1，增删改查都十分方便，但是当要求多个tag并列筛选author时，写了个特别坑爹的sql：12345678SELECT a.*FROM Author a JOIN Author_Tag aut ON(a.id=aut.author_id)WHERE aut.tag_id=1OR aut.tag_id=2OR aut.tag_id=3GROUP BY a.idHAVING COUNT(DISTINCT aut.tag_id)=3 字面理解的话，这个SQL十分符合人类（菜鸟）的思维: tag.id=1,2,3不是in，不是or，但也不是and，因为笛卡尔积中不可能有一条数据同时满足tag.id=1 and tag.id=2 and tag.id=3 于是将满足任一条件的结果查询出来，在数个数是否等于3，就可以判断是否同时满足。 但是，千万忍住这样的诱惑，这样的聚合查询会大大拖慢SQL查询速度。 stackoverflow中推荐这种SQL查询语句：12345SELECT aut1.author_idFROM Author_Tag aut1 JOIN Author_Tag aut2 ON(aut1.author_id=aut2.author_id and aut2.tag_id=2)JOIN Author_Tag aut3 ON(aut1.author_id=aut3.author_id and aut3.tag_id=3)WHERE aut1.tag_id=1 这种想法也不难理解，自连接三次后将笛卡尔积三个条件全部满足的部分筛选出来，留下来的author_id就是三个tag都满足的author数据 至于这个查询为什么比上面的聚合查询选个数 快20倍，具体的原因我也不是十分清楚，模糊得感觉到这是一个空间换时间的策略。 有待后续深入学习数据库再来填这个坑。 确定方案由于考虑到由tag查询author应该很少使用（产品上比较隐蔽，也没有突出此功能），最终选择了方案2来追求author查tags的方便与快捷。","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"数据结构设计","slug":"数据结构设计","permalink":"https://xudongye.github.io/xdlog/tags/数据结构设计/"}]},{"title":"点赞设计","slug":"design/点赞设计","date":"2016-10-02T14:16:24.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"design/点赞设计/","link":"","permalink":"https://xudongye.github.io/xdlog/design/点赞设计/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"一次点赞功能设计探索难点 点赞次数如何统计 实时用聚合查询(SQL: SELECT COUNT(1) FROM LIKE WHERE ARTICLE_ID=?)查询数据库条目 性能问题太大 将点赞次数保存在目标对象(ARTICLE.LIKE_COUNT)上，每次有点赞/取消赞行为则增减该数字 写目标对象数据条目频繁 未登录用户如何点赞，且可以记录点赞状态 在数据库记录ip地址或保存在Cookie中的标记浏览器唯一性的长随机数，Like.visitor_id来作为访客的唯一标识 如何在其登录后将未登录赞转换为关联实际用户的赞 visitor_id与user_id并存的情况下，user_id的意义大打折扣，未登录可以记录赞，是否还有必要记录登录赞 浏览器缓存（推荐Html5.localStorage） 服务端点赞次数统计如何实时加一 如何防止客户端作弊，一直加一 登录后需要发送用户点赞请求来同步数据 多种赞目标（可以赞文章、评论、商品等）数据表结构设计 用表继承的方式，父表记录user_id,create_time,status等通用信息，多个子表来标识不同对象(article_id/comment_id/product_id的一种) 表过多 每多一种点赞目标就要添加新表 单表保存，多字段用外键指向赞目标主键 空字段太多 数据条数庞大 单表保存，用一个表征类别的字段区分赞目标对象种类(type=article/comment/product)，用一个字段记录目标主键 无法使用外键约束来保证数据完整性 数据条数庞大 缓存 消息队列 NoSQL","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"数据结构设计","slug":"数据结构设计","permalink":"https://xudongye.github.io/xdlog/tags/数据结构设计/"}]},{"title":"java内存区域与内存溢出异常","slug":"java/jvm/深入理解jvm学习笔记/2java内存区域与内存溢出异常","date":"2016-10-02T01:16:24.000Z","updated":"2020-12-18T02:51:05.425Z","comments":true,"path":"java/jvm/深入理解jvm学习笔记/2java内存区域与内存溢出异常/","link":"","permalink":"https://xudongye.github.io/xdlog/java/jvm/深入理解jvm学习笔记/2java内存区域与内存溢出异常/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"java内存区域与内存溢出异常运行时数据区域 程序计数器(Program Counter Register) 字节码行号指示器，用来控制指令的前进：如分支、循环、跳转、异常处理、线程恢复等。 java虚拟机栈(Java Virtual Machine Stacks) 通常所说的栈内存。 在方法执行时创建栈帧，保存了局部变量表、操作数栈、动态链接、方法出口等信息。 其中局部变量表存放了编译期可知的各种基本数据类型（8大基本类型）、对象引用以及returnAddress类型 局部变量表空间相对确定，可在编译期完成分配，运行期间不会改变局部变量表的大小。 此区域主要会导致STackOverflow-栈深度超出jvm允许深度异常、OutOfMemoryError异常。 本地方法栈(Native Method Stack) 主要供native方法使用 java堆(Java Heap) 存放对象实例 Xms与Xmx表示其最小-最大分配内存 方法区(Method Area) 主要存储： 类信息 常量 静态变量 即时编译器编译后的代码 常被称之为永久代，jvm规范未对这个区域的回收做强制规定 运行时常量池(Runtime Constants Pool) 是方法区的一部分 除了编译期的字面量与符号引用，运行期新的常量也能加入池中 直接内存(Direct Memory) 不是jvm运行时数据区 线程 线程共享：方法区、堆 线程隔离：虚拟机栈、本地方法栈、程序计数器 HotSpot虚拟机 对象的创建 检查类是否已加载 为新生对象分配内存 指针碰撞：内存是规整的，通过移动指针分界点来分配内存 空闲列表：内存不是规整的 采用哪种分配方式最终是根据垃圾收集器是否带有压缩整理功能导致java堆是否规整决定的 线程安全 线程同步处理 本地线程分配缓冲(Thread Local Allocation Buffer, TLAB) 初始化零值 设置对象头 执行构造器方法 对象的内存布局 对象头(Header) 对象是哪个类的实例 类的元数据信息 哈希码 gc分代 锁状态标志 线程持有的锁 偏向线程ID 偏向时间戳 实例数据(Instance Data) 对齐填充(Padding) 对象的访问定位 句柄访问 句柄：可简单理解为智能指针，由操作系统所管理的引用标识，封装了操作范围内的服务。 最大的优势在于，reference中存储的是稳定的句柄地址而不是指针地址，所以当对象的物理位置被移动时，reference数据无需任何修改，而在GC过程中，对象的移动十分普遍。 直接指针访问 优势：节省指针定位的开销，速度更快。 HotSpot虚拟机是采用此访问定位方式。 OutOfMemoryError异常 java堆溢出 java.lang.OutOfMemoryError: Java heap space 演示范例： 向ArrayList死循环添加对象 栈溢出 如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常 如果虚拟机在拓展栈时无法申请到足够的内存空间，将抛出OutOfMemoryError异常 演示范例： 死递归 方法区和运行时常量池溢出 java.lang.OutOfMemoryError: PermGen space 演示范例： 使用String.intern()将字符串纳入运行时常量池，无限循环导致溢出 使用CGLib字节码技术动态生成Class并装载至内存，最终造成方法区溢出 方法区溢出其实十分常见：CGLib(常见的spring aop)、jsp应用、OSGi应用等。","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://xudongye.github.io/xdlog/tags/读书笔记/"},{"name":"jvm","slug":"jvm","permalink":"https://xudongye.github.io/xdlog/tags/jvm/"}]},{"title":"非环形依赖与依赖倒置原则","slug":"design/非环形依赖与依赖倒置原则","date":"2016-08-26T15:11:24.000Z","updated":"2020-12-18T02:51:05.417Z","comments":true,"path":"design/非环形依赖与依赖倒置原则/","link":"","permalink":"https://xudongye.github.io/xdlog/design/非环形依赖与依赖倒置原则/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"一大组痛苦的maven循环依赖引发的重构危机起因将项目的不同模块切分后，发现有些抽象逻辑上并不是紧耦合的模块，由于出现了互相调用，引发了maven的循环依赖。 例如： A模块依赖B模块，B模块同时依赖A。（多个模块同理） 一般情况下，如果不是使用一些代码分析工具嗅探代码坏味道 A.java中import B; B.java中import A; 其实十分常见，也不会出现编译错误。 但是在maven中，由于maven是根据依赖关键build package，所以一旦出现循环依赖，maven只能build失败，抛出循环依赖的异常。 也正是这个异常的频繁出现，给了我一个思考模块化、依赖倒置、解耦的契机。 循环依赖循环依赖（Circular dependency）是指在软件工程中两个或多个模块之间直接或间接地相互依赖，这样的模块组也称之为互递归。 循环依赖的问题 从软件设计角度来说，最大的问题在于互相依赖的紧耦合模块降低甚至完全破坏了单个模块的可复用性。 当局部模块发生的变化传播到与之耦合的其他模块，其多米诺效应很有可能会造成整体的错误（包括程序错误、编译错误）。 循环依赖可能会阻止了使用引用计数（Reference counting）的垃圾回收器（garbage collectors）的自动释放无引用对象，造成内存泄漏。 非循环依赖原则非循环依赖原则(Acyclic dependencies principle)作为一个软件开发原则其实一直存在（只是我没有知道这个概念），只是在maven这里由于事先机制引发了程序的构建错误。 依赖类型软件依赖类型分为显式依赖和隐式依赖。 显式依赖的例子： include表达式，如C/C++中的#include，java中的import 构建系统中的依赖（如maven中的dependency） 隐式依赖的例子： 依靠暴露的接口中没有明确定义的行为（很常见，不能准确表达impl bean的interface方法名其实都在做隐式依赖） 网络协议 总体来说，无论何时，best practice都是优先使用显式依赖，因为更好分析与定位。 破除循环依赖的策略 依赖倒置原则 将公用依赖放在一个新的package里 依赖倒置原则依赖倒置原则是面向对象设计5大原则（SOLID)）之一，专注于软件模块之间的解耦。 主要要求以下： 高级模块不应依赖低级模块，而都应该依赖于其抽象。 抽象不应依赖细节，而是细节依赖抽象。 在传统的应用架构中，在系统的复杂性不断增长中，低级模块按照被高级模块使用的目的来设计。在这种组合下，高级模块直接依赖于低级模块。这个对低级组件的依赖，大大限制了高级组件的可复用性。 控制翻转 增加了抽象层后，高级组件和低级组件都避免了传统的从顶到底的直接依赖。而是每层都依赖于高级组件根据需求所绘制的行为蓝图的抽象。 这里很容易让人想到一个设计模式————适配器模式。 抽象依赖在面向对象编程过程中，通常有如下手段满足依赖倒置原则： 一个类的成员变量必须是接口或者抽象类 所有聚合多个类的包必须只和其他接口或抽象类的包连接 没有类应该继承具体类 没有方法应该复写一个已经被实现的方法 所有的变量实例，都需要一个诸如工厂方法模式的创建设计模式的实现，或者使用依赖注入框架（如：spring IOC, angularjs） maven模块切分我使用maven的目的之一，就是希望通过maven时刻提醒开发者：解耦解耦。我希望达到的效果，就是当我做一个项目时，相似的模块可以直接从原项目中拔下来就用，查看一下pom.xml的依赖列表，分析一下要剔除的依赖模块，再将代码稍作清理就可以使用。而不是缺乏管理的项目那样，把代码复制出来，消除编译错误就已经是浩瀚的工程。 maven切分模块的意义不言而喻。 google了很久，看出主流的切分方式有2种： 水平切分 即基于业务切分，将项目切分为customer,order,admin,work等。我最初就是这样切分的，这样的缺点，上文已经充分说明，由于高层依赖底层，造成复用性极差，每个service,dao基本都是定制给controller使用的。一旦试图依赖其他模块，很容易造成循环依赖，也就是这个文章的来源。 垂直切分 即基于系统层级切分，分为controller,service,dao等，这个缺点也很明显，根本达不到我的拔下来就用的目的，每一层都分离，但是层内不同业务之间的纠缠与耦合，却没有管理。 遵循单一责任原则的水平与垂直共同切分经过一次次模块设计失败后，我一定慢慢拨开了挡在眼前的迷雾，我需要的模块切分方式，应该以以下原则为指导： 先将项目按照业务切分 在将每个业务按照系统层级切分，在我的系统中，我认为dao层与其具体实现是紧耦合（肯定是使用hibernate访问mysql）的，所以分成了rest-api,service-interface,service-implementation,data四层 rest-api层：取名一律为业务名+’-api’，主要规定rest api的controller规则 service-interface层：取名一律为业务名+’-service’，主要规定该业务需要暴露的服务，这些服务的使用者，既有可能是上层rest-api层，也有可能是其他service-implementation service-implementation层：取名一律为业务名+’-core’，显示了这一层负责了最主要的业务逻辑，是系统的核心组件，此层依赖于service-interface层，并实现其接口，并且根据需要依赖其他interface dao层：取名一律为业务名本身，负责dao操作以及表结构的规定（PO），主要方法集成自通用类BaseDao(Hibernate的应用封装) 其他穿插组件： base-model：定义了模型层面的一些基础数据，如BaseEntity base-exception：定义了通用的异常接口以及错误信息 base-dao：定义了基于泛型的通用的常见dao操作 base-util: 常用工具（base系列随便移植） authorization-filter: 根据具体业务逻辑实现的访问权限控制，依赖于相应service-interface，并且被需要权限控制的rest-api层依赖 sdk: 各种第三方sdk，主要供service-implementation层依赖使用 单一责任原则（SRP），从业务和技术上总和考虑，确实只完成了一件事的class，才聚合在一个模块中 这里需要画一个UML图，然而我不是巴哈我不会(ノಠ益ಠ)ノ彡┻━┻ 至此，模块之间的依赖关系就趋于线形而不是环形，单个业务组内，rest-api依赖于service-interface，service-implementation实现service-interface，并依赖data层。 业务组之间，service-implementation可能依赖于其他service-interface形成交叉，data层可能由于PO的主外键关系注册需要单向依赖。 缺陷 实际工作的webapp-module，其实需要依赖于rest-api，service-implementation的所有集合，也就是说必须成套出现，这种关系某种程度上说是一种隐性依赖 data层属于最低层级，没有接口隔离，造成跨模块之间只能单向依赖，典型场景就是PO之间的外键双向映射无法满足（直接循环依赖了） module好多，IDE：宝宝心里苦","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[{"name":"面向对象","slug":"面向对象","permalink":"https://xudongye.github.io/xdlog/tags/面向对象/"},{"name":"解耦","slug":"解耦","permalink":"https://xudongye.github.io/xdlog/tags/解耦/"}]},{"title":"消除SPA井号路由前缀","slug":"javascript/angularjs/消除SPA的井号路由前缀","date":"2016-08-22T11:59:24.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"javascript/angularjs/消除SPA的井号路由前缀/","link":"","permalink":"https://xudongye.github.io/xdlog/javascript/angularjs/消除SPA的井号路由前缀/","excerpt":"","keywords":[{"name":"Javascript","slug":"Javascript","permalink":"https://xudongye.github.io/xdlog/categories/Javascript/"}],"text":"消除基于angularjs构建的单页面应用（SPA）路由上的#前缀 $locationProvider.html5mode(true) $locationProvider.html5mode([mode]) mode: type: Object properties: enabled-{boolean}-(default: false)，如果为true，会在支持history.pushState的浏览器依靠pushState来改变url，在不支持pushState的浏览器会变回#前缀的路径 requireBase-{boolean}-(default: true)，如果html5mode被使用，此参数指定是否需要呈现一个base标签。如果enabled requireBase都设置为true，并且没有base标签，那么在注入$location时angular会抛出错误 rewriteLinks-{boolean}-(default: true)，是否重写html5mode下的相对路径 type: boolean 只设置enabled &lt;head&gt;中增加&lt;base href=&quot;/&quot;&gt;指定base路径 刷新页面时给出get请求错误 Cannot GET /detail?workid=4 3.1. 出现原因 当第一次访问页面/detail，就是刷新页面后，浏览器无从得知这是否是一个真的url还是html5的state。 所以浏览器直接去服务器寻址，并返回了404的错误。 然而，如果根页面（index.html）以及所以的javascript代码全部加载完成，此时尝试导航到/detail，angular就能在浏览器尝试寻址服务器之前迅速地导航到该state。 详见stackoverflow 3.2. 此处的关键，在于将服务器上未解决的请求转移到SPA的根路径 mod rewrite mod_rewrite是Apache web server的一个默认模块，篡改浏览器提交的url请求，并传递内容给浏览器。 这个过程完全发生在服务端，浏览器毫不知情。结果页面就好像是源于提交的url（实际上不是），就像给源url带了一个面具。 然而，这个功能跟经典的重定向是不同的，重定向只是简单地指挥浏览器跳转到另一个不同的服务器地址。 由于mod rewrite有效地伪装了网站内容是从哪里、如何服务的，所以能提高网站安全性。由于静态化了网站路径，也能够用做搜索引擎优化。 grunt plugin: connect-modrewrite 参考http://stackoverflow.com/questions/24283653/angularjs-html5mode-using-grunt-connect-grunt-0-4-5 connect-modrewrite表达式的详细规则见于github 在Gruntfile.js中connect中增加一个middleware: 1234567891011121314151617livereload: &#123; options: &#123; open: true, middleware: function (connect) &#123; return [ // mod rewrite all request to /index.html modRewrite([&apos;^[^\\\\.]*$ /index.html [L]&apos;]), connect.static(&apos;.tmp&apos;), connect().use( &apos;/bower_components&apos;, connect.static(&apos;./bower_components&apos;) ), connect.static(appConfig.app) ]; &#125; &#125; &#125; nginx config 123456789server &#123; server_name yoursite.com; root /usr/share/html; index index.html; location / &#123; try_files $uri $uri/ /index.html; &#125;&#125;","categories":[{"name":"Javascript","slug":"Javascript","permalink":"https://xudongye.github.io/xdlog/categories/Javascript/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://xudongye.github.io/xdlog/tags/Javascript/"},{"name":"angularjs","slug":"angularjs","permalink":"https://xudongye.github.io/xdlog/tags/angularjs/"}]},{"title":"nginx配置CORS服务","slug":"linux/nginx配置CORS服务","date":"2016-08-16T13:16:24.000Z","updated":"2020-12-18T02:51:05.441Z","comments":true,"path":"linux/nginx配置CORS服务/","link":"","permalink":"https://xudongye.github.io/xdlog/linux/nginx配置CORS服务/","excerpt":"","keywords":[{"name":"Linux","slug":"Linux","permalink":"https://xudongye.github.io/xdlog/categories/Linux/"}],"text":"nginx配置CORS服务同源策略含义同源策略(same origin policy)是浏览器安全的基石，同源是指三个相同 协议相同(http不能访问https) 域名相同(miaoshu.me不能访问www.miaoshu.me) 端口相同(localhost:80不能访问localhost:8080) 目的保证用户信息的安全，防止恶意的网站窃取数据。 限制范围 Cookie、LocalStorage 和 IndexDB 无法读取。 DOM无法获得。(iframe, window.open) AJAX不能发送。 CORS相比如jsonp(网页动态添加script标签，向服务器请求json数据)的只能发送GET请求的限制，CORS(Cross-Origin Resource Sharing)是跨域ajax请求的根本解决方案。 CORS需要浏览器和服务器同时支持。 实现CORS通信的关键是服务器。只要服务器实现了CORS接口，就可以跨源通信。 两种请求 simple request 满足以下条件 method: HEAD/GET/POST http header不超出以下name: * Accept * Accept-Language * Content-Language * Last-Event-ID * Content-Type: 只限于application/x-www-form-urlencoded、multipart/form-data、text/plain not-so-simple request 浏览器处理流程 simple request 直接发出CORS请求 not-so-simple request 预检请求(preflight) nginx配置如果服务不是属于开放平台服务，则需要先过滤请求域名 并在response header中增加Access-Control-Allow-*系列参数 1234567891011set $cors &apos;&apos;;if ($http_origin ~* &apos;https?://(localhost|www\\.miaoshu\\.me|miaoshu\\.me|vstar\\.lebooks\\.me)&apos;) &#123; set $cors &apos;true&apos;;&#125;if ($cors = &apos;true&apos;) &#123; add_header &apos;Access-Control-Allow-Origin&apos; &quot;$http_origin&quot; always; add_header &apos;Access-Control-Allow-Credentials&apos; &apos;true&apos; always; add_header &apos;Access-Control-Allow-Methods&apos; &apos;GET, POST, PUT, DELETE, OPTIONS&apos; always; add_header &apos;Access-Control-Allow-Headers&apos; &apos;Accept,Authorization,Cache-Control,Content-Type,DNT,If-Modified-Since,Keep-Alive,Origin,User-Agent,X-Mx-ReqToken,X-Requested-With&apos; always;&#125; 无论response code是多少都允许跨域add_header后增加参数always(此参数必须在1.7.5以上的nginx，否则服务无法启动) 允许跨域发送Cookieangularjs中的$http服务可全局指定ajax请求的是否发送credentials(angular版本1.1.1以上) 123angular.module('app').config(['$httpProvider', function($httpProvider) &#123; $httpProvider.defaults.withCredentials = true;&#125;]) reference浏览器同源政策及其规避方法-阮一峰网络日志 跨域资源共享 CORS 详解-阮一峰网络日志 W3C Recomendation nginx","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xudongye.github.io/xdlog/categories/Linux/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://xudongye.github.io/xdlog/tags/nginx/"}]},{"title":"maven增加本地jar包依赖","slug":"java/maven/maven增加本地jar依赖","date":"2016-08-13T11:54:24.000Z","updated":"2020-12-18T02:51:05.425Z","comments":true,"path":"java/maven/maven增加本地jar依赖/","link":"","permalink":"https://xudongye.github.io/xdlog/java/maven/maven增加本地jar依赖/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"如何为maven增加本地jar包的依赖起因在接入腾讯开放平台过程中，发现腾讯的SDK并没有增加在maven的中央仓库，也没有开放源代码，只是发布了一个jar包。 所以需要将这个完全本地的jar包加入到maven的dependencies列表中。 错误的示范简单google之后，试用了这种方案：1234567&lt;dependency&gt; &lt;groupId&gt;sample&lt;/groupId&gt; &lt;artifactId&gt;com.sample&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;project.basedir&#125;/src/main/resources/yourJar.jar&lt;/systemPath&gt;&lt;/dependency&gt; 将此依赖指定为system依赖，然后指定对应的系统路径。 将此module打包也能成功。 虽然这个方案看上去十分简单，却是错的。 但是由于我在使用一个multiple modules project，webapp module作为最后的release模块，依赖于其他许多子模块。 scope=system的dependency被认定为系统级依赖，不会被复制到最终的应用的war包里。 将未经maven管理的依赖引入项目 选定groupId, artifactId, version 这些参数对用户来说毫不重要，但是maven对所有的dependency都需要这些信息。 所以此处姑且使用: groupId: com.example artifactId: mylib version: 1.0 创建一个本地maven依赖仓库目录 在module根目录下添加一个repo目录（与pom.xml平级） 将jar作为artifact安装进repo 执行maven goal: 1mvn deploy:deploy-file -Durl=file:///path/to/yourproject/repo/ -Dfile=mylib.jar -DgroupId=com.example -DartifactId=mylib -Dpackaging=jar -Dversion=1.0 执行成功后，repo目录会产生一些包含pom文件等元数据以及jar包文件的目录。 为当前module增加本地仓库 123456 &lt;!--other repositories if any--&gt;&lt;repository&gt; &lt;id&gt;project.local&lt;/id&gt; &lt;name&gt;project&lt;/name&gt; &lt;url&gt;file:$&#123;project.basedir&#125;/repo&lt;/url&gt;&lt;/repository&gt; 为当前module增加本地依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;mylib&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt;&lt;/dependency&gt; 此时再进行打包，会发现mylib.jar变成了mylib-1.0.jar，并且会像其他jar包一样会复制到target的lib目录","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"maven","slug":"maven","permalink":"https://xudongye.github.io/xdlog/tags/maven/"}]},{"title":"windows安装maven","slug":"java/maven/maven-on-windows","date":"2016-08-01T06:04:24.000Z","updated":"2020-12-18T02:51:05.425Z","comments":true,"path":"java/maven/maven-on-windows/","link":"","permalink":"https://xudongye.github.io/xdlog/java/maven/maven-on-windows/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"安装jdk及配置环境变量 安装maven，并配置PATH 修改本地仓库地址 %M2_HOME%\\conf\\settings.xml搜索localRepository节点 注意：此处File.separator要填入正斜杠，即使是windows系统 修改JDK版本 在profiles节点增加 123456789101112 &lt;profile&gt; &lt;id&gt;jdk-1.7&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.7&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.7&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt; &lt;/profile&gt; 修改远程maven仓库镜像地址（针对访问外网较慢的环境） 在mirrors节点增加（oschina第三方仓库，服务不是很稳定，但速度较快） 123456&lt;mirror&gt; &lt;id&gt;nexus-osc-thirdparty&lt;/id&gt; &lt;mirrorOf&gt;thirdparty&lt;/mirrorOf&gt; &lt;name&gt;Nexus osc thirdparty&lt;/name&gt; &lt;url&gt;http://maven.oschina.net/content/repositories/thirdparty/&lt;/url&gt;&lt;/mirror&gt;","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"maven","slug":"maven","permalink":"https://xudongye.github.io/xdlog/tags/maven/"}]},{"title":"Ubuntu创建sudo组用户","slug":"linux/Ubuntu创建sudo组用户","date":"2016-07-22T02:36:24.000Z","updated":"2020-12-18T02:51:05.441Z","comments":true,"path":"linux/Ubuntu创建sudo组用户/","link":"","permalink":"https://xudongye.github.io/xdlog/linux/Ubuntu创建sudo组用户/","excerpt":"","keywords":[{"name":"Linux","slug":"Linux","permalink":"https://xudongye.github.io/xdlog/categories/Linux/"}],"text":"Ubuntu创建sudo组用户 adduser username Enter new Unix password: Changing the user information for lebooks此处一路enter全部接受默认设置即可 Is the information correct?[Y/n] usermod -aG sudo username 将用户加入sudo组，a：append，追加到新的组而不将其从原来的组移除；G：group su - username 测试用户权限 番外篇：为什么使用sudo用户而不是直接使用root 在日常使用中直接以root用户身份是十分危险的，一个错误的指令可能在不经意间摧毁系统。理想情况是，你以一个仅有你工作需要的权限的用户来操作Linux，当使用sudo时，Think before doing. sudo会在/var/log/auth.log留下命令日志 锁定root用户，让暴力破解root密码的攻击无处下手，因为一个系统肯定有root用户，但是sudo用户的用户名却无处可猜 多用户允许更方便地改变admin权限 sudo能更细致地设置安全策略 如果以sudo用户登录后离开电脑与以root身份登录的危害不同 以root身份运行的网络应用如果被破解入侵并植入脚本，将造成难以挽回的损失（血的教训！） 参考资料:Ubuntu help","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xudongye.github.io/xdlog/categories/Linux/"}],"tags":[]},{"title":"记录一次阿里云裸机apt-get使用故障","slug":"linux/Ubuntu-apt-get-source.list-not-found","date":"2016-06-21T12:36:24.000Z","updated":"2020-12-18T02:51:05.441Z","comments":true,"path":"linux/Ubuntu-apt-get-source.list-not-found/","link":"","permalink":"https://xudongye.github.io/xdlog/linux/Ubuntu-apt-get-source.list-not-found/","excerpt":"","keywords":[{"name":"Linux","slug":"Linux","permalink":"https://xudongye.github.io/xdlog/categories/Linux/"}],"text":"记录一次阿里云裸机apt-get使用故障root@host:apt-get install tomcat7 E: unable to locate package tomcat7 root@host:apt-get update nothing download /etc/apt/sources.list 文件丢失了 在askubuntu找回了一个副本","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xudongye.github.io/xdlog/categories/Linux/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://xudongye.github.io/xdlog/tags/Ubuntu/"}]},{"title":"OAuth2.0理解","slug":"design/OAuth2.0理解","date":"2016-06-14T15:16:24.000Z","updated":"2020-12-18T02:51:05.409Z","comments":true,"path":"design/OAuth2.0理解/","link":"","permalink":"https://xudongye.github.io/xdlog/design/OAuth2.0理解/","excerpt":"","keywords":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"text":"OAuth2.0理解 接触到使用了OAuth2.0的互联网开放平台（如微信、新浪微博等）开发已经时间不短，之前一直是根据文档去拿token实现需求的功能，没有完全明白这要来来回回拿code、accessToken、refreshToken有什么意义 应用场景理解一个设计标准，必须要明白他要解决的问题，其中耿介才能明了 此处试图用一个很常见的生活场景来还原OAuth2.0要解决的问题： 我有个朋友叫做“团长”，他经常叫我帮他发送体检报告、打印简历之类的事。于是就需要我登录他的163邮箱，为了让我登录邮箱，传统的方式就是，他必须把邮箱的账号和密码告诉我。 这样的授权方式会面临几个比较大的问题： 我为了方便以后帮团长打简历，必须要保存团长的密码，这样很不安全。 团长其实是不希望我看见他跟老婆的私人邮件的，但是密码没有这样的权限控制，也没办法限制授权的有效期。 团长只有修改密码，才能收回对我的授权，而这样团长的其他助理也会全部失去授权。 一旦我在登录过程中，有人在我身后看到了我输入的密码，团长的密码就会泄露出去，团长的所有数据会全部泄露。 OAuth的作用就呼之欲出了。 名词定义对应以上的场景，我们来做出以下定义： 客户端，第三方程序，即上文所说的我 服务提供商，即上文中的163邮箱 用户，资源所有者，即上文中的团长 OAuth思路OAuth在”客户端”与”服务提供商”之间，设置了一个授权层（authorization layer）。”客户端”不能直接登录”服务提供商”，只能登录授权层，以此将用户与客户端区分开来。”客户端”登录授权层所用的令牌（token），与用户的密码不同。用户可以在登录的时候，指定授权层令牌的权限范围和有效期。 “客户端”登录授权层以后，”服务提供商”根据令牌的权限范围和有效期，向”客户端”开放用户储存的资料。 于是上述过程就变成了以下步骤： 我先去服务提供商那里登记备案，我叫魁斯哒浮-优艾斯题壁，我的编号是9527，我家住www.lichengyuan.com 我将团长引导到授权页面，上面写着我的名字，我要申请干哪些事的权限，这个权限就限制了我看团长其他邮件的权力，就解决了问题2 团长一看是我，确认ok，服务提供商就会将一个临时的code发给我家，www.lichengyuan.com/room201，所以即使有人冒充我，这个code还是发不到他手里去 我用code去服务提供商换取访问令牌后，就可以访问我申请权限范围内的资源 在上述过程中，团长从没有告诉我任何人密码，解决了问题1；团长可以随时去服务提供商那里解除我的授权，而不影响其他助理，解决了问题3；由于我没有拿到团长的密码，自然也泄露不了团长的密码，即使访问令牌被泄露，由于其失效短，权限有限，其危害性也相对较小。 授权流程以常见的微信授权登录为例，描述一个相对完整的OAuth2.0授权流程 用户访问客户端，后者将前者导向认证服务器例：https://mp.weixin.com/authorize?response_type=code&amp;client_id=CLIENT_ID&amp;state=xyz&amp;redirect_uri=http://www.client.com/callback这个url中 response_type：表示授权类型，必选项，此处的值固定为”code” client_id：表示客户端的ID，必选项 redirect_uri：表示重定向URI，可选项 scope：表示申请的权限范围，可选项（解决问题2） state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值（这是一个给client开发者自投自抢的参数） 用户选择是否给予客户端授权（选‘是’继续流程）这里用户将在授权服务器的页面上，看到请求授权的客户端是谁，请求哪些权限，而这两个关键信息，客户端是无法撒谎的 认证服务器将用户导向客户端事先指定的”重定向URI”（redirection URI），同时附上一个授权码用户确认授权后，认证服务器将回应客户端的url，例如： http://www.client.com/callback?code=CODE&amp;state=xyz这个url中： code：表示授权码，必选项。该码的有效期应该很短，通常设为10分钟，客户端只能使用该码一次，否则会被授权服务器拒绝。该码与客户端ID和重定向URI，是一一对应关系。 state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。 客户端收到授权码，附上早先的”重定向URI”，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见例：http://mp.weixin.com/authorize?grant_type=authorization_code&amp;code=CODE&amp;redirect_uri=http://www.client.com/callback grant_type：表示使用的授权模式，必选项，此处的值固定为”authorization_code”。 code：表示上一步获得的授权码，必选项。 redirect_uri：表示重定向URI，必选项，且必须与A步骤中的该参数值保持一致。 client_id：表示客户端ID，必选项。 认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token）。 refresh_token的作用如果用户访问的时候，客户端的”访问令牌”已经过期，则需要使用”更新令牌”申请一个新的访问令牌。 由于access_token作为客户端的准入令牌，可能在访问过程中被泄露，于是OAuth在设计上，access_token的有效时间通常不会太长，以微信为例，应该是2小时，所以access_token被泄露的危害被控制在一定范围内。（解决问题4）而refresh_token只在首次获得和请求刷新”访问令牌”时才会在网络中出现，其他时间都是保存在客户端内部，很难被泄露，所以有效时间可以相对较长，这样既保证了安全性，也避免了因为”访问令牌”失效，而需要让用户一直去点授权的麻烦。 需要实现OAuth的场景如果你的应用，保存了大量的用户数据，又准备接入大量的第三方应用以实现平台化，那么就必须要实现OAuth2.0授权机制。 至于具体的实现途径，后续我会尝试开源一个框架来实现。","categories":[{"name":"程序设计","slug":"程序设计","permalink":"https://xudongye.github.io/xdlog/categories/程序设计/"}],"tags":[]},{"title":"web应用get请求获取中文乱码问题","slug":"java/tomcat/web应用get请求获取中文乱码问题","date":"2016-04-21T06:54:24.000Z","updated":"2020-12-18T02:51:05.433Z","comments":true,"path":"java/tomcat/web应用get请求获取中文乱码问题/","link":"","permalink":"https://xudongye.github.io/xdlog/java/tomcat/web应用get请求获取中文乱码问题/","excerpt":"","keywords":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"text":"web应用get请求获取中文乱码问题 spring配置文件applicationSettings.xml添加节点 123456789101112131415&lt;bean class=\"org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter\"&gt; &lt;property name=\"messageConverters\"&gt; &lt;list&gt; &lt;bean class=\"org.springframework.http.converter.StringHttpMessageConverter\"&gt; &lt;property name=\"supportedMediaTypes\"&gt; &lt;list&gt; &lt;value&gt;text/plain;charset=UTF-8&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; tomcat配置conf/server.xml添加节点规定容器的url编码 1&lt;Connector port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" URIEncoding=\"UTF-8\"/&gt;","categories":[{"name":"Java","slug":"Java","permalink":"https://xudongye.github.io/xdlog/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xudongye.github.io/xdlog/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://xudongye.github.io/xdlog/tags/tomcat/"}]},{"title":"Ubuntu安装tomcat7 nginx mysql等服务","slug":"linux/Ubuntu安装tomcat7-nginx-mysql","date":"2016-03-04T13:36:24.000Z","updated":"2020-12-18T02:51:05.441Z","comments":true,"path":"linux/Ubuntu安装tomcat7-nginx-mysql/","link":"","permalink":"https://xudongye.github.io/xdlog/linux/Ubuntu安装tomcat7-nginx-mysql/","excerpt":"","keywords":[{"name":"Linux","slug":"Linux","permalink":"https://xudongye.github.io/xdlog/categories/Linux/"}],"text":"Ubuntu运用apt-get install tomcat7 nginx mysql等服务apt-get install tomcat7tomcat7包依赖于JDK，如果没有安装JDK会自动安装OpenJDK123java version &quot;1.7.0_101&quot;OpenJDK Runtime Environment (IcedTea 2.6.6) (7u101-2.6.6-0ubuntu0.14.04.1)OpenJDK 64-Bit Server VM (build 24.95-b01, mixed mode) CATALINA_HOME /usr/share/tomcat7CATALINA_BASE /var/lib/tomcat7 apt-get install nginx低版本nginx不支持always关键字，但是Ubuntu的中央repository最新nginx版本是1.4.6，必须添加PPA更新nginx版本。 123456789# 安装software-properties-common管理Ubuntu软件应用安装来源信任，允许管理分布式和个人软件资源。$ apt-get install software-properties-common$ apt-get install python-software-properties# 将nginx/stable的ppa加入信任$ add-apt-repository ppa:nginx/stable# 更新package list$ apt-get update# 升级或安装nginx$ apt-get upgrade nginx/apt-get install nginx nginx所有配置在目录：/etc/nginx/日志文件目录：/var/log/nginx/ 修改nginx最大body大小解决413 Request Entity Too Large错误 nginx.cnf中http{}节点中增加配置 1client_max_body_size 2m;","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xudongye.github.io/xdlog/categories/Linux/"}],"tags":[{"name":"部署","slug":"部署","permalink":"https://xudongye.github.io/xdlog/tags/部署/"}]},{"title":"Linux下apt-get安装MySQL","slug":"mysql/Linux下apt-get安装MySQL","date":"2016-03-03T03:36:24.000Z","updated":"2020-12-18T02:51:05.441Z","comments":true,"path":"mysql/Linux下apt-get安装MySQL/","link":"","permalink":"https://xudongye.github.io/xdlog/mysql/Linux下apt-get安装MySQL/","excerpt":"","keywords":[{"name":"Linux","slug":"Linux","permalink":"https://xudongye.github.io/xdlog/categories/Linux/"}],"text":"Linux下apt-get安装MySQL apt-get install mysql-server apt-get install mysql-client mysql -u root -p进入mysql命令行，用set password命令修改密码 12SET PASSWORD FOR 'root'@'localhost'=PASSWORD(‘localhost login password');SET PASSWORD FOR'root'@'%'=PASSWORD(‘remote login password'); 大坑-mysql不能远程访问 gedit /etc/mysql.my.cnf 找到bind-address =127.0.0.1 修改为bind-address =0.0.0.0 123# Instead of skip-networking the default is now to listen only on# localhost which is more compatible and is not less secure.bind-address = 0.0.0.0 授权远程ip登录 12GRANT ALL PRIVILEGES ON *.* TO 'myuser'@'%' IDENTIFIED BY 'mypassword' WITH GRANT OPTION;FLUSH PRIVILEGES; 修改字符集解决中文乱码问题 my.cnf中mysqld添加配置 12character-set-server=utf8mb4init-connect = &quot;SET NAMES utf8mb4&quot;","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xudongye.github.io/xdlog/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://xudongye.github.io/xdlog/tags/linux/"},{"name":"mysql","slug":"mysql","permalink":"https://xudongye.github.io/xdlog/tags/mysql/"}]},{"title":"windows mysql部署指南","slug":"mysql/windows mysql部署指南","date":"2016-03-02T09:41:24.000Z","updated":"2020-12-18T02:51:05.441Z","comments":true,"path":"mysql/windows mysql部署指南/","link":"","permalink":"https://xudongye.github.io/xdlog/mysql/windows mysql部署指南/","excerpt":"","keywords":[{"name":"Mysql","slug":"Mysql","permalink":"https://xudongye.github.io/xdlog/categories/Mysql/"}],"text":"windows mysql部署指南 解压MySQL免安装包，令其路径为D:\\mysql_home 在my-default.ini旁边复制一个my.ini文件，并根据注释修改相关参数 12345678910111213141516[client] port=3306 default-character-set=utf8 [mysqld] port=3306 character_set_server=utf8 #解压目录 basedir=D:\\mysql_home #解压目录下data目录 datadir=D:\\mysql_home\\data sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES [WinMySQLAdmin] D:\\mysql_home\\bin\\mysqld.exe 添加环境变量 MYSQL_HOME – D:\\mysql_home path后追加;%MYSQL_HOME%\\bin 安装mysql服务 进入D:\\mysql_home\\bin目录以管理员身份打开控制台 mysqld –console mysqld –initialize mysqld install 启动mysql服务 net start mysql (停止服务: net stop mysql) 修改root账户密码 修改my.ini，在[mysqld]下添加一行skip-grant-tables来跳过密码验证 重启后进入mysql，执行update mysql.user set authentication_string=password(‘}’) where user=’root’ and Host = ‘localhost’; 可能会修改mysql.user.password_expired字段为否，来取消密码过期或者flush privileges 删除skip-grant-tables后重启mysql 以新密码登录","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://xudongye.github.io/xdlog/categories/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xudongye.github.io/xdlog/tags/mysql/"},{"name":"windows","slug":"windows","permalink":"https://xudongye.github.io/xdlog/tags/windows/"}]},{"title":"Ubuntu git server搭建指南","slug":"linux/Ubuntu git server搭建指南","date":"2015-12-19T11:16:24.000Z","updated":"2020-12-18T02:51:05.441Z","comments":true,"path":"linux/Ubuntu git server搭建指南/","link":"","permalink":"https://xudongye.github.io/xdlog/linux/Ubuntu git server搭建指南/","excerpt":"","keywords":[{"name":"Linux","slug":"Linux","permalink":"https://xudongye.github.io/xdlog/categories/Linux/"}],"text":"Ubuntu git server搭建指南 Ubuntu安装git apt-get update 更新apt-get apt-get install git自动安装git git –version 检测git安装成功 新建一个运行git的Linux用户 adduser git 新建一个名为git的用户（设置密码） 改变git用户的shell登录行为 vim /etc/passwd 将git用户记录如： 1git:x:1001:1001:,,,:/home/git:/bin/bash 改成 1git:x:1001:1001:,,,:/home/git:/usr/bin/git-shell 创建远端仓库 cd /home/ mkdir git cd git mkdir yourproject.git git init –bare –shared yourproject.git 初始化仓库 注意，一定要保证git用户对yourproject.git下所有文件有读写权限（建议递归修改目录owner: chown -R git yourproject.git） 本地安装git和tortoisegit 设置本地通用git用户name email（可在tortoisegit &gt; settings直接设置） 本地产生SSH公钥与私钥 在git-bash中运行: ssh-keygen -C “{{user.email}}“ -t rsa(将{{user.email}}替换为上文中设置的git email) 一路enter后，windows系统在users\\.ssh目录下可以看到生成的公钥id_rsa.pub与私钥id_rsa文件 将公钥复制到Ubuntu上 追加到/home/git/.ssh/authorized_keys文件尾部（第一次复制需要手动创建该文件） github用户可将公钥添加到github key设置页面 本地使用SSH私钥推拉远端仓库 运行PuTTYGen，在Conversions菜单中点击Import key，选择ssh-keygen生成的私钥文件所在位置，比如id_rsa文件 点击Save private key按钮，将其保存为.ppk文件 打开TortoiseGit &gt; settings &gt; git &gt; remote，点击Add Key，选择前一步所保存的.ppk文件所在的位置即可 关于Linux /etc/passwd文件的说明： 12345678910111213141516171819202122232425262728root:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologinsys:x:3:3:sys:/dev:/usr/sbin/nologinsync:x:4:65534:sync:/bin:/bin/syncgames:x:5:60:games:/usr/games:/usr/sbin/nologinman:x:6:12:man:/var/cache/man:/usr/sbin/nologinlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologinmail:x:8:8:mail:/var/mail:/usr/sbin/nologinnews:x:9:9:news:/var/spool/news:/usr/sbin/nologinuucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologinproxy:x:13:13:proxy:/bin:/usr/sbin/nologinwww-data:x:33:33:www-data:/var/www:/usr/sbin/nologinbackup:x:34:34:backup:/var/backups:/usr/sbin/nologinlist:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologinirc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologingnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologinnobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologinlibuuid:x:100:101::/var/lib/libuuid:syslog:x:101:104::/home/syslog:/bin/falsemessagebus:x:102:105::/var/run/dbus:/bin/falsentp:x:103:109::/home/ntp:/bin/falsesshd:x:104:65534::/var/run/sshd:/usr/sbin/nologingit:x:1000:1000:,,,:/home/git:/usr/bin/git-shellmysql:x:105:113:MySQL Server,,,:/nonexistent:/bin/falseftp:x:106:114:ftp daemon,,,:/srv/ftp:/bin/falsetomcat7:x:107:115::/usr/share/tomcat7:/bin/falseredis:x:108:116:redis server,,,:/var/lib/redis:/bin/false 这个文件记录了linux中每个用户的基本属性，每个用户对应一行文本。每行文本又被冒号分隔为7部分，分别是： 用户名 密码：一般会加密保存在/etc/shadow文件中，此处只显示一个占位符*或者x 用户id 组id 用户描述 主目录 用户登录后执行的shell：如root用户通常是/bin/bash来指定bash作为shell解释器，一些伪用户用/usr/sbin/nologin来禁用登录，上文中git用户使用/usr/bin/git-shell来指定git-shell为解释器","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xudongye.github.io/xdlog/categories/Linux/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://xudongye.github.io/xdlog/tags/Ubuntu/"},{"name":"git","slug":"git","permalink":"https://xudongye.github.io/xdlog/tags/git/"},{"name":"vcs","slug":"vcs","permalink":"https://xudongye.github.io/xdlog/tags/vcs/"}]}]}